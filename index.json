[{"content":"需求  虚拟机 我和对象都是程序员，学新技术的时候得有环境 同时两台 win 用于娱乐 目标是 2 台 win 达到 2k 下中配吃鸡流畅，独立键鼠显示器 带 nas 最好 对我用处不是很大，有的话更好，当网盘用用。  配置如下 实现细节  看 B 站司波图的教程 显示器得带音响，因为在家玩，不喜欢带耳机，音质听个响 开机麻烦，因为要先开 unraid ，然后再开 vm ，有的时候只是想开个 centos vm ，进行开发。懒得去房间开主机，买了个小米蓝牙开关，配合主板的 ac recovery 可以实现远程开机。(好像可以用代码实现，一直没整出来) usb 设备，就 unraid 带的 hot usb 插件就可以 直通硬盘，开发环境 centos 的无所谓，丢了就算，我放在了 nas 的 2t 机械盘里。但是我的 win ，有的时候还要拿来工作，包括游戏，丢了要下老半天。所以我原本笔记本上有一块 500g 的固态，又买了一块三星 980 pro 。用于 win 的硬盘，使用的是 pcie 直通。和物理机一样，都在硬盘里。虚拟机删了，东西也都在硬盘。性能达到满 显卡直通，打游戏肯定要显卡直通的，我买的两个同价位同性能的 n 卡和 a 卡，都能直通，除了 a 卡在 LOL 环境下会被检测是虚拟机环境，需要改一个配置。两个发挥的性能没什么区别，都达到了物理机的 90%性能，主要是因为 CPU 的导致没跑满性能 主板和机箱有坑！因为 b660m 是 matx 的，虽然可以插 2 个显卡，但是你如果配置的是 matx 的机箱，第二张显卡就卡在了电源那里，所以机箱一定要是 atx 的。不然装不下，害我白花了 170 快，闲鱼 89 挂着呢。当然可以买 atx 主板，贵啊！ CPU 直通， 打游戏的时候，核心要分离开的。一碗粉的钱总会有点影响，12600k 是 16 线程，所以我给 2 个 win 各用了 8 线程，CPU 得买带核显的，因为 unraid 自己要占一个输出，万一 web 挂了，还有地方可以查。 电源，不用想你都一碗粉的钱了，电源功率整大点别崩了，我的 750w ，用起来还行。建议上 1000w unraid 系统，我只是主要是想用虚拟机功能，nas 不是主要目的，所以就买了 basic 版本，b 站也有半价折扣教程。不用 pve ，当然是因为我代码看不懂，unraid 可视化做的太好了。不用开心版，是因为我要做主力机器的，未来也有可能在 nas 上做一些事情，支持下正版（第一次买正版系统） 不知道为什么，我 bios 里已经调整为首选视频输出是板载显卡了，但是当我的 hdmi 插在独立显卡的时候，unraid 启动的时候还是会占用独立显卡，导致显卡直通的时候会提示 busy 。所以我花了几块钱买了个 hdmi 欺骗器，一直插在核显上。 微星的主板需要关闭 fast boot ，微星自己有一个叫 msi fast boot ，两个都关了，否则 unraid 重启会黑屏  效果  nas 2t 双开 win 虚拟机，2k 100 渲染 中配吃鸡，70fps ，LOL 团战 150fps ，走路 200+ 远程开机，配合 unraid web 远程开虚拟机，进行开发  总结 最近看了 B 站司波图的两男一机。突然想用一碗粉的钱吃两碗粉。基于上面的需求，就动手做了。主板应该选带 wifi 的，不用一直拖网线，有点失误。都是 618 京东买的，后面价格降价了，可恶的狗东。但是有大部分 30 天保价，后面又少了几百块。配置图是没保价之前的价格。总体还算满意。达到了一开始的需求，家里整个公网 ip 啥的，也能在公司就能用家里的虚拟机了。因为自己换了 M1 pro ，pd 虚拟机总觉得用的不舒服。还不能装 centos7 。也满足了自己第一次装机，省钱的话，就是省了一份 cpu ，主板，电源，机箱。2000+。装机大佬们可以多多评价。总觉得硬件买贵了，又不敢去咸鱼～～🙄\n","permalink":"https://sunhao1256.github.io/posts/all-in-one/","summary":"需求  虚拟机 我和对象都是程序员，学新技术的时候得有环境 同时两台 win 用于娱乐 目标是 2 台 win 达到 2k 下中配吃鸡流畅，独立键鼠显示器 带 nas 最好 对我用处不是很大，有的话更好，当网盘用用。  配置如下 实现细节  看 B 站司波图的教程 显示器得带音响，因为在家玩，不喜欢带耳机，音质听个响 开机麻烦，因为要先开 unraid ，然后再开 vm ，有的时候只是想开个 centos vm ，进行开发。懒得去房间开主机，买了个小米蓝牙开关，配合主板的 ac recovery 可以实现远程开机。(好像可以用代码实现，一直没整出来) usb 设备，就 unraid 带的 hot usb 插件就可以 直通硬盘，开发环境 centos 的无所谓，丢了就算，我放在了 nas 的 2t 机械盘里。但是我的 win ，有的时候还要拿来工作，包括游戏，丢了要下老半天。所以我原本笔记本上有一块 500g 的固态，又买了一块三星 980 pro 。用于 win 的硬盘，使用的是 pcie 直通。和物理机一样，都在硬盘里。虚拟机删了，东西也都在硬盘。性能达到满 显卡直通，打游戏肯定要显卡直通的，我买的两个同价位同性能的 n 卡和 a 卡，都能直通，除了 a 卡在 LOL 环境下会被检测是虚拟机环境，需要改一个配置。两个发挥的性能没什么区别，都达到了物理机的 90%性能，主要是因为 CPU 的导致没跑满性能 主板和机箱有坑！因为 b660m 是 matx 的，虽然可以插 2 个显卡，但是你如果配置的是 matx 的机箱，第二张显卡就卡在了电源那里，所以机箱一定要是 atx 的。不然装不下，害我白花了 170 快，闲鱼 89 挂着呢。当然可以买 atx 主板，贵啊！ CPU 直通， 打游戏的时候，核心要分离开的。一碗粉的钱总会有点影响，12600k 是 16 线程，所以我给 2 个 win 各用了 8 线程，CPU 得买带核显的，因为 unraid 自己要占一个输出，万一 web 挂了，还有地方可以查。 电源，不用想你都一碗粉的钱了，电源功率整大点别崩了，我的 750w ，用起来还行。建议上 1000w unraid 系统，我只是主要是想用虚拟机功能，nas 不是主要目的，所以就买了 basic 版本，b 站也有半价折扣教程。不用 pve ，当然是因为我代码看不懂，unraid 可视化做的太好了。不用开心版，是因为我要做主力机器的，未来也有可能在 nas 上做一些事情，支持下正版（第一次买正版系统） 不知道为什么，我 bios 里已经调整为首选视频输出是板载显卡了，但是当我的 hdmi 插在独立显卡的时候，unraid 启动的时候还是会占用独立显卡，导致显卡直通的时候会提示 busy 。所以我花了几块钱买了个 hdmi 欺骗器，一直插在核显上。 微星的主板需要关闭 fast boot ，微星自己有一个叫 msi fast boot ，两个都关了，否则 unraid 重启会黑屏  效果  nas 2t 双开 win 虚拟机，2k 100 渲染 中配吃鸡，70fps ，LOL 团战 150fps ，走路 200+ 远程开机，配合 unraid web 远程开虚拟机，进行开发  总结 最近看了 B 站司波图的两男一机。突然想用一碗粉的钱吃两碗粉。基于上面的需求，就动手做了。主板应该选带 wifi 的，不用一直拖网线，有点失误。都是 618 京东买的，后面价格降价了，可恶的狗东。但是有大部分 30 天保价，后面又少了几百块。配置图是没保价之前的价格。总体还算满意。达到了一开始的需求，家里整个公网 ip 啥的，也能在公司就能用家里的虚拟机了。因为自己换了 M1 pro ，pd 虚拟机总觉得用的不舒服。还不能装 centos7 。也满足了自己第一次装机，省钱的话，就是省了一份 cpu ，主板，电源，机箱。2000+。装机大佬们可以多多评价。总觉得硬件买贵了，又不敢去咸鱼～～🙄","title":"all in one配置"},{"content":"Git常用命令 git init # 初始化本地git仓库（创建新仓库） git config --global user.name \u0026quot;xxx\u0026quot; # 配置用户名 git config --global user.email \u0026quot;xxx@xxx.com\u0026quot; # 配置邮件 git config --global color.ui true # git status等命令自动着色 git config --global color.status auto git config --global color.diff auto git config --global color.branch auto git config --global color.interactive auto git config --global --unset http.proxy # remove proxy configuration on git git clone git+ssh://git@192.168.53.168/VT.git # clone远程仓库 git status # 查看当前版本状态（是否修改） git add xyz # 添加xyz文件至index git add . # 增加当前子目录下所有更改过的文件至index git commit -m 'xxx' # 提交 git commit --amend -m 'xxx' # 合并上一次提交（用于反复修改） git commit -am 'xxx' # 将add和commit合为一步 git rm xxx # 删除index中的文件 git rm -r * # 递归删除 git log # 显示提交日志 git log -1 # 显示1行日志 -n为n行 git log -5 git log --stat # 显示提交日志及相关变动文件 git log -p -m git show dfb02e6e4f2f7b573337763e5c0013802e392818 # 显示某个提交的详细内容 git show dfb02 # 可只用commitid的前几位 git show HEAD # 显示HEAD提交日志 git show HEAD^ # 显示HEAD的父（上一个版本）的提交日志 ^^为上两个版本 ^5为上5个版本 git tag # 显示已存在的tag git tag -a v2.0 -m 'xxx' # 增加v2.0的tag git show v2.0 # 显示v2.0的日志及详细内容 git log v2.0 # 显示v2.0的日志 git diff # 显示所有未添加至index的变更 git diff --cached # 显示所有已添加index但还未commit的变更 git diff HEAD^ # 比较与上一个版本的差异 git diff HEAD -- ./lib # 比较与HEAD版本lib目录的差异 git diff origin/master..master # 比较远程分支master上有本地分支master上没有的 git diff origin/master..master --stat # 只显示差异的文件，不显示具体内容 git remote add origin git+ssh://git@192.168.53.168/VT.git # 增加远程定义（用于push/pull/fetch） git branch # 显示本地分支 git branch --contains 50089 # 显示包含提交50089的分支 git branch -a # 显示所有分支 git branch -r # 显示所有原创分支 git branch --merged # 显示所有已合并到当前分支的分支 git branch --no-merged # 显示所有未合并到当前分支的分支 git branch -m master master_copy # 本地分支改名 git checkout -b master_copy # 从当前分支创建新分支master_copy并检出 git checkout -b master master_copy # 上面的完整版 git checkout features/performance # 检出已存在的features/performance分支 git checkout --track hotfixes/BJVEP933 # 检出远程分支hotfixes/BJVEP933并创建本地跟踪分支 git checkout v2.0 # 检出版本v2.0 git checkout -b devel origin/develop # 从远程分支develop创建新本地分支devel并检出 git checkout -- README # 检出head版本的README文件（可用于修改错误回退） git merge origin/master # 合并远程master分支至当前分支 git cherry-pick ff44785404a8e # 合并提交ff44785404a8e的修改 git push origin master # 将当前分支push到远程master分支 git push origin :hotfixes/BJVEP933 # 删除远程仓库的hotfixes/BJVEP933分支 git push --tags # 把所有tag推送到远程仓库 git fetch # 获取所有远程分支（不更新本地分支，另需merge） git fetch --prune # 获取所有原创分支并清除服务器上已删掉的分支 git pull origin master # 获取远程分支master并merge到当前分支 git mv README README2 # 重命名文件README为README2 git reset --hard HEAD # 将当前版本重置为HEAD（通常用于merge失败回退） git rebase git branch -d hotfixes/BJVEP933 # 删除分支hotfixes/BJVEP933（本分支修改已合并到其他分支） git branch -D hotfixes/BJVEP933 # 强制删除分支hotfixes/BJVEP933 git ls-files # 列出git index包含的文件 git show-branch # 图示当前分支历史 git show-branch --all # 图示所有分支历史 git whatchanged # 显示提交历史对应的文件修改 git revert dfb02e6e4f2f7b573337763e5c0013802e392818 # 撤销提交dfb02e6e4f2f7b573337763e5c0013802e392818 git ls-tree HEAD # 内部命令：显示某个git对象 git rev-parse v2.0 # 内部命令：显示某个ref对于的SHA1 HASH git reflog # 显示所有提交，包括孤立节点 git show HEAD@{5} git show master@{yesterday} # 显示master分支昨天的状态 git log --pretty=format:'%h %s' --graph # 图示提交日志 git show HEAD~3 git show -s --pretty=raw 2be7fcb476 git stash # 暂存当前修改，将所有至为HEAD状态 git stash list # 查看所有暂存 git stash show -p stash@{0} # 参考第一次暂存 git stash apply stash@{0} # 应用第一次暂存 git grep \u0026quot;delete from\u0026quot; # 文件中搜索文本“delete from” git grep -e '#define' --and -e SORT_DIRENT git gc git fsck Git多个账户   通过ssh命令生成多个公私钥\nssh-keygen -t rsa -f ~/.ssh/demo.pub   在.ssh下创建config配置\n# github主账号 Host sunhao1256 HostName github.com User git IdentityFile ~/.ssh/sunhao1256_github_rsa # github frank1256账号 Host frank1256 HostName github.com User git IdentityFile ~/.ssh/frank1256_github_rsa # gitee主账号 Host sunhao1256 HostName gitee.com User git IdentityFile ~/.ssh/sunhao1256_gitee_rsa   添加key到ssh中\nssh-add huayun_rsa   命令测试\nssh -T user@host ssh -T git@frank1256 Hi frank1256! You've successfully authenticated, but GitHub does not provide shell access.   错误\n如果出现too many failure times，可能是你配置的ssh 太多了。\n需要添加IdentityFileOnly yes\nIdentitiesOnly yes   注意！！使用仓库的时候，需要更换HostName为Host，例如\ngit@github.com:sunhao1256/test-git-pr.git 更换为 git@sunhao1256:sunhao1256/test-git-pr.git 如果不进行更换，默认使用当前缓存中的账号，默认第一个\n  ","permalink":"https://sunhao1256.github.io/posts/git%E5%91%BD%E4%BB%A4/","summary":"Git常用命令 git init # 初始化本地git仓库（创建新仓库） git config --global user.name \u0026quot;xxx\u0026quot; # 配置用户名 git config --global user.email \u0026quot;xxx@xxx.com\u0026quot; # 配置邮件 git config --global color.ui true # git status等命令自动着色 git config --global color.status auto git config --global color.diff auto git config --global color.branch auto git config --global color.interactive auto git config --global --unset http.proxy # remove proxy configuration on git git clone git+ssh://git@192.168.53.168/VT.git # clone远程仓库 git status # 查看当前版本状态（是否修改） git add xyz # 添加xyz文件至index git add .","title":"Git命令"},{"content":"Redis redis有哪些数据结构，你用过哪些，做过什么事情   String\n最简单的数据结构，用于存放字符串，实际上在redis中存放的是字符数组，类似java中的arrayList，**Redis 为了对内存做极致的优化，不同长度的字符串使用不同的结构体来表示。**Redis 规定了字符串的长度不得超过 512 MB\n  List\n底层用的双向列表，类似java中的LinkedList，因为是链表所有，插入删除都是O(1)，查询是O(n)\n常见的命令\n  lpush从头添加元素，rpush从尾添加\n  lpop拿出头部的元素，rpop从尾部拿元素\n索引，lpush+lpop即可实现栈，rpush+lpop可以实现队列\n    Hash\n对应着java中的hashMap\n  Set\nRedis 的集合相当于 Java 语言中的 HashSet，它内部的键值对是无序、唯一的。它的内部实现相当于一个特殊的字典，字典中所有的 value 都是一个值 NULL。\n  Zset\n它类似于 Java 中 SortedSet 和 HashMap 的结合体，一方面它是一个 set，保证了内部 value 的唯一性，另一方面它可以为每个 value 赋予一个 score 值，用来代表排序的权重。\n使用场景：\n 排行榜，key是用户id，value是访问次数。 限流，key是用户id+接口id，value是时间戳，每次进方法之前，拿当前时间戳-interval，删除小于now-interval的元素，算出加入当前这次请求set中的个数是否大于max，大于则限流。    BloomFilter\n使用高效的数据结构解决是否存在的问题，可以解决穿透的问题\n  HyperLogLog\n可以用于基数的统计，例如UV统计\n  redis如何做到限流的 限流的几个方式\n  计数器\n计数器即是计算在单位时间窗口内请求访问的次数是否超过阀值。\n窗口分为：固定窗口、滑动窗口\n  固定窗口java实现：\nprivate final AtomicInteger cur = new AtomicInteger(0); private Long startTime; public boolean isAllowed(int maxCount, int interval) { //如果没有第一次时间，则当下为第一次时间  if (startTime == null) startTime = System.currentTimeMillis(); //新增一次  cur.addAndGet(1); //如果当前时间减去开始时间，大于间隙了，说明进入新一轮计算  if (System.currentTimeMillis() - interval * 1000L \u0026gt; startTime) { //重置开始时间  startTime = System.currentTimeMillis(); //重置计数  cur.set(1); return true; } //还在时间内  return cur.get() \u0026lt;= maxCount; } 固定窗口解决了在单位时间内流量次数不会超过阀值，但是在临界点会出现问题。\n在前一个一秒内，0.8秒到1秒，访问了5次，没有超过阀值，1秒到1.2秒访问了5次，没有超过阀值。0.8秒到1.2秒之间的0.4秒访问了10次，超过了阀值。没有达到目的。这样的问题原因是窗口没有“滑动”。\n  滑动窗口\n滑动窗口是一种算法思想\n 滑动窗口算法（Sliding Window Algorithm）\n  Sliding window algorithm is used to perform required operation on specific window size of given large buffer or array.\n滑动窗口算法是在给定特定窗口大小的数组或字符串上执行要求的操作。\n  This technique shows how a nested for loop in few problems can be converted to single for loop and hence reducing the time complexity.\n该技术可以将一部分问题中的嵌套循环转变为一个单循环，因此它可以减少时间复杂度。\n 简而言之，滑动窗口算法在一个特定大小的字符串或数组上进行操作，而不在整个字符串和数组上操作，这样就降低了问题的复杂度，从而也达到降低了循环的嵌套深度。其实这里就可以看出来滑动窗口主要应用在数组和字符串上。\n常见的算法题，找到A字符串中，包含T个字符的最小覆盖子串\n//找到字符串EBBANCF中包含ABC三个字符的最小子串  //往往类似于“ 请找到满足 xx 的最 x 的区间（子串、子数组）的 xx ”这类问题都可以使用该方法进行解决。  public String noFixed(String str,String target){ String[] s = str.split(\u0026#34;\u0026#34;); String[] t = target.split(\u0026#34;\u0026#34;); //定义两个指针，在s上滑动  int left=0,right=0; String res=null; List window=new ArrayList(); //一直滑动，直到右指针到头了  while (right\u0026lt;s.length){ //移动右指针，一直到包含了所有的目标元素  window.add(s[right]); right++; //如果window满足要求了，就移动左指针  while (window.containsAll(Arrays.asList(t))){ if(res==null){ //第一次得到结果  res=String.join(\u0026#34;\u0026#34;,window); }else{ //比较当前的长度大小和目前最小的结果  res=(window.size()\u0026gt;res.length())?String.join(\u0026#34;\u0026#34;,window):res; } //移动左指针,直至窗口不满足  window.remove(s[left]); left++; } } return res; } /** * 固定窗口大小为f */ public String fixed(Integer f, String str) { String result = null; int right = 0; //寻找字符串中长度为f的包含最多元音字母的子串  String[] s = str.split(\u0026#34;\u0026#34;); List window = new ArrayList(); while (right \u0026lt; s.length) { //滑动右指针  window.add(s[right]); right++; //达到目标窗口的大小  if (right \u0026gt;= f) { //检查条件  String cur = String.join(\u0026#34;\u0026#34;, window); if (result == null) { //满足条件的话  if (countOfVowel(cur) \u0026gt; 0) result = cur; } else { int i = countOfVowel(result); int j = countOfVowel(cur); result = i \u0026gt; j ? result : cur; } //移动左指针，因为窗口固定，删除左边right-f个字符  window.remove(s[right-f]); } } return result; } private int countOfVowel(String s) { String[] split = s.split(\u0026#34;\u0026#34;); List\u0026lt;String\u0026gt; vowels = Arrays.asList(\u0026#34;A\u0026#34;, \u0026#34;E\u0026#34;, \u0026#34;I\u0026#34;, \u0026#34;O\u0026#34;, \u0026#34;U\u0026#34;); int res = 0; for (int i = 0; i \u0026lt; split.length; i++) { if (vowels.contains(split[i].toUpperCase())) { res++; } } return res; } 滑动窗口解决了临界的问题，但是当在窗口内达到了阀值，剩余的请求都会被拒绝，这样处理不好。\n    漏桶\npublic class LeakBucketLimit { /** * 出水率 */ private final long rate=5L;//1秒出水5个请求  /** * 桶的容量 */ private final long capacity=10L; /** * 当前水量 */ private long currentWater; /** * 最后刷新时间 */ private long refreshTime; public boolean tryAcquire(){ /** * 获取当前时间 */ long currentTime = System.currentTimeMillis(); /** * 流出去的水 */ long outWater = (currentTime-refreshTime)/1000*rate; /** * 当前 */ currentWater = Math.max(0,currentWater-outWater); System.out.println(currentWater); refreshTime=currentTime; if(currentWater\u0026gt;=capacity){ //不够流了  return false; } //加水  currentWater++; return true; } } 缺陷：不管是什么流量，桶都会按照rate一点一点消费，如果来了爆炸的流量，依然一点一点消费，实际情况中，我们希望能快速消费。而平时就按照rate消费。\n  令牌桶\n令牌桶就是为了解决漏桶的缺点。\n  有一个令牌管理员，根据限流大小，定速往令牌桶里放令牌。 如果令牌数量满了，超过令牌桶容量的限制，那就丢弃。 系统在接受到一个用户请求时，都会先去令牌桶要一个令牌。如果拿到令牌，那么就处理这个请求的业务逻辑； 如果拿不到令牌，就直接拒绝这个请求。   /** * 令牌桶发放速度 */ private final long tokenRate=5L; /** * 桶的容量 */ private final long capacity=10; /** * 上一次刷新的时间 */ private long refreshTime; /** * 当前桶里的令牌 */ private long currentToken; public boolean tryAcquire(){ //当前时间  long currentTime=System.currentTimeMillis(); //更新当前桶里的令牌个数  //当前token个数=原来当前个数+间隙之间生产出来的token个数（可能为0）  currentToken =Math.min (capacity,(currentToken+currentTime - refreshTime) / 1000 * tokenRate); refreshTime=currentTime; if(currentToken\u0026gt;0){ //还有令牌  currentToken--; return true; } return false; }   redis是单线程的吗，它为什么这么快？   是“单线程”也不是“单线程”\n在redis6.0后，推出了多线程的概念。这里的单线程或者多线程，是对于整个redis来说的。并不是针对一个缓存的读取而言。\n说redis是单线程的，并不是说redis的所有操作模块都是单线程的。redis单线程指的是，用单个线程进行网络io和键值读取。\nRedis中只有网络请求模块和数据操作模块是单线程的。而其他的如持久化存储模块、集群支撑模块等是多线程的\n在redis6.0之前一直是这样处理的，为什么对于网络的io不用多线程呢。\n 首先使用多线程的目的是为了提高IO利用率和CPU利用率，而redis的是io密集型软件。CPU并不是它的瓶颈。可以使用多线程来提高IO\n利用率，但是提高IO利用率的方法并非只有多线程一种方式\n 对线程带来的弊端：内存模型，锁，CAS操作保证并发。\n虽然，采用多线程可以帮助我们提升CPU和I/O的利用率，但是多线程带来的并发问题也给这些语言和框架带来了更多的复杂性。而且，多线程模型中，多个线程的互相切换也会带来一定的性能开销。\n所以，在提升I/O利用率这个方面上，Redis并没有采用多线程技术，而是选择了多路复用 I/O技术。\n多路复用即redis使用单线程，去接收并发下的网络套接字。redis没有使用多线程，减少线程之前切换的开销，以及多线程带来的共享对象的并发问题。因此大家称redis是单线程的\n由于多路复用的IO模型本质上仍然是同步阻塞型IO模型。\n在多路复用的IO模型中，在处理网络请求时，调用 select （其他函数同理）的过程是阻塞的，也就是说这个过程会阻塞线程，如果并发量很高，此处可能会成为瓶颈。\n如果能采用多线程，使得网络处理的请求并发进行，就可以大大的提升性能。多线程除了可以减少由于网络 I/O 等待造成的影响，还可以充分利用 CPU 的多核优势。\nRedis 6.0采用多个IO线程来处理网络请求，网络请求的解析可以由其他线程完成，然后把解析后的请求交由主线程进行实际的内存读写。提升网络请求处理的并行度，进而提升整体性能。\n但是，Redis 的多 IO 线程只是用来处理网络请求的，对于读写命令，Redis 仍然使用单线程来处理。因此不会数据上的并发安全问题\n  为什么快？\n  完全基于内存\n  数据结构简单，对数据操作也简单，如哈希表、跳表都有很高的性能\n  采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU\n  使用多路I/O复用模型，非阻塞，即reactor模型\nIO多路复用，即单个线程处理多个socket请求，非阻塞只socket设置为非阻塞，发送请求后不会继续等待，而是可以继续再发信息或者收信息。epoll监听哪些socket上有事件到达，当 accept、read、write 和 close 文件事件产生时，就会回调 FD 绑定的事件处理器\n    Redis在主从复制的和故障转移的过程中会导致数据丢失吗   异步数据丢失：\n显然是会的，从上面的「主从复制」流程来看，这个过程是异步的（在复制的过程中：主服务器会一直接收请求，然后把修改命令发给从服务器），\n假如主服务器的命令还没发完给从服务器，自己就挂掉了。这时候想要让从服务器顶上主服务器，但从服务器的数据是不全的\n  脑裂\n还有另一种情况就是：有可能哨兵认为主服务器挂了，但真实是主服务器并没有挂( 网络抖动)，而哨兵已经选举了一台从服务器当做是主服务器了，此时「客户端」还没反应过来，还继续写向旧主服务器写数据\n  redis的高可用和持久化 高可用：\n  哨兵：\n哨兵」干的事情主要就是：监控（监控主服务器的状态）、选主（主服务器挂了，在从服务器选出一个作为主服务器）、通知（故障发送消息给管理员）和配置（作为配置中心，提供当前主服务器的信息），可以把「哨兵」当做是运行在「特殊」模式下的Redis服务器，为了「高可用」，哨兵也是集群架构的。\n 哨兵可以理解为特殊的Redis服务器，一般会组成哨兵集群 哨兵主要工作是监控、告警、配置以及选主 当主服务器发生故障时，会「选出」一台从服务器来顶上「客观下线」的服务器，由「领头哨兵」进行切换    主从备份：和mysql类似，主节点只处理写的请求，而从节点处理读的请求，他们之间是通过psync同步\n 你启动一台slave 的时候，他会发送一个psync命令给master ，如果是这个slave第一次连接到master，他会触发一个全量复制。master就会启动一个线程，生成RDB快照，还会把新的写请求都缓存在内存中，RDB文件生成后，master会将这个RDB发送给slave的，slave拿到之后做的第一件事情就是写进本地的磁盘，然后加载进内存，然后master会把内存里面缓存的那些新命名都发给slave。\n  PSYNC命令两种模式：完全重同步、部分重同步 完全重同步：主从服务器建立连接、主服务器生成RDB文件发给从服务器、主服务器不阻塞（相关修改命令记录至buffer）、将修改命令发给从服务器 部分重同步：从服务器断线重连，发送RunId和offset给主服务器，主服务器判断offset和runId，将还未同步给从服务器的offset相关指令进行发送    redis cluster：\n分片集群：用于解决主从复制、脑裂的问题。类似es\n  redis的持久化：\n​\tRedis提供了2中持久化方式AOF，RDB\n 根据我们自己配置的时间或者手动去执行BGSAVE或SAVE命令，Redis就会去生成RDB文件，这个RDB文件实际上就是一个经过压缩的二进制文件，Redis可以通过这个文件在启动的时候来还原我们的数据\n而AOF则是把Redis服务器接收到的所有写命令都记录到日志中\nRedis重跑一遍这个记录下的日志文件，就相当于还原了数据\n   RDB：RDB 持久化机制，是对 Redis 中的数据执行周期性的持久化。\n 优点： 他会生成多个数据文件，每个数据文件分别都代表了某一时刻Redis里面的数据，这种方式，有没有觉得很适合做冷备，完整的数据运维设置定时任务，定时同步到远端的服务器，比如阿里的云服务，这样一旦线上挂了，你想恢复多少分钟之前的数据，就去远端拷贝一份之前的数据就好了。\nRDB对Redis的性能影响非常小，是因为在同步数据的时候他只是fork了一个子进程去做持久化的，而且他在数据恢复的时候速度比AOF来的快。\n缺点： RDB都是快照文件，都是默认五分钟甚至更久的时间才会生成一次，这意味着你这次同步到下次同步这中间五分钟的数据都很可能全部丢失掉。AOF则最多丢一秒的数据，数据完整性上高下立判。\n还有就是RDB在生成数据快照的时候，如果文件很大，客户端可能会暂停几毫秒甚至几秒，你公司在做秒杀的时候他刚好在这个时候fork了一个子进程去生成一个大快照，哦豁，出大问题。\n   AOF：AOF 机制对每条写入命令作为日志，以 append-only 的模式写入一个日志文件中，因为这个模式是只追加的方式，所以没有任何磁盘寻址的开销，所以很快，有点像Mysql中的binlog。\n 优点： 上面提到了，RDB五分钟一次生成快照，但是AOF是一秒一次去通过一个后台的线程fsync操作，那最多丢这一秒的数据。\nAOF在对日志文件进行操作的时候是以append-only的方式去写的，他只是追加的方式写数据，自然就少了很多磁盘寻址的开销了，写入性能惊人，文件也不容易破损。\n缺点： 一样的数据，AOF文件比RDB还要大。\nAOF开启后，Redis支持写的QPS会比RDB支持写的要低，他不是每秒都要去异步刷新一次日志嘛fsync，当然即使这样性能还是很高.\n   实际上：\n使用RDB先恢复数据，速度快，然后通过AOF进行补全\n  redis布隆过滤器 布隆过滤器可以使用高效的数据结构，存放大量的数据。布隆过滤器说存在，则不一定存在，但是布隆过滤器说不存在，则一定不存在。常用于缓存穿透的问题。\n特点\n 空间效率高 多次hash，时间效率高 存在误判，所以不好做删除  使用场景\n 黑名单 URL去重 ID校验 防止穿透  原理：\n 布隆过滤器本质上是一个位数组，每个元素只占1个bit，只会有0和1，通过n次hash，减少hash碰撞。当一个key过来的时候，进行n次hash，得出n次结果，将n次结果的位值在数组中查找，如果发现有一个值为0，则key一定不在过滤器中。如果都为1可能在过滤器中，因为hash值会碰撞。hash的次数和数组的大小决定了布隆过滤器的准确度。  使用：\n google在guava中封装好的BloomFilter redis 4.0后可以加入module BloomFilter  redis分布式锁 SETNX + EXPIRE\nredis为什么选用跳表   跳表是一种进阶型的链表，具有二分查找的功能参考\n Redis只在两个地方用到了跳跃表，一个是实现有序集合键(zset)，另一个是在集群节点中用作内部数据结构，除此之外，跳表在Redis里面没有其他用途。\n但是为什么用跳表而不用红黑树呢？猜想如下： 1）在做范围查找的时候，平衡树比skiplist操作要复杂。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在skiplist上进行范围查找就非常简单，只需要在找到小值之后，对第1层链表进行若干步的遍历就可以实现。 2）平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速。 3）从内存占用上来说，skiplist比平衡树更灵活一些。一般来说，平衡树每个节点包含2个指针（分别指向左右子树），而skiplist每个节点包含的指针数目平均为1/(1-p)，具体取决于参数p的大小。如果像Redis里的实现一样，取p=1/4，那么平均每个节点包含1.33个指针，比平衡树更有优势。 4）查找单个key，skiplist和平衡树的时间复杂度都为O(log n)，大体相当；而哈希表在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近O(1)，性能更高一些。所以我们平常使用的各种Map或dictionary结构，大都是基于哈希表实现的。 5）从算法实现难度上来比较，skiplist比平衡树要简单得多。\n   redis防击穿、雪崩、穿透   击穿\n和雪崩有一点像。击穿是大量请求，打一个key，这个key突然失效，导致打挂了库。而雪崩是大量key一起失效，设计永不过期\n  穿透\n访问一个不可能存在的key，一直打到数据库，导致数据库挂了\n解决方案：\n 代码中针对查key的逻辑需要注意，在逻辑上就处理掉这些不会出现的key 对于不存在的key，依然存缓存，value设为null，或者提示语句。例如“稍后再试，请求不正确”。并且给他一个过期时间 使用布隆过滤器 通过nginx做ip的限制，加黑名单。    雪崩\n大批量的key在同时一时刻失效，导致大批量的请求全部打到数据上。数据库承受不住挂了。\n解决方案：\n 设置过期时间的时候加上随机数，保证同一时间不会有大量的key失效 设置这种热点数据用不过期。需要更新的时候，顺手更新一下缓存就可以了    redis是先删缓存还是先写库，怎么解决缓存一致性   先删缓存，再更新数据库\n缓存删除完成后，数据库更新操作还没好，此时请求过来，读缓存，读不到，读数据库，得到的是旧数据\n解决方案：延时双删\n 流程如下：\n 线程1删除缓存，然后去更新数据库 线程2来读缓存，发现缓存已经被删除，所以直接从数据库中读取，这时候由于线程1还没有更新完成，所以读到的是旧值，然后把旧值写入缓存 线程1，根据估算的时间，sleep，由于sleep的时间大于线程2读数据+写缓存的时间，所以缓存被再次删除 如果还有其他线程来读取缓存的话，就会再次从数据库中读取到最新值     先更新库，再删除缓存\n更新数据库成功，如果删除缓存失败或者还没有来得及删除，那么，其他线程从缓存中读取到的就是旧值，还是会发生不一致。\n解决方案：先更新数据库，成功后往消息队列发消息，消费到消息后再删除缓存，借助消息队列的重试机制来实现，达到最终一致性的效果。进阶一点，使用数据的binlog通知到消息队列，然后更新缓存。无代码入侵\n 缺陷：\n 引入消息中间件之后，问题更复杂了，怎么保证消息不丢失更麻烦 就算更新数据库和删除缓存都没有发生问题，消息的延迟也会带来短暂的不一致性，不过这个延迟相对来说还是可以接受的     设置过期时间\n 每次放入缓存的时候，设置一个过期时间，比如5分钟，以后的操作只修改数据库，不操作缓存，等待缓存超时后从数据库重新读取。\n如果对于一致性要求不是很高的情况，可以采用这种方案。\n这个方案还会有另外一个问题，就是如果数据更新的特别频繁，不一致性的问题就很大了。\n在实际生产中，我们有一些活动的缓存数据是使用这种方式处理的。\n因为活动并不频繁发生改变，而且对于活动来说，短暂的不一致性并不会有什么大的问题。\n   总结\n首先，我们要明确一点，缓存不是更新，而应该是删除。\n删除缓存有两种方式：\n 举个栗子，一个缓存涉及的表的字段，在 1 分钟内就修改了 20 次，或者是 100 次，那么缓存更新 20 次、100 次；但是这个缓存在 1 分钟内只被读取了 1 次，有大量的冷数据。 实际上，如果你只是删除缓存的话，那么在 1 分钟内，这个缓存不过就重新计算一次而已，开销大幅度降低。用到缓存才去算缓存。\n  先删除缓存，再更新数据库。解决方案是使用延迟双删。 先更新数据库，再删除缓存。解决方案是消息队列或者其他binlog同步，引入消息队列会带来更多的问题，并不推荐直接使用。  针对缓存一致性要求不是很高的场景，那么只通过设置超时时间就可以了。\n其实，如果不是很高的并发，无论你选择先删缓存还是后删缓存的方式，都几乎很少能产生这种问题，但是在高并发下，你应该知道怎么解决问题。\n  redis的淘汰策略 官网上给到的内存淘汰机制是以下几个：\n  noeviction:返回错误当内存限制达到并且客户端尝试执行会让更多内存被使用的命令（大部分的写入指令，但DEL和几个例外）\n  allkeys-lru: 尝试回收最少使用的键（LRU），使得新添加的数据有空间存放。\n  volatile-lru: 尝试回收最少使用的键（LRU），但仅限于在过期集合的键,使得新添加的数据有空间存放。\n  allkeys-random: 回收随机的键使得新添加的数据有空间存放。\n  volatile-random: 回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的键。\n  volatile-ttl: 回收在过期集合的键，并且优先回收存活时间（TTL）较短的键,使得新添加的数据有空间存放。\n如果没有键满足回收的前提条件的话，策略volatile-lru, volatile-random以及volatile-ttl就和noeviction 差不多了。\n  问题排查 arthas jdk自带命令 jps\njcmd\njstate\nhttps://docs.oracle.com/en/java/javase/11/tools/tools-and-command-reference.html\nKafka 消息队列的通信模式   点对点模式\n点对点模式通常是基于拉取或者轮询的消息传送模型，生产者将消息发送到队列中，消费者主动去拿消息。点对点模型的的优点是消费者拉取消息的频率可以由自己控制。但是消息队列是否有消息需要消费，在消费者端无法感知，所以在消费者端需要额外的线程去监控。\n  发布订阅模式\n发布订阅模式是一个基于消息送的消息传送模型，改模型可以有多种不同的订阅者。生产者将消息放入消息队列后，队列会将消息推送给订阅过该类消息的消费者（类似微信公众号）。由于是消费者被动接收推送，所以无需感知消息队列是否有待消费的消息！但是consumer1、consumer2、consumer3由于机器性能不一样，所以处理消息的能力也会不一样，但消息队列却无法感知消费者消费的速度！所以推送的速度成了发布订阅模模式的一个问题！假设三个消费者处理速度分别是8M/s、5M/s、2M/s，如果队列推送的速度为5M/s，则consumer3无法承受！如果队列推送的速度为2M/s，则consumer1、consumer2会出现资源的极大浪费！\n  Kafka架构   Producer：Producer即生产者，消息的产生者，是消息的入口。\nkafka cluster：\nBroker：Broker是kafka实例，每个服务器上有一个或多个kafka的实例，我们姑且认为每个broker对应一台服务器。每个kafka集群内的broker都有一个不重复的编号，如图中的broker-0、broker-1等……\nTopic：消息的主题，可以理解为消息的分类，kafka的数据就保存在topic。在每个broker上都可以创建多个topic。\nPartition：Topic的分区，每个topic可以有多个分区，分区的作用是做负载，提高kafka的吞吐量。同一个topic在不同的分区的数据是不重复的，partition的表现形式就是一个一个的文件夹！\nReplication:每一个分区都有多个副本，副本的作用是做备胎。当主分区（Leader）故障的时候会选择一个备胎（Follower）上位，成为Leader。在kafka中默认副本的最大数量是10个，且副本的数量不能大于Broker的数量，follower和leader绝对是在不同的机器，同一机器对同一个分区也只可能存放一个副本（包括自己）。\nMessage：每一条发送的消息主体。\nConsumer：消费者，即消息的消费方，是消息的出口。\nConsumer Group：我们可以将多个消费组组成一个消费者组，在kafka的设计中同一个分区的数据只能被消费者组中的某一个消费者消费。同一个消费者组的消费者可以消费同一个topic的不同分区的数据，这也是为了提高kafka的吞吐量！\nZookeeper：kafka集群依赖zookeeper来保存集群的的元信息，来保证系统的可用性。\n  为什么要用消息队列 解耦、异步、削丰\nKafka的推还是拉 拉\nKafka如何做到消息不丢失的 消息丢失有如下场景\n  producer发送给broker\n会出现，producer发给broker没收到，broker收到了还没同步给其他broker就挂了，broker持久化的时候，走磁盘缓存挂了\n不想丢数据，那就使用带有callback的api，设置 acks、retries、factor等等些参数来保证Producer发送的消息不会丢就好啦。\n  客户端消费broker丢了\n首先，要想client端消费数据不能丢，肯定是不能使用autoCommit的，所以必须是手动提交的\n  生产者保证消息发送到集群\n 使用带有回调方法（callback）的api，并设置好参数acks和retries和retry.backoff.ms这几个参数 acks参数表示如何判断系统认为消息发送成功。0，只要发过去就行了，1broker的leader收到就行了，-1，副本要同步完毕才算成功\nretries参数表示生产者生产消息的重试次数。 retry.backoff.ms参数表示消息生产超时失败后重试的间隔时间。 通过回调函数，我们可以知道消息是否发送成功。如果发送失败，我们需要进行异常处理。 比如把失败消息存入本地磁盘或者远程数据库，等服务正常了再发送。这样才能保证消息不丢失。\n   Kafka为什么可以有这么大的吞吐量 消息队列「最核心」的功能就是把生产的数据存储起来，然后给各个业务把数据再读取出来。\nKafka在「存储」和「读取」这个过程中又做了很多的优化\n 我们往一个Topic发送消息或者读取消息时，实际内部是多个Partition在处理【并行】 在存储消息时，Kafka内部是顺序写磁盘的，并且利用了操作系统的缓冲区来提高性能【append+cache】 在读写数据中也减少CPU拷贝文件的次数【零拷贝】  Kafka怎么保证顺序消费 kafka 的分布式单位是 partition，同一个 partition 中的数据可以保证 FIFO。不同的 partition 之间不能保证顺序。每个partition 只能够有一个消费者消费。因为在发送数据的时候，绝大多数用户都可以通过 message key 来定义，同一个 key 的 message 都会发送到同一个 partition 上面，所以一般不会有问题。\nkafka怎么保证不重复消费的 消费方进行做去重表\nMySql 推荐文章\n https://www.cnblogs.com/lianzhilei/p/11250589.html https://mp.weixin.qq.com/s/BFuA-59Fpue2r6dt8YBbrQ  一条语句的执行过程  客户端请求 连接器（验证用户身份，给予权限） 查询缓存（存在缓存则直接返回，不存在则执行后续操作） 分析器（对SQL进行词法分析和语法分析操作） 优化器（主要对执行的sql优化选择最优的执行方案方法） 执行器（执行时会先看用户是否有执行权限，有才去使用这个引擎提供的接口） 去引擎层获取数据返回（如果开启查询缓存则会缓存查询结果）  常见的存储引擎 使用哪一种引擎可以灵活选择，一个数据库中多个表可以使用不同引擎以满足各种性能和实际需求，使用合适的存储引擎，将会提高整个数据库的性能 。\nMysql的Data目录下都会存放每个表的元数据信息，包括表的定义与数据库引擎没有关系，文件为**.frm**结尾，例如user.frm存放的是user表的元数据信息\n InnoDB  .frm文件：与表相关的元数据信息都存放在frm文件，包括表结构的定义信息等 .MYD (MYData) 文件：MyISAM 存储引擎专用，用于存储MyISAM 表的数据 .MYI (MYIndex)文件：MyISAM 存储引擎专用，用于存储MyISAM 表的索引相关信息   MyISAM  .frm 文件：与表相关的元数据信息都存放在frm文件，包括表结构的定义信息等 .ibd 文件或 .ibdata 文件：这两种文件都是存放 InnoDB 数据的文件，之所以有两种文件形式存放 InnoDB 的数据，是因为 InnoDB 的数据存储方式能够通过配置来决定是使用共享表空间存放存储数据，还是用独享表空间存放存储数据。   对比  InnoDB 支持事务，MyISAM 不支持事务。这是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一； InnoDB 支持外键，而 MyISAM 不支持。对一个包含外键的 InnoDB 表转为 MYISAM 会失败； InnoDB 是聚簇索引，MyISAM 是非聚簇索引。聚簇索引的文件存放在主键索引的叶子节点上，因此 InnoDB 必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。而 MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。 InnoDB 不保存表的具体行数，执行select count(*) from table 时需要全表扫描。而 MyISAM 用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快； InnoDB 最小的锁粒度是行锁，MyISAM 最小的锁粒度是表锁。一个更新语句会锁住整张表，导致其他查询和更新都会被阻塞，因此并发访问受限。这也是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一；       对比项 MyISAM InnoDB     主外键 不支持 支持   事务 不支持 支持   行表锁 表锁，即使操作一条记录也会锁住整个表，不适合高并发的操作 行锁,操作时只锁某一行，不对其它行有影响，适合高并发的操作   缓存 只缓存索引，不缓存真实数据 不仅缓存索引还要缓存真实数据，对内存要求较高，而且内存大小对性能有决定性的影响   表空间 小 大   关注点 性能 事务   默认安装 是 是    一张表，里面有ID自增主键，当insert了17条记录之后，删除了第15,16,17条记录，再把Mysql重启，再insert一条记录，这条记录的ID是18还是15 ？ 如果表的类型是MyISAM，那么是18。因为MyISAM表会把自增主键的最大ID 记录到数据文件中，重启MySQL自增主键的最大ID也不会丢失；\n如果表的类型是InnoDB，那么是15。因为InnoDB 表只是把自增主键的最大ID记录到内存中，所以重启数据库或对表进行OPTION操作，都会导致最大ID丢失。\n自增主键用完了怎么办 会报重复主键错误，2亿了，早就开始分库分表了\nmysql的索引数据结构为什么用B+树，讲一讲mysql索引的数据结构是什么样的   索引是帮助mysql更快获得数据的一种数据结构\n  索引分类\n数据结构角度\n B+树索引 Hash索引 Full-Text全文索引  从物理存储角度\n  根据数据与索引的存储关联性，可以分为聚簇索引和非聚簇索引（也叫聚集索引和非聚集索引）。聚簇索引也叫簇类索引，是一种对磁盘上实际数据重新组织以按指定的一个或多个列的值排序。整个简洁的说法，这俩的区别就是索引的存储顺序和数据的存储顺序是否是关系的，有关就是聚簇索引，无关就是非聚簇索引。具体实现方式根据索引的数据结构不同会有所不同。下面以B+树实现的索引为例，举例来说明聚簇索引和非聚簇索引。\n  聚集索引（clustered index）,InnoDb 的主键索引就是聚集索引\n  非聚集索引（non-clustered index），也叫辅助索引（secondary index），也叫二级索引\n如果不是主键索引，则就可以称之为非主键索引，又可以称之为辅助索引或者二级索引。主键索引的叶子节点存储了完整的数据行，而非主键索引的叶子节点存储的则是主键索引值，通过非主键索引查询数据时，会先查找到主键索引，然后再到主键索引上去查找对应的数据。\n 在这里假设我们有张表user，具有三列：ID，age，name，create_time，id是主键，（age，create_time,，name）建立辅助索引。执行如下sql语句：\nselect name from user where age\u0026gt;2 order by create_time desc。\n正常的话，查询分两步：\n1.按照辅助索引，查找到记录的主键，\n2.按照主键主键索引里查找记录，返回name。\n但实际上，我们可以看到，辅助索引节点是按照age，create_time，name建立的，索引信息里完全包含我们所要的信息，如果能从辅助索引里返回name信息，则第二步是完全没有必要的，可以极大提升查询速度。\n按照这种思想Innodb里针对使用辅助索引的查询场景做了优化，叫覆盖索引\n 聚集索引和非聚集索引都是B+树结构\n  从逻辑角度\n  主键索引：主键索引是一种特殊的唯一索引，不允许有空值\nMySQL中是根据主键来组织数据的，所以每张表都必须有主键索引，主键索引只能有一个，不能为null同时必须保证唯一性。建表时如果没有指定主键索引，则会自动生成一个隐藏的字段作为主键索引。\n  普通索引或者单列索引：每个索引只包含单个列，一个表可以有多个单列索引\n  多列索引（复合索引、联合索引）：复合索引指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用复合索引时遵循最左前缀集合\n  唯一索引或者非唯一索引\n  空间索引：空间索引是对空间数据类型的字段建立的索引，MYSQL中的空间数据类型有4种，分别是GEOMETRY、POINT、LINESTRING、POLYGON。MYSQL使用SPATIAL关键字进行扩展，使得能够用于创建正规索引类型的语法创建空间索引。创建空间索引的列，必须将其声明为NOT NULL，空间索引只能在存储引擎为MYISAM的表中创建\n    B-树和B+树\n  B-树\nB-树就是平时说的B树，和二叉树的区别在于，可以存在多个子树。从而达到深度低的效果。通常用于操作系统的文件查询，因为一次深度就是一次磁盘的IO。B-树的节点，除了子节点的指针信息，和索引信息(主键)，还存放了数据\n  B+树\nB+Tree 是在 B-Tree 基础上的一种优化，使其更适合实现外存储索引结构，InnoDB 存储引擎就是用 B+Tree 实现其索引结构。\n从上一节中的B-Tree结构图中可以看到每个节点中不仅包含数据的key值，还有data值。而每一个页的存储空间是有限的，如果data数据较大时将会导致每个节点（即一个页）能存储的key的数量很小，当存储的数据量很大时同样会导致B-Tree的深度较大，增大查询时的磁盘I/O次数，进而影响查询效率。在B+Tree中，所有数据记录节点都是按照键值大小顺序存放在同一层的叶子节点上，而非叶子节点上只存储key值信息，这样可以大大加大每个节点存储的key值数量，降低B+Tree的高度。\n    正因为InnoDB的数据和聚集索引是存放在一起的，所以默认建表的时候推荐创建主键索引，如果没有建立的话，mysql会自动创建一个隐藏的列作为主键并且这个字段长度为6个字节，类型为整型。\n最左匹配原则是什么 B+Tree性质\n 通过上面的分析，我们知道IO次数取决于b+数的高度h，假设当前数据表的数据为N，每个磁盘块的数据项的数量是m，则有h=㏒(m+1)N，当数据量N一定的情况下，m越大，h越小；而m = 磁盘块的大小 / 数据项的大小，磁盘块的大小也就是一个数据页的大小，是固定的，如果数据项占的空间越小，数据项的数量越多，树的高度越低。这就是为什么每个数据项，即索引字段要尽量的小，比如int占4字节，要比bigint8字节少一半。这也是为什么b+树要求把真实的数据放到叶子节点而不是内层节点，一旦放到内层节点，磁盘块的数据项会大幅度下降，导致树增高。当数据项等于1时将会退化成线性表。 当b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+数是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道下一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。比如当(张三,F)这样的数据来检索时，b+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了， 这个是非常重要的性质，即索引的最左匹配特性。  Explain Explain + SQL语句即可,如下:\nexplain select * from tbl_dept;  1执行结果如下:  **\nEXPLAIN结果参数含义\n1.id: id代表执行select子句或操作表的顺序,例如,上述的执行结果代表只有一次执行而且执行顺序是第一(因为只有一个id为1的执行结果),id分别有三种不同的执行结果,分别如下:\n id相同,执行顺序由上至下  \n id不同,如果是子查询,id的序号会递增,id值越大,优先级越高,越先被执行  \n id相同和不同,同时存在,遵从优先级高的优先执行,优先级相同的按照由上至下的顺序执行  \n2.select_type 查询的类型,主要用于区别普通查询,联合查询,子查询等复杂查询\n simple: 简单的select查询,查询中不包含子查询或union查询 primary: 查询中若包含任何复杂的子部分,最外层查询则被标记为primary subquery 在select 或where 列表中包含了子查询 derived 在from列表中包含的子查询被标记为derived,mysql会递归这些子查询,把结果放在临时表里 union 做第二个select出现在union之后,则被标记为union,若union包含在from子句的子查询中,外层select将被标记为derived union result 从union表获取结果的select  3.table 显示一行的数据时关于哪张表的 4.type 查询类型从最好到最差依次是:system\u0026gt;const\u0026gt;eq_ref\u0026gt;ref\u0026gt;range\u0026gt;index\u0026gt;All,一般情况下,得至少保证达到range级别,最好能达到ref\n system:表只有一行记录,这是const类型的特例,平时不会出现 const:表示通过索引一次就找到了,const即常量,它用于比较primary key或unique索引,因为只匹配一行数据,所以效率很快,如将主键置于where条件中,mysql就能将该查询转换为一个常量  \n eq_ref:唯一性索引扫描,对于每个索引键,表中只有一条记录与之匹配,常见于主键或唯一索引扫描 ref:非唯一性索引扫描,返回匹配某个单独值的行,它可能会找到多个符合条件的行,所以他应该属于查找和扫描的混合体 range:只检索给定范围的行,使用一个索引来选择行,如where语句中出现了between,\u0026lt;,\u0026gt;,in等查询,这种范围扫描索引比全表扫描要好，因为它只需要开始于索引的某一点，而结束于另一点，不用扫描全部索引。 index:index类型只遍历索引树,这通常比All快,因为索引文件通常比数据文件小,index是从索引中读取,all从硬盘中读取 all:全表扫描,是最差的一种查询类型  5.possible_keys 显示可能应用在这张表中的索引,一个或多个,查询到的索引不一定是真正被用到的\n6.key 实际使用的索引,如果为null,则没有使用索引,因此会出现possible_keys列有可能被用到的索引,但是key列为null,表示实际没用索引。\n7.key_len 表示索引中使用的字节数,而通过该列计算查询中使用的 索引长度,在不损失精确性的情况下,长度越短越好,key_len显示的值为索引字段的最大可能长度,并非实际使用长度,即,key_len是根据表定义计算而得么不是通过表内检索出的\n8.ref 显示索引的哪一列被使用了,如果可能的话是一个常数,哪些列或常量被用于查找索引列上的值\n9.rows 根据表统计信息及索引选用情况,大只估算出找到所需的记录所需要读取的行数\n10.Extra\n Using filesort:说明mysql会对数据使用一个外部的索引排序,而不是按照表内的索引顺序进行读取,mysql中无法利用索引完成的排序操作称为\u0026quot;文件排序\u0026quot; Using temporary :使用了临时表保存中间结果,mysql在对查询结果排序时使用临时表,常见于order by和分组查询group by Using index:表示相应的select操作中使用了覆盖索引（Covering Index），避免访问了表的数据行，效率不错。如果同时出现using where，表明索引被用来执行索引键值的查找；如果没有同时出现using where，表明索引用来读取数据而非执行查找动作。 其中的覆盖索引含义是所查询的列是和建立的索引字段和个数是一一对应的 Using where:表明使用了where过滤 Using join buffer:表明使用了连接缓存,如在查询的时候会有多次join,则可能会产生临时表 impossible where:表示where子句的值总是false,不能用来获取任何元祖。如下例：  select * from t1 where id='1' and id='2';  select tables optimized away  在没有GROUPBY子句的情况下，基于索引优化MIN/MAX操作或者对于MyISAM存储引擎优化COUNT(*)操作，不必等到执行阶段再进行计算，查询执行计划生成的阶段即完成优化。\n distinct：优化distinct操作，在找到第一匹配的元组后即停止找同样值的动作，即一旦MySQL找到了与行相联合匹配的行，就不再搜索了。  重点：\n　type：访问类型，查看SQL到底是以何种类型访问数据的。\n　key：使用的索引，MySQL用了哪个索引，有时候MySQL用的索引不是最好的，需要force index()。\n　rows：最大扫描的列数。\n　extra：重要的额外信息，特别注意损耗性能的两个情况，using filesort和using temporary。\n说出你如何调优的 直接explain\n常见的优化手段  使用覆盖索引解决回表，提高查询效率 使用explain检查sql语句执行的情况 where语句时，字段类型一定要一直，否则索引失效 使用函数索引不走 OR导致索引是在特定情况下的，并不是所有的OR都是使索引失效，如果OR连接的是同一个字段，那么索引不会失效，反之索引失效。 模糊匹配，like 中%不能写在前面 IS NULL走索引，IS NOT NULL走索引 开启慢日志，查看哪些sql执行太慢  MVVC MySQL的大多数事务型存储引擎实现都不是简单的行级锁。基于提升并发性考虑，一般都同时实现了多版本并发控制（MVCC），包括Oracle、PostgreSQL。只是实现机制各不相同。\n可以认为 MVCC 是行级锁的一个变种，但它在很多情况下避免了加锁操作，因此开销更低。虽然实现机制有所不同，但大都实现了非阻塞的读操作，写操作也只是锁定必要的行。\nMVCC 的实现是通过保存数据在某个时间点的快照来实现的。也就是说不管需要执行多长时间，每个事物看到的数据都是一致的。\n典型的MVCC实现方式，分为乐观（optimistic）并发控制和悲观（pressimistic）并发控制。下边通过 InnoDB的简化版行为来说明 MVCC 是如何工作的。\nInnoDB 的 MVCC，是通过在每行记录后面保存两个隐藏的列来实现。这两个列，一个保存了行的创建时间，一个保存行的过期时间（删除时间）。当然存储的并不是真实的时间，而是系统版本号（system version number）。每开始一个新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询到的每行记录的版本号进行比较。\nREPEATABLE READ（可重读）隔离级别下MVCC如何工作：\n  SELECT\nInnoDB会根据以下两个条件检查每行记录：\n只有符合上述两个条件的才会被查询出来\n   InnoDB只查找版本早于当前事务版本的数据行，这样可以确保事务读取的行，要么是在开始事务之前已经存在要么是事务自身插入或者修改过的 行的删除版本号要么未定义，要么大于当前事务版本号，这样可以确保事务读取到的行在事务开始之前未被删除    INSERT：InnoDB为新插入的每一行保存当前系统版本号作为行版本号\n  DELETE：InnoDB为删除的每一行保存当前系统版本号作为行删除标识\n  UPDATE：InnoDB为插入的一行新纪录保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为删除标识\n  保存这两个额外系统版本号，使大多数操作都不用加锁。使数据操作简单，性能很好，并且也能保证只会读取到符合要求的行。不足之处是每行记录都需要额外的存储空间，需要做更多的行检查工作和一些额外的维护工作。\nMVCC 只在 COMMITTED READ（读提交）和REPEATABLE READ（可重复读）两种隔离级别下工作。\n事务特性，隔离级别，怎么解决幻读？ 特性：ACID\n  原子性\n整个事务要么全部执行，要么全部不执行，不会停在中间。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样\n  一致性\n一致性，这个是大家误解最深的，很多博客都喜欢用银行转账的例子来讲一直性，所谓的一致性是基于原子性。\n原子性只保证了一个事物内的所有操作同一性，大家同生死，不会出现你死了，我还活着。但是，原子性并没有保证大家同一时刻一起生，一起死。计算机指令是有先后顺序的，这样就决定了一个事物的提交，会经历一个时间过程，那么如果事物提交进行到了一半，我读取了数据库，会不会读到中间结果？\n为了防止这样的情况，数据库事物的一致性就规定了事物提交前后，永远只可能存在事物提交前的状态和事物提交后的状态，从一个一致性的状态到另一个一致性状态，而不可能出现中间的过程态。也就是说事物的执行结果是量子化状态，而不是线性状态。\n数据库提交事物会有一个过程，如果提交的时候，存在一个时间差，在提交的第一秒，一个删除过程还没完成到了第三秒才完成，会不会第一秒访问的人和第三秒访问的人得到不同的结果？出现不一致，状态的混沌？这就是一致性得保证的只会有前状态和后状态，绝不会出现中间态。\n  隔离性\n一个事务的执行不能其它事务干扰。即一个事务内部的操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务之间不能互相干扰\n  持久性\n在事务完成以后，该事务所对数据库所作的更改便持久的保存在数据库之中，并不会被回滚\n  隔离级别：\n  读未提交\n脏读，事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据\n  读已提交\n不可重复读，一个事务读2次，2次读的结果不一样，务 A 多次读取同一数据，事务B在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果不一致。\n  可重复读\n会造成幻读\n 幻读是事务非独立执行时发生的一种现象。例如事务T1对一个表中所有的行的某个数据项做了从“1”修改为“2”的操作，这时事务T2又对这个表中插入了一行数据项，而这个数据项的数值还是为“1”并且提交给数据库。而操作事务T1的用户如果再查看刚刚修改的数据，会发现还有一行没有修改，其实这行是从事务T2中添加的，就好像产生幻觉一样，这就是发生了幻读。 幻读和不可重复读都是读取了另一条已经提交的事务（这点就脏读不同），所不同的是不可重复读查询的都是同一个数据项，而幻读针对的是一批数据整体（比如数据的个数）。\n   SERIALIZABLE(可串行化)： 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。\n  如何解决幻读\nmysql使用了间隙锁和记录锁来解决的，间隙锁就是对一段区域的记录都锁定\n所以，Innodb 引擎为了解决「可重复读」隔离级别使用「当前读」而造成的幻读问题，就引出了 next-key 锁，就是记录锁和间隙锁的组合。\n 记录锁，锁的是记录本身； 间隙锁，锁的就是两个值之间的空隙，以防止其他事务在这个空隙间插入新的数据，从而避免幻读现象。  参考\n  三范式  第一范式：列不能再拆分了 第二范式：每一条数据必须能够被区分，主键存在，而且能保证唯一 第三范式：不要有冗余 反范式：冗余一些字段，避免查询  为什么要分库分表，有什么方案 分库\n 垂直分库，每个业务有自己单独的库  分表\n 垂直分表：单表分成多表，扩展开来 水平分表：数据分开来，例如用户表，通过id分为user-10000,user-20000，通过hash，让数据散列到不同的库不同表，不至于单库压力大  缺点：\n 分布式事务：Seata 连表查询：尽量避免，实在不行只能分开查询，再汇总 分页排序等：查完内存分页排序 分布式ID，唯一主键：雪花算法  什么是回表 指非聚集索引在查找数据的时候，会先查找到聚集索引，再通过聚集索引找到最终的数据。这就是回表\nMySQL覆盖索引 覆盖索引（Covering Index）,或者叫索引覆盖， 也就是平时所说的不需要回表操作\n  就是select的数据列只用从索引中就能够取得，不必读取数据行，MySQL可以利用索引返回select列表中的字段，而不必根据索引再次读取数据文件，换句话说查询列要被所建的索引覆盖。\n  索引是高效找到行的一个方法，但是一般数据库也能使用索引找到一个列的数据，因此它不必读取整个行。毕竟索引叶子节点存储了它们索引的数据，当能通过读取索引就可以得到想要的数据，那就不需要读取行了。一个索引包含（覆盖）满足查询结果的数据就叫做覆盖索引。\n  判断标准\n使用explain，可以通过输出的extra列来判断，对于一个索引覆盖查询，显示为using index，MySQL查询优化器在执行查询前会决定是否有索引覆盖查询\n  为什么非主键索引结构叶子节点存储的是主键值？  保证数据一致性和节省存储空间，可以这么理解：商城系统订单表会存储一个用户ID作为关联外键，而不推荐存储完整的用户信息，因为当我们用户表中的信息（真实名称、手机号、收货地址···）修改后，不需要再次维护订单表的用户数据，同时也节省了存储空间\n 为什么Mysql索引要用B+树不是B树？  用B+树不用B树考虑的是IO对性能的影响，B树的每个节点都存储数据，而B+树只有叶子节点才存储数据，所以查找相同数据量的情况下，B树的高度更高，IO更频繁。数据库索引是存储在磁盘上的，当数据量大时，就不能把整个索引全部加载到内存了，只能逐一加载每一个磁盘页（对应索引树的节点）。其中在MySQL底层对B+树进行进一步优化：在叶子节点中是双向链表，且在链表的头结点和尾节点也是循环指向的。\n 为何不采用Hash创建索引方式？  因为Hash索引底层是哈希表，哈希表是一种以key-value存储数据的结构，所以多个数据在存储关系上是完全没有任何顺序关系的，所以，对于区间查询是无法直接通过索引查询的，就需要全表扫描。所以，哈希索引只适用于等值查询的场景。而B+ Tree是一种多路平衡查询树，所以他的节点是天然有序的（左子节点小于父节点、父节点小于右子节点），所以对于范围查询的时候不需要做全表扫描。\n哈希索引不支持多列联合索引的最左匹配规则，如果有大量重复键值得情况下，哈希索引的效率会很低，因为存在哈希碰撞问题。\n 什么时候需要建立索引，什么时候不需要建立索引  创建索引\n 主键自动建立唯一索引 频繁作为查询条件的字段 查询中与其他表关联的字段，外键关系建立索引 单键/组合索引的选择问题，高并发下倾向创建组合索引 查询中排序的字段，排序字段通过索引访问大幅提高排序速度 查询中统计或分组字段  不建立索引\n 表记录太少 经常增删改的表 数据重复且分布均匀的表字段，只应该为最经常查询和最经常排序的数据列建立索引（如果某个数据类包含太多的重复数据，建立索引没有太大意义） 频繁更新的字段不适合创建索引（会加重IO负担） where条件里用不到的字段不创建索引   数据库建立索引常用的规则如下：  表的主键、外键必须有索引； 数据量超过300的表应该有索引； 经常与其他表进行连接的表，在连接字段上应该建立索引； 经常出现在Where子句中的字段，特别是大表的字段，应该建立索引； 索引应该建在选择性高的字段上； 索引应该建在小字段上，对于大的文本字段甚至超长字段，不要建索引； 复合索引的建立需要进行仔细分析；尽量考虑用单字段索引代替：    正确选择复合索引中的主列字段，一般是选择性较好的字段； 复合索引的几个字段是否经常同时以AND方式出现在Where子句中？单字段查询是否极少甚至没有？如果是，则可以建立复合索引；否则考虑单字段索引； 如果复合索引中包含的字段经常单独出现在Where子句中，则分解为多个单字段索引； 如果既有单字段索引，又有这几个字段上的复合索引，一般可以删除复合索引；    频繁进行数据操作的表，不要建立太多的索引； 删除无用的索引，避免对执行计划造成负面影响；  以上是一些普遍的建立索引时的判断依据。 索引的建立必须慎重，对每个索引的必要性都应该经过仔细分析，要有建立的依据。 因为太多的索引与不充分、不正确的索引对性能都毫无益处：在表上建立的每个索引都会增加存储开销，索引对于插入、删除、更新操作也会增加处理上的开销。 另外，过多的复合索引，在有单字段索引的情况下，一般都是没有存在价值的；相反，还会降低数据增加删除时的性能，特别是对频繁更新的表来说，负面影响更大。 总的来说，小型表肯定不建索引， 或者数据库记录在亿条数据级以上，还是建议使用非关系型数据库。 还有些特殊字段的数据库，比如BLOB，CLOB字段肯定也不适合建索引。 其实这个问题更感觉偏向于做软件项目的一种经验。\ncount(1)，count(*)，count(列名)  count(*)包括了所有的列，相当于行数，在统计结果的时候，不会忽略列值为NULL count(1)包括了所有列，用1代表代码行，在统计结果的时候，不会忽略列值为NULL count(列名)只包括列名那一列，在统计结果的时候，会忽略列值为空（这里的空不是只空字符串或者0，而是表示null）的计数，即某个字段值为NULL时，不统计。 执行效率上：  列名为主键，count(列名)会比count(1)快 列名不为主键，count(1)会比count(列名)快 如果表多个列并且没有主键，则 count(1) 的执行效率优于 count(*) 如果有主键，则 select count（主键）的执行效率是最优的 如果表只有一个字段，则 select count(*) 最优。    mysql单表一千万数据，怎么查最快   limit，offset\n在limit的偏移量越来越大的时候，数据则会越来越慢，花费的时间也会越来越长，使用子查询\n  Mybatis 讲一讲mybatis 的工作原理 Spring Spring的Bean注入过程讲一下 Spring中常见的设计模式说一说 Spring是怎么解决Bean之间的循环依赖问题 spring针对如果是非单例的bean直接会抛出异常。\n单例的bean是\nSpringMvc的流程 SpringBoot的启动原理 SpringCloud了解多少 AOP怎么实现的 @Configureable的作用 分布式 怎么保证幂等  唯一索引 悲观锁，加锁  CAP C (一致性):对某个指定的客户端来说，读操作能返回最新的写操作。对于数据分布在不同节点上的数据上来说，如果在某个节点更新了数据，那么在其他节点如果都能读取到这个最新的数据，那么就称为强一致，如果有某个节点没有读取到，那就是分布式不一致。\nA (可用性)：非故障的节点在合理的时间内返回合理的响应(不是错误和超时的响应)。可用性的两个关键一个是合理的时间，一个是合理的响应。合理的时间指的是请求不能无限被阻塞，应该在合理的时间给出返回。合理的响应指的是系统应该明确返回结果并且结果是正确的，这里的正确指的是比如应该返回50，而不是返回40。\nP (分区容错性):当出现网络分区后，系统能够继续工作。打个比方，这里个集群有多台机器，有台机器网络出现了问题，但是这个集群仍然可以正常工作。\nNacos怎么实现的AP和CP 在nacos中，CP与AP切换的条件是注册的服务实例是否是临时实例\n为什么要用dubbo，和SpringCloud的区别是什么 Dubbo由于是二进制的传输，占用带宽会更少。Spring Cloud 是 HTTP 协议传输，带宽占用会比较多，同时使用 HTTP 协议一般会使用 JSON 报文，消耗会更大。\nDubbo 的开发难度较大，原因是 Dubbo 的 jar 包依赖问题很多大型工程无法解决；Spring Cloud 的接口协议约定比较自由且松散，需要有强有力的行政措施来限制接口无序升级。\nDubbo 的注册中心可以选择 Zookeeper、Redis 等多种；Spring Cloud 的注册中心只能用 Eureka 或者自研\n分布式事务、分布式锁、分布式链路追踪解决方案   分布式锁  基于 MySQL 中的锁：MySQL 本身有自带的悲观锁 for update 关键字，也可以自己实现悲观/乐观锁来达到目的；\n  基于 Zookeeper 有序节点：Zookeeper 允许临时创建有序的子节点，这样客户端获取节点列表时，就能够当前子节点列表中的序号判断是否能够获得锁；\nzooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，它可以为分布式应用提供一致性服务，它是Hadoop和Hbase的重要组件，同时也可以作为配置中心、注册中心运用在微服务体系中。\n  基于 Redis 的单线程：由于 Redis 是单线程，所以命令会以串行的方式执行，并且本身提供了像 SETNX(set if not exists) 这样的指令，本身具有互斥性；\n  锁超时：如果某服务获取到锁，挂了，那么锁就永远得不到了。因此需要设置超时时间\n但是另一个问题随即而来：如果在加锁和释放锁之间的逻辑执行得太长，以至于超出了锁的超时限制，也会出现问题。因为这时候第一个线程持有锁过期了，而临界区的逻辑还没有执行完，与此同时第二个线程就提前拥有了这把锁，导致临界区的代码不能得到严格的串行执行。\n为了避免这个问题，Redis 分布式锁不要用于较长时间的任务。如果真的偶尔出现了问题，造成的数据小错乱可能就需要人工的干预。\n有一个稍微安全一点的方案是 将锁的 value 值设置为一个随机数，释放锁时先匹配随机数是否一致，然后再删除 key，这是为了 确保当前线程占有的锁不会被其他线程释放，除非这个锁是因为过期了而被服务器自动释放的。\n但是匹配 value 和删除 key 在 Redis 中并不是一个原子性的操作，也没有类似保证原子性的指令，所以可能需要使用像 Lua 这样的脚本来处理了，因为 Lua 脚本可以 保证多个指令的原子性执行。\n  RedLock：解决多节点redis时，发生获取锁后，主节点掉线，导致其他服务获取到了锁\n      分布式事务\n阿里的Seata\n  ES 为什么ES能查询的这么快 你了解多少ES，为什么选择用ES Zookeeper Zookeeper是干什么的，你使用过吗，用它做过什么事情吗 Java并发 讲一下伪共享 在计算机中，真正做计算的动作都是cpu核心。而与cpu交互最多的是内存。每次代码在执行的时候，变量都是存放在内存中的。但是内存的速度相对于CPU来说是相当慢的。因此在CPU和内存中间还有“高速缓存”，一般有3级，L1，L2，L3依此离CPU的距离变远。越近的容量越小，造价越高。其中L3是多核心共享的。\nCPU再计算的时候，会先从L1中找，找不到从L2中，再从L3中，最后才从主内存中加载。\n而高速缓存的单位通常是连续的64字节的一个“缓存行”。\n在程序运行的过程中，缓存每次更新都从主内存中加载连续的 64 个字节。因此，如果访问一个 long 类型的数组时，当数组中的一个值被加载到缓存中时，另外 7 个元素也会被加载到缓存中。\n但是，如果使用的数据结构中的项在内存中不是彼此相邻的，比如链表，那么将得不到免费缓存加载带来的好处。\n不过，这种免费加载也有一个坏处。设想如果我们有个 long 类型的变量 a，它不是数组的一部分，而是一个单独的变量，并且还有另外一个 long 类型的变量 b 紧挨着它，那么当加载 a 的时候将免费加载 b。\n看起来似乎没有什么毛病，但是如果一个 CPU 核心的线程在对 a 进行修改，另一个 CPU 核心的线程却在对 b 进行读取。\n当前者修改 a 时，会把 a 和 b 同时加载到前者核心的缓存行中，更新完 a 后其它所有包含 a 的缓存行都将失效，因为其它缓存中的 a 不是最新值了。\n而当后者读取 b 时，发现这个缓存行已经失效了，需要从主内存中重新加载。\n请记住，我们的缓存都是以缓存行作为一个单位来处理的，所以失效 a 的缓存的同时，也会把 b 失效，反之亦然。\n这样就出现了一个问题，b 和 a 完全不相干，每次却要因为 a 的更新需要从主内存重新读取，它被缓存未命中给拖慢了。\n这就是传说中的伪共享。\n你知道UnSafe类吗，为什么他是“UnSafe”的，它能做什么   UnSafe的获取方式\nField f = Unsafe.class.getDeclaredField(\u0026#34;theUnsafe\u0026#34;); f.setAccessible(true); Unsafe unsafe = (Unsafe) f.get(null);   可以做什么\n  实例化一个类\nUnsafe.allocateInstance()只会给对象分配内存，并不会调用构造方法\n  使用Unsafe的putXXX()方法，我们可以修改任意私有字段的值。\n    抛出check异常\n我们知道如果代码抛出了checked异常，要不就使用try\u0026hellip;catch捕获它，要不就在方法签名上定义这个异常，但是，通过Unsafe我们可以抛出一个checked异常，同时却不用捕获或在方法签名上定义它。\n// 使用正常方式抛出IOException需要定义在方法签名上往外抛 public static void readFile() throws IOException { throw new IOException(); } // 使用Unsafe抛出异常不需要定义在方法签名上往外抛 public static void readFileUnsafe() { unsafe.throwException(new IOException()); }   使用堆外内存\n如果进程在运行过程中JVM上的内存不足了，会导致频繁的进行GC。理想情况下，我们可以考虑使用堆外内存，这是一块不受JVM管理的内存。\n使用Unsafe的allocateMemory()我们可以直接在堆外分配内存，这可能非常有用，但我们要记住，这个内存不受JVM管理，因此我们要调用freeMemory()方法手动释放它。\n  CompareAndSwap操作\nJUC下面大量使用了CAS操作，它们的底层是调用的Unsafe的CompareAndSwapXXX()方法。这种方式广泛运用于无锁算法，与java中标准的悲观锁机制相比，它可以利用CAS处理器指令提供极大的加速。\n  park/unpark\nJVM在上下文切换的时候使用了Unsafe中的两个非常牛逼的方法park()和unpark()。\n当一个线程正在等待某个操作时，JVM调用Unsafe的park()方法来阻塞此线程。\n当阻塞中的线程需要再次运行时，JVM调用Unsafe的unpark()方法来唤醒此线程。\n我们之前在分析java中的集合时看到了大量的LockSupport.park()/unpark()，它们底层都是调用的Unsafe的这两个方法。\n  异步、同步；阻塞、非阻塞；线程、进程他们的关系   异步和同步\n同步与异步最大的区别就是被调用方的执行方式和返回时机，同步指的是被调用方做完事情之后再返回，异步指的是被调用方先返回，然后再做事情，做完之后再想办法通知调用方\n  阻塞和非阻塞\n阻塞就是发起一个请求，调用者一直等待请求结果返回，也就是当前线程会被挂起，无法从事其他任务，只有当条件就绪才能继续。\n非阻塞就是发起一个请求，调用者不用一直等着结果返回，可以先去干其他事情。\n   阻塞和同步不是一回事，同步，异步与阻塞，非阻塞针对的对象是不一样的，阻塞,非阻塞是说的调用者，同步，异步说的是被调用者\n 你知道哪几种锁   公平锁/非公平锁\n公平锁：按照线程的申请顺序获取锁\n非公平锁：不是按照申请的顺序，可能后申请的线程反而先获取到锁\nReentrantLock中可以通过构造方法指定是否为公平锁，默认为非公平锁，非公平锁的优点在于吞吐量大。\nsynchronized无法指定为公平锁，一直都是非公平锁。\n  可重入锁\n可重入锁，是指一个线程获取锁之后再尝试获取锁时会自动获取锁，可重入锁的优点是避免死锁。\n具体一点，就是一个线程获得锁之后，再次获得锁的时候，不需要释放锁。\nimport java.util.concurrent.atomic.AtomicReference; public class UnreentrantLock { private AtomicReference\u0026lt;Thread\u0026gt; owner = new AtomicReference\u0026lt;Thread\u0026gt;(); public void lock() { Thread current = Thread.currentThread(); //这句是很经典的“自旋”语法，AtomicInteger中也有  for (;;) { if (!owner.compareAndSet(null, current)) { return; } } } public void unlock() { Thread current = Thread.currentThread(); owner.compareAndSet(current, null); } } 代码也比较简单，使用原子引用来存放线程，同一线程两次调用lock()方法，如果不执行unlock()释放锁的话，第二次调用自旋的时候就会产生死锁，这个锁就不是可重入的，而实际上同一个线程不必每次都去释放锁再来获取锁，这样的调度切换是很耗资源的。稍微改一下，把它变成一个可重入锁：\nimport java.util.concurrent.atomic.AtomicReference; public class UnreentrantLock { private AtomicReference\u0026lt;Thread\u0026gt; owner = new AtomicReference\u0026lt;Thread\u0026gt;(); private int state = 0; public void lock() { Thread current = Thread.currentThread(); if (current == owner.get()) { state++; return; } //这句是很经典的“自旋”式语法，AtomicInteger中也有  for (;;) { if (!owner.compareAndSet(null, current)) { return; } } } public void unlock() { Thread current = Thread.currentThread(); if (current == owner.get()) { if (state != 0) { state--; } else { owner.compareAndSet(current, null); } } } } ReentrantLock和synchronized都是可重入锁。\nsynchronized是在对象头中做了计数器，monitorenter的时候，计数器+1，monitorexit的时候，计数器-1。来达到重入锁的目的。\nReentrantLock底层用的AQS，AQS中有一个state变量，获取锁成功后，会+1，用来解决重入锁的问题\n  独占锁/共享锁\n独占锁：锁一次只能被一个线程占有\n共享锁：锁可以被多个线程占有\nReentrantLock和synchronized都是独享锁，ReadWriteLock的读锁是共享锁，写锁是独享锁。\n  互斥锁/读写锁\n与独享锁/共享锁的概念差不多，是独享锁/共享锁的具体实现。\nReentrantLock和synchronized都是互斥锁\nReadWriteLock是读写锁\n  乐观锁/悲观锁\n悲观锁，是指认为对于同一个数据的并发操作必然会发生修改，即使不会发生修改也这么认为，所以一定要加锁。\n乐观锁，是指认为对于同一个数据的并发操作不一定会发生修改，在更新数据的时候，尝试去更新数据，如果失败就不断尝试。\n悲观锁适用于写操作多的场景，乐观锁适用于读操作多的场景。\n  分段锁\n分段锁，是一种锁的设计思路，它细化了锁的粒度，主要运用在ConcurrentHashMap中，实现高效的并发操作，当操作不需要更新整个数组时，就只锁数组中的一项就可以了。\n  偏向锁/轻量级锁/重量级锁\n这三种锁，都是针对于Synchronized关键字进行优化的，主要通过对象监视器在对象头中的字段来表明的\n  偏向锁\n当同一段同步代码一直被一个线程访问，那么这个线程会自动获取锁，降低获取锁的代价\n  轻量级锁\n当前的锁如果是偏向锁的话，如果被另一个线程访问中，就是持有中。偏向锁会升级为轻量级锁，这个线程会通过自旋的方式不断的尝试获取锁\n  重量级锁\n当前锁是轻量级锁的情况下，当自旋的线程自旋了一定程度后，还没有获得到锁的话，就会进入阻塞状态，该锁会升级为重量级锁，重量级锁会让其他线程进入阻塞状态，性能降低\n    自旋锁\n通过不断尝试获取锁，通过减少上下文切换带来的开锁消耗。提高性能，缺点是循环会消耗CPU\n  监视器锁\nsynchronized的实现方式，使用monitorenter和monitorexit来实现\n  mutex锁\n互斥锁，LockSupport.part()底层通过mutex实现的\n  自己实现一个锁 /** * 实现一个锁 * * 思路：通过定义一个变量，让多个线程去修改他，通过CAS操作，如果没有操作成功的，则进入队列 * */ public class MyLock { //定义一个状态变量，通过volatile关键字修饰,让每个线程都能看到  private volatile int state; private static long stateOffset; private static long tailOffset; //UnSafe类  private static Unsafe unsafe; private static class Node { // 存储的元素为线程  Thread thread; // 前一个节点（可以没有，但实现起来很困难）  Node prev; // 后一个节点  Node next; public Node() { } public Node(Thread thread, Node prev) { this.thread = thread; this.prev = prev; } } // 链表头  private volatile Node head; // 链表尾  private volatile Node tail; static { Field f = null; try { f = Unsafe.class.getDeclaredField(\u0026#34;theUnsafe\u0026#34;); f.setAccessible(true); unsafe = (Unsafe) f.get(null); // 获取state的偏移量  stateOffset = unsafe.objectFieldOffset(MyLock.class.getDeclaredField(\u0026#34;state\u0026#34;)); // 获取tail的偏移量  tailOffset = unsafe.objectFieldOffset(MyLock.class.getDeclaredField(\u0026#34;tail\u0026#34;)); } catch (NoSuchFieldException | IllegalAccessException e) { e.printStackTrace(); } } // 原子更新tail字段  private boolean compareAndSetTail(Node expect, Node update) { return unsafe.compareAndSwapObject(this, tailOffset, expect, update); } /** * cas更新state * @param expect * @param update * @return */ private boolean compareAndSetState(int expect, int update) { return unsafe.compareAndSwapInt(this, stateOffset, expect, update); } private Node empty = new Node(); public MyLock() { this.head=this.tail=empty; } public void lock() { // 尝试更新state字段，更新成功说明占有了锁  if (compareAndSetState(0, 1)) { return; } // 未更新成功则入队  Node node = enqueue(); Node prev = node.prev; // 再次尝试获取锁，需要检测上一个节点是不是head，检查是不是下一个应该的，按入队顺序加锁  while (node.prev != head || !compareAndSetState(0, 1)) { // 未获取到锁，阻塞  unsafe.park(false, 0L); } // 下面不需要原子更新，因为同时只有一个线程访问到这里  // 获取到锁了且上一个节点是head  // head后移一位  head = node; // 清空当前节点的内容，协助GC  node.thread = null; // 将上一个节点从链表中剔除，协助GC  node.prev = null; prev.next = null; } // 入队  private Node enqueue() { while (true) { // 获取尾节点  Node t = tail; // 构造新节点  Node node = new Node(Thread.currentThread(), t); // 不断尝试原子更新尾节点  if (compareAndSetTail(t, node)) { // 更新尾节点成功了，让原尾节点的next指针指向当前节点  t.next = node; return node; } } } // 解锁  public void unlock() { // 把state更新成0，这里不需要原子更新，因为同时只有一个线程访问到这里  state = 0; // 下一个待唤醒的节点  Node next = head.next; // 下一个节点不为空，就唤醒它  if (next != null) { unsafe.unpark(next.thread); } } public static int count; public static void main(String[] args) throws InterruptedException { MyLock lock = new MyLock(); CountDownLatch countDownLatch = new CountDownLatch(1000); IntStream.range(0, 1000).forEach(i -\u0026gt; new Thread(() -\u0026gt; { lock.lock(); try { IntStream.range(0, 10000).forEach(j -\u0026gt; { count++; }); } finally { lock.unlock(); } // System.out.println(Thread.currentThread().getName());  countDownLatch.countDown(); }, \u0026#34;tt-\u0026#34; + i).start()); countDownLatch.await(); System.out.println(count); } } 讲一下线程的生命周期 java.lang.Thread.State中定义了线程的状态\npublic enum State { /** * Thread state for a thread which has not yet started. */ //新建状态,线程还未开始  NEW, /** * Thread state for a runnable thread. A thread in the runnable * state is executing in the Java virtual machine but it may * be waiting for other resources from the operating system * such as processor. */ //可以运行状态，已经在jvm虚拟机中了，正在等待操作系统分配资源  RUNNABLE, /** * Thread state for a thread blocked waiting for a monitor lock. * A thread in the blocked state is waiting for a monitor lock * to enter a synchronized block/method or * reenter a synchronized block/method after calling * {@link Object#wait() Object.wait}. */ //阻塞状态，正在等待一个monitor锁，就是我们平时用的synchronized的关键字。  //或者在调用了Object.wait()方法且被notify()之后也会进入BLOCKED状态  BLOCKED, /** * Thread state for a waiting thread. * A thread is in the waiting state due to calling one of the * following methods: * \u0026lt;ul\u0026gt; * \u0026lt;li\u0026gt;{@link Object#wait() Object.wait} with no timeout\u0026lt;/li\u0026gt; * \u0026lt;li\u0026gt;{@link #join() Thread.join} with no timeout\u0026lt;/li\u0026gt; * \u0026lt;li\u0026gt;{@link LockSupport#park() LockSupport.park}\u0026lt;/li\u0026gt; * \u0026lt;/ul\u0026gt; * * \u0026lt;p\u0026gt;A thread in the waiting state is waiting for another thread to * perform a particular action. * * For example, a thread that has called {@code Object.wait()} * on an object is waiting for another thread to call * {@code Object.notify()} or {@code Object.notifyAll()} on * that object. A thread that has called {@code Thread.join()} * is waiting for a specified thread to terminate. * 等待状态 * 1. Object.wait()无超时的方法后且未被notify()前，如果被notify()了会进入BLOCKED状态 * 2. Thread.join()无超时的方法后 * 3. LockSupport.park()无超时的方法后 */ WAITING, /** * Thread state for a waiting thread with a specified waiting time. * A thread is in the timed waiting state due to calling one of * the following methods with a specified positive waiting time: * \u0026lt;ul\u0026gt; * \u0026lt;li\u0026gt;{@link #sleep Thread.sleep}\u0026lt;/li\u0026gt; * \u0026lt;li\u0026gt;{@link Object#wait(long) Object.wait} with timeout\u0026lt;/li\u0026gt; * \u0026lt;li\u0026gt;{@link #join(long) Thread.join} with timeout\u0026lt;/li\u0026gt; * \u0026lt;li\u0026gt;{@link LockSupport#parkNanos LockSupport.parkNanos}\u0026lt;/li\u0026gt; * \u0026lt;li\u0026gt;{@link LockSupport#parkUntil LockSupport.parkUntil}\u0026lt;/li\u0026gt; * \u0026lt;/ul\u0026gt; *超市等待状态,调用了 * 1. Thread.sleep()方法后 * 2. Object.wait(timeout)方法后且未到超时时间前，如果达到超时了或被notify()了会进入BLOCKED状态 * 3. Thread.join(timeout)方法后 * 4. LockSupport.parkNanos(nanos)方法后 * 5. LockSupport.parkUntil(deadline)方法后 /* TIMED_WAITING, /** * Thread state for a terminated thread. * The thread has completed execution. */ //终止状态，线程执行完毕  TERMINATED; } 线程可以被终止吗，怎么终止 可以被终止\n 通过设置标记，配合循环  ​\t线程只有在执行完代码后才会终止，因此我们可以使用while循环，通过一个volatile修饰的变量控制跳出循环即可\n  通过interrupt方法\n  但是这种方式有问题，实际上在执行interrupt后，依然会继续执行一会儿，并不能做到立马停止。\n如果有阻塞的动作，会立马抛出异常\n interrupt()方法，标记线程结束，只是给一个标记，并不终止。 interrupted()方法，返回当前线程是否有终止的标记，并且清除标记。下一次再调这个方法会返回false isInterrupted()方法，返回当前线程是否有终止的标记，但不清除标记。 通过stop方法，stop就像直接拔掉插头一样，会造成很多问题，不推荐使用  AQS是什么？ AQS全称\nAbstractQueuedSynchronizer，抽象的队列同步器\nAQS是基于FIFO的队列实现的，并且内部维护了一个状态变量state，通过原子更新这个状态变量state即可以实现加锁解锁操作。\n内部结构\n Node：典型的双链表结构，节点中保存着当前线程、前一个节点、后一个节点以及线程的状态等信息。 State：通过这个状态用来控制锁  需要子类实现的方法：\n// 互斥模式下使用：尝试获取锁 protected boolean tryAcquire(int arg) { throw new UnsupportedOperationException(); } // 互斥模式下使用：尝试释放锁 protected boolean tryRelease(int arg) { throw new UnsupportedOperationException(); } // 共享模式下使用：尝试获取锁 protected int tryAcquireShared(int arg) { throw new UnsupportedOperationException(); } // 共享模式下使用：尝试释放锁 protected boolean tryReleaseShared(int arg) { throw new UnsupportedOperationException(); } // 如果当前线程独占着锁，返回true protected boolean isHeldExclusively() { throw new UnsupportedOperationException(); } 通过AQS自己实现一个锁\npublic class MyLockBaseOnAqs { // 定义一个同步器，实现AQS类  private static class Sync extends AbstractQueuedSynchronizer { // 实现tryAcquire(acquires)方法  @Override public boolean tryAcquire(int acquires) { if (compareAndSetState(0, 1)) { setExclusiveOwnerThread(Thread.currentThread()); return true; } return false; } // 实现tryRelease(releases)方法  @Override protected boolean tryRelease(int releases) { setExclusiveOwnerThread(null); setState(0); return true; } } // 声明同步器  private final Sync sync = new Sync(); // 加锁  public void lock() { sync.acquire(1); } // 解锁  public void unlock() { sync.release(1); } private static int count = 0; public static void main(String[] args) throws InterruptedException { MyLockBaseOnAqs lock = new MyLockBaseOnAqs(); CountDownLatch countDownLatch = new CountDownLatch(1000); IntStream.range(0, 1000).forEach(i -\u0026gt; new Thread(() -\u0026gt; { lock.lock(); try { IntStream.range(0, 10000).forEach(j -\u0026gt; { count++; }); } finally { lock.unlock(); } // System.out.println(Thread.currentThread().getName());  countDownLatch.countDown(); }, \u0026#34;tt-\u0026#34; + i).start()); countDownLatch.await(); System.out.println(count); } } wait()、notify()、sleep()、yield()、join()、Interrupt()这几个方法的作用   wait\n当我们调用wait（）方法后，线程会放到等待池当中，等待池的线程是不会去竞争同步锁。只有调用了notify（）或notifyAll()后等待池的线程才会开始去竞争锁，notify（）是随机从等待池选出一个线程放到锁池，而notifyAll()是将等待池的所有线程放到锁池当中\nwait会释放对象锁\n  notify()随机从等待池里，选一个线程去争夺锁。notify()释放所有的等待池里的线程。\nwait()和synchroinzed要锁的对象是同一个对象才可以wait()和notify()因为会对对象的“锁标志”进行操作，所以它们必须在获得对象锁后执行即在 synchronized函数或synchronized block中进行调用，否则如果虽然能编译通过，但在运行时会发生IllegalMonitorStateException的异常。\n  join\nThread实例的方法，释放CPU执行权，等待被调用join方法的线程结束才继续执行本线程下面的操作。不会释放所持有对象的锁。\n  sleep()\nThread类的静态方法，释放CPU执行权，可以让其他线程拥有机会去抢占CPU。等待指定时间后自己醒来。不会释放所持有对象的锁。\n  interrupt()\n只是单纯的打上中止的标记。断处于等待状态的线程（对于阻塞状态的线程不起作用，如因synchronized方法或代码块等而阻塞的线程）：在wait或sleep的线程、在等待线程结束的线程（join的调用者）可以被中断，如果被中断，会抛出InterruptedException；2、对非等待状态的线程调用interrupt不会抛异常，需要手动检测线程状态并做相应处理。\n  yield()\nThread的静态方法，此方法只是使当前线程重新回到可执行状态，不会阻塞线程，因此执行yield()的线程有可能在进入到可执行状态后马上又被执行。实际上，当某个线程调用了yield方法暂停之后，只有优先级与当前线程相同，或者优先级比当前线程更高的处于就绪状态的线程才会获得执行的机会。\n  实现线程安全的方法 加锁就完事\n公平锁和非公平锁的区别,ReentrantLock是怎么实现的，ReentrantLock又是怎么实现重入锁的，它的条件锁又是什么？ ReentrantLock，表面意思重复进入的锁\n 通过state变量每次递增，用来实现重入锁。检查当前的独占锁是否是当前线程，如果是的话，直接给state变量+1，不会释放锁，再加锁  ReentrantLock内部的主要的属性Sync，是实现了AQS的一个锁。其还有2个子类，\n  FairSync\n公平锁，实现具体公平锁的实现逻辑\n  NoFairSync\n非公平锁，实现具体的非公平锁逻辑\n  ReentrantLock实现了Lock接口\n// 获取锁 void lock(); // 获取锁（可中断） void lockInterruptibly() throws InterruptedException; // 尝试获取锁，如果没获取到锁，就返回false boolean tryLock(); // 尝试获取锁，如果没获取到锁，就等待一段时间，这段时间内还没获取到锁就返回false boolean tryLock(long time, TimeUnit unit) throws InterruptedException; // 释放锁 void unlock(); // 条件锁 Condition newCondition();   构造方法\n// 默认构造方法 public ReentrantLock() { sync = new NonfairSync(); } // 自己可选择使用公平锁还是非公平锁 public ReentrantLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync(); }   公平锁加锁过程\n// ReentrantLock.lock() public void lock() { // 调用的sync属性的lock()方法  // 这里的sync是公平锁，所以是FairSync的实例  sync.lock(); } // ReentrantLock.FairSync.lock() final void lock() { // 调用AQS的acquire()方法获取锁  // 注意，这里传的值为1  acquire(1); } // AbstractQueuedSynchronizer.acquire() public final void acquire(int arg) { // 尝试获取锁  // 如果失败了，就排队  if (!tryAcquire(arg) \u0026amp;\u0026amp; // 注意addWaiter()这里传入的节点模式为独占模式  acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } // ReentrantLock.FairSync.tryAcquire() protected final boolean tryAcquire(int acquires) { // 当前线程  final Thread current = Thread.currentThread(); // 查看当前状态变量的值  int c = getState(); // 如果状态变量的值为0，说明暂时还没有人占有锁  if (c == 0) { // 如果没有其它线程在排队，那么当前线程尝试更新state的值为1  // 如果成功了，则说明当前线程获取了锁  if (!hasQueuedPredecessors() \u0026amp;\u0026amp; compareAndSetState(0, acquires)) { // 当前线程获取了锁，把自己设置到exclusiveOwnerThread变量中  // exclusiveOwnerThread是AQS的父类AbstractOwnableSynchronizer中提供的变量  setExclusiveOwnerThread(current); // 返回true说明成功获取了锁  return true; } } // 如果当前线程本身就占有着锁，现在又尝试获取锁  // 那么，直接让它获取锁并返回true  else if (current == getExclusiveOwnerThread()) { // 状态变量state的值加1  int nextc = c + acquires; // 如果溢出了，则报错  if (nextc \u0026lt; 0) throw new Error(\u0026#34;Maximum lock count exceeded\u0026#34;); // 设置到state中  // 这里不需要CAS更新state  // 因为当前线程占有着锁，其它线程只会CAS把state从0更新成1，是不会成功的  // 所以不存在竞争，自然不需要使用CAS来更新  setState(nextc); // 当线程获取锁成功  return true; } // 当前线程尝试获取锁失败  return false; } // AbstractQueuedSynchronizer.addWaiter() // 调用这个方法，说明上面尝试获取锁失败了 private Node addWaiter(Node mode) { // 新建一个节点  Node node = new Node(Thread.currentThread(), mode); // 这里先尝试把新节点加到尾节点后面  // 如果成功了就返回新节点  // 如果没成功再调用enq()方法不断尝试  Node pred = tail; // 如果尾节点不为空  if (pred != null) { // 设置新节点的前置节点为现在的尾节点  node.prev = pred; // CAS更新尾节点为新节点  if (compareAndSetTail(pred, node)) { // 如果成功了，把旧尾节点的下一个节点指向新节点  pred.next = node; // 并返回新节点  return node; } } // 如果上面尝试入队新节点没成功，调用enq()处理  enq(node); return node; } // AbstractQueuedSynchronizer.enq() private Node enq(final Node node) { // 自旋，不断尝试  for (;;) { Node t = tail; // 如果尾节点为空，说明还未初始化  if (t == null) { // Must initialize  // 初始化头节点和尾节点  if (compareAndSetHead(new Node())) tail = head; } else { // 如果尾节点不为空  // 设置新节点的前一个节点为现在的尾节点  node.prev = t; // CAS更新尾节点为新节点  if (compareAndSetTail(t, node)) { // 成功了，则设置旧尾节点的下一个节点为新节点  t.next = node; // 并返回旧尾节点  return t; } } } } // AbstractQueuedSynchronizer.acquireQueued() // 调用上面的addWaiter()方法使得新节点已经成功入队了 // 这个方法是尝试让当前节点来获取锁的 final boolean acquireQueued(final Node node, int arg) { // 失败标记  boolean failed = true; try { // 中断标记  boolean interrupted = false; // 自旋  for (;;) { // 当前节点的前一个节点  final Node p = node.predecessor(); // 如果当前节点的前一个节点为head节点，则说明轮到自己获取锁了  // 调用ReentrantLock.FairSync.tryAcquire()方法再次尝试获取锁  if (p == head \u0026amp;\u0026amp; tryAcquire(arg)) { // 尝试获取锁成功  // 这里同时只会有一个线程在执行，所以不需要用CAS更新  // 把当前节点设置为新的头节点  setHead(node); // 并把上一个节点从链表中删除  p.next = null; // help GC  // 未失败  failed = false; return interrupted; } // 是否需要阻塞  if (shouldParkAfterFailedAcquire(p, node) \u0026amp;\u0026amp; // 真正阻塞的方法  parkAndCheckInterrupt()) // 如果中断了  interrupted = true; } } finally { // 如果失败了  if (failed) // 取消获取锁  cancelAcquire(node); } } // AbstractQueuedSynchronizer.shouldParkAfterFailedAcquire() // 这个方法是在上面的for()循环里面调用的 // 第一次调用会把前一个节点的等待状态设置为SIGNAL，并返回false // 第二次调用才会返回true private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { // 上一个节点的等待状态  // 注意Node的waitStatus字段我们在上面创建Node的时候并没有指定  // 也就是说使用的是默认值0  // 这里把各种等待状态再贴出来  //static final int CANCELLED = 1;  //static final int SIGNAL = -1;  //static final int CONDITION = -2;  //static final int PROPAGATE = -3;  int ws = pred.waitStatus; // 如果等待状态为SIGNAL(等待唤醒)，直接返回true  if (ws == Node.SIGNAL) return true; // 如果前一个节点的状态大于0，也就是已取消状态  if (ws \u0026gt; 0) { // 把前面所有取消状态的节点都从链表中删除  do { node.prev = pred = pred.prev; } while (pred.waitStatus \u0026gt; 0); pred.next = node; } else { // 如果前一个节点的状态小于等于0，则把其状态设置为等待唤醒  // 这里可以简单地理解为把初始状态0设置为SIGNAL  // CONDITION是条件锁的时候使用的  // PROPAGATE是共享锁使用的  compareAndSetWaitStatus(pred, ws, Node.SIGNAL); } return false; } // AbstractQueuedSynchronizer.parkAndCheckInterrupt() private final boolean parkAndCheckInterrupt() { // 阻塞当前线程  // 底层调用的是Unsafe的park()方法  LockSupport.park(this); // 返回是否已中断  return Thread.interrupted(); }   非公平锁过程\n// ReentrantLock.lock() public void lock() { sync.lock(); } // ReentrantLock.NonfairSync.lock() // 这个方法在公平锁模式下是直接调用的acquire(1); final void lock() { // 直接尝试CAS更新状态变量  if (compareAndSetState(0, 1)) // 如果更新成功，说明获取到锁，把当前线程设为独占线程  setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); } // ReentrantLock.NonfairSync.tryAcquire() protected final boolean tryAcquire(int acquires) { // 调用父类的方法  return nonfairTryAcquire(acquires); } // ReentrantLock.Sync.nonfairTryAcquire() final boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { // 如果状态变量的值为0，再次尝试CAS更新状态变量的值  // 相对于公平锁模式少了!hasQueuedPredecessors()条件  if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc \u0026lt; 0) // overflow  throw new Error(\u0026#34;Maximum lock count exceeded\u0026#34;); setState(nextc); return true; } return false; }   释放锁过程\n// java.util.concurrent.locks.ReentrantLock.unlock() public void unlock() { sync.release(1); } // java.util.concurrent.locks.AbstractQueuedSynchronizer.release public final boolean release(int arg) { // 调用AQS实现类的tryRelease()方法释放锁  if (tryRelease(arg)) { Node h = head; // 如果头节点不为空，且等待状态不是0，就唤醒下一个节点  // 还记得waitStatus吗？  // 在每个节点阻塞之前会把其上一个节点的等待状态设为SIGNAL（-1）  // 所以，SIGNAL的准确理解应该是唤醒下一个等待的线程  if (h != null \u0026amp;\u0026amp; h.waitStatus != 0) unparkSuccessor(h); return true; } return false; } // java.util.concurrent.locks.ReentrantLock.Sync.tryRelease protected final boolean tryRelease(int releases) { int c = getState() - releases; // 如果当前线程不是占有着锁的线程，抛出异常  if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; // 如果状态变量的值为0了，说明完全释放了锁  // 这也就是为什么重入锁调用了多少次lock()就要调用多少次unlock()的原因  // 如果不这样做，会导致锁不会完全释放，别的线程永远无法获取到锁  if (c == 0) { free = true; // 清空占有线程  setExclusiveOwnerThread(null); } // 设置状态变量的值  setState(c); return free; } private void unparkSuccessor(Node node) { // 注意，这里的node是头节点  // 如果头节点的等待状态小于0，就把它设置为0  int ws = node.waitStatus; if (ws \u0026lt; 0) compareAndSetWaitStatus(node, ws, 0); // 头节点的下一个节点  Node s = node.next; // 如果下一个节点为空，或者其等待状态大于0（实际为已取消）  if (s == null || s.waitStatus \u0026gt; 0) { s = null; // 从尾节点向前遍历取到队列最前面的那个状态不是已取消状态的节点  for (Node t = tail; t != null \u0026amp;\u0026amp; t != node; t = t.prev) if (t.waitStatus \u0026lt;= 0) s = t; } // 如果下一个节点不为空，则唤醒它  if (s != null) LockSupport.unpark(s.thread); }   条件锁\n 条件锁，是指在获取锁之后发现当前业务场景自己无法处理，而需要等待某个条件的出现才可以继续处理时使用的一种锁。\n比如，在阻塞队列中，当队列中没有元素的时候是无法弹出一个元素的，这时候就需要阻塞在条件notEmpty上，等待其它线程往里面放入一个元素后，唤醒这个条件notEmpty，当前线程才可以继续去做“弹出一个元素”的行为。\n   条件锁流程\n// AbstractQueuedSynchronizer.ConditionObject.await() public final void await() throws InterruptedException { // 如果线程中断了，抛出异常  if (Thread.interrupted()) throw new InterruptedException(); // 添加节点到Condition的队列中，并返回该节点  Node node = addConditionWaiter(); // 完全释放当前线程获取的锁  // 因为锁是可重入的，所以这里要把获取的锁全部释放  int savedState = fullyRelease(node); int interruptMode = 0; // 是否在同步队列中  while (!isOnSyncQueue(node)) { // 阻塞当前线程  LockSupport.park(this); // 上面部分是调用await()时释放自己占有的锁，并阻塞自己等待条件的出现  // *************************分界线************************* //  // 下面部分是条件已经出现，尝试去获取锁  if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; } // 尝试获取锁，注意第二个参数，这是上一章分析过的方法  // 如果没获取到会再次阻塞（这个方法这里就不贴出来了，有兴趣的翻翻上一章的内容）  if (acquireQueued(node, savedState) \u0026amp;\u0026amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; // 清除取消的节点  if (node.nextWaiter != null) // clean up if cancelled  unlinkCancelledWaiters(); // 线程中断相关  if (interruptMode != 0) reportInterruptAfterWait(interruptMode); } // AbstractQueuedSynchronizer.ConditionObject.addConditionWaiter private Node addConditionWaiter() { Node t = lastWaiter; // 如果条件队列的尾节点已取消，从头节点开始清除所有已取消的节点  if (t != null \u0026amp;\u0026amp; t.waitStatus != Node.CONDITION) { unlinkCancelledWaiters(); // 重新获取尾节点  t = lastWaiter; } // 新建一个节点，它的等待状态是CONDITION  Node node = new Node(Thread.currentThread(), Node.CONDITION); // 如果尾节点为空，则把新节点赋值给头节点（相当于初始化队列）  // 否则把新节点赋值给尾节点的nextWaiter指针  if (t == null) firstWaiter = node; else t.nextWaiter = node; // 尾节点指向新节点  lastWaiter = node; // 返回新节点  return node; } // AbstractQueuedSynchronizer.fullyRelease final int fullyRelease(Node node) { boolean failed = true; try { // 获取状态变量的值，重复获取锁，这个值会一直累加  // 所以这个值也代表着获取锁的次数  int savedState = getState(); // 一次性释放所有获得的锁  if (release(savedState)) { failed = false; // 返回获取锁的次数  return savedState; } else { throw new IllegalMonitorStateException(); } } finally { if (failed) node.waitStatus = Node.CANCELLED; } } // AbstractQueuedSynchronizer.isOnSyncQueue final boolean isOnSyncQueue(Node node) { // 如果等待状态是CONDITION，或者前一个指针为空，返回false  // 说明还没有移到AQS的队列中  if (node.waitStatus == Node.CONDITION || node.prev == null) return false; // 如果next指针有值，说明已经移到AQS的队列中了  if (node.next != null) // If has successor, it must be on queue  return true; // 从AQS的尾节点开始往前寻找看是否可以找到当前节点，找到了也说明已经在AQS的队列中了  return findNodeFromTail(node); } 条件通知方法\n// AbstractQueuedSynchronizer.ConditionObject.signal public final void signal() { // 如果不是当前线程占有着锁，调用这个方法抛出异常  // 说明signal()也要在获取锁之后执行  if (!isHeldExclusively()) throw new IllegalMonitorStateException(); // 条件队列的头节点  Node first = firstWaiter; // 如果有等待条件的节点，则通知它条件已成立  if (first != null) doSignal(first); } // AbstractQueuedSynchronizer.ConditionObject.doSignal private void doSignal(Node first) { do { // 移到条件队列的头节点往后一位  if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; // 相当于把头节点从队列中出队  first.nextWaiter = null; // 转移节点到AQS队列中  } while (!transferForSignal(first) \u0026amp;\u0026amp; (first = firstWaiter) != null); } // AbstractQueuedSynchronizer.transferForSignal final boolean transferForSignal(Node node) { // 把节点的状态更改为0，也就是说即将移到AQS队列中  // 如果失败了，说明节点已经被改成取消状态了  // 返回false，通过上面的循环可知会寻找下一个可用节点  if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; // 调用AQS的入队方法把节点移到AQS的队列中  // 注意，这里enq()的返回值是node的上一个节点，也就是旧尾节点  Node p = enq(node); // 上一个节点的等待状态  int ws = p.waitStatus; // 如果上一个节点已取消了，或者更新状态为SIGNAL失败（也是说明上一个节点已经取消了）  // 则直接唤醒当前节点对应的线程  if (ws \u0026gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); // 如果更新上一个节点的等待状态为SIGNAL成功了  // 则返回true，这时上面的循环不成立了，退出循环，也就是只通知了一个节点  // 此时当前节点还是阻塞状态  // 也就是说调用signal()的时候并不会真正唤醒一个节点  // 只是把节点从条件队列移到AQS队列中  return true; } 条件锁获取流程\n（1）新建一个节点加入到条件队列中去；\n（2）完全释放当前线程占有的锁；\n（3）阻塞当前线程，并等待条件的出现；\n（4）条件已出现（此时节点已经移到AQS的队列中），尝试获取锁；\n条件锁的唤醒流程\n（1）从条件队列的头节点开始寻找一个非取消状态的节点；\n（2）把它从条件队列移到AQS队列；\n（3）且只移动一个节点；\n    为什么ReentrantLock默认采用的是非公平模式？\n答：因为非公平模式效率比较高。\n为什么非公平模式效率比较高？\n答：因为非公平模式会在一开始就尝试两次获取锁，如果当时正好state的值为0，它就会成功获取到锁，少了排队导致的阻塞/唤醒过程，并且减少了线程频繁的切换带来的性能损耗。\n非公平模式有什么弊端？\n答：非公平模式有可能会导致一开始排队的线程一直获取不到锁，导致线程饿死。\n  公平非公平的实现方法\n公平锁在实现的时候，会先去检查自己这node前面有没有其他node去排队了\n而非公平锁，不会去检查，而是直接去尝试获取锁\n  ReetrantWhriteReadLock是怎么实现读写锁的 读写锁\n读锁：多个线程可以获取同一把锁\n写锁：多个线程只有一个线程可以获取到写锁\n 读锁流程  // ReentrantReadWriteLock.ReadLock.lock() public void lock() { sync.acquireShared(1); } // AbstractQueuedSynchronizer.acquireShared() public final void acquireShared(int arg) { // 尝试获取共享锁（返回1表示成功，返回-1表示失败）  if (tryAcquireShared(arg) \u0026lt; 0) // 失败了就可能要排队  doAcquireShared(arg); } // ReentrantReadWriteLock.Sync.tryAcquireShared() protected final int tryAcquireShared(int unused) { Thread current = Thread.currentThread(); // 状态变量的值  // 在读写锁模式下，高16位存储的是共享锁（读锁）被获取的次数，低16位存储的是互斥锁（写锁）被获取的次数  int c = getState(); // 互斥锁的次数  // 如果其它线程获得了写锁，直接返回-1  if (exclusiveCount(c) != 0 \u0026amp;\u0026amp; getExclusiveOwnerThread() != current) return -1; // 读锁被获取的次数  int r = sharedCount(c); // 下面说明此时还没有写锁，尝试去更新state的值获取读锁  // 读者是否需要排队（是否是公平模式）  if (!readerShouldBlock() \u0026amp;\u0026amp; r \u0026lt; MAX_COUNT \u0026amp;\u0026amp; compareAndSetState(c, c + SHARED_UNIT)) { // 获取读锁成功  if (r == 0) { // 如果之前还没有线程获取读锁  // 记录第一个读者为当前线程  firstReader = current; // 第一个读者重入的次数为1  firstReaderHoldCount = 1; } else if (firstReader == current) { // 如果有线程获取了读锁且是当前线程是第一个读者  // 则把其重入次数加1  firstReaderHoldCount++; } else { // 如果有线程获取了读锁且当前线程不是第一个读者  // 则从缓存中获取重入次数保存器  HoldCounter rh = cachedHoldCounter; // 如果缓存不属性当前线程  // 再从ThreadLocal中获取  // readHolds本身是一个ThreadLocal，里面存储的是HoldCounter  if (rh == null || rh.tid != getThreadId(current)) // get()的时候会初始化rh  cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) // 如果rh的次数为0，把它放到ThreadLocal中去  readHolds.set(rh); // 重入的次数加1（初始次数为0）  rh.count++; } // 获取读锁成功，返回1  return 1; } // 通过这个方法再去尝试获取读锁（如果之前其它线程获取了写锁，一样返回-1表示失败）  return fullTryAcquireShared(current); } // AbstractQueuedSynchronizer.doAcquireShared() private void doAcquireShared(int arg) { // 进入AQS的队列中  final Node node = addWaiter(Node.SHARED); boolean failed = true; try { boolean interrupted = false; for (;;) { // 当前节点的前一个节点  final Node p = node.predecessor(); // 如果前一个节点是头节点（说明是第一个排队的节点）  if (p == head) { // 再次尝试获取读锁  int r = tryAcquireShared(arg); // 如果成功了  if (r \u0026gt;= 0) { // 头节点后移并传播  // 传播即唤醒后面连续的读节点  setHeadAndPropagate(node, r); p.next = null; // help GC  if (interrupted) selfInterrupt(); failed = false; return; } } // 没获取到读锁，阻塞并等待被唤醒  if (shouldParkAfterFailedAcquire(p, node) \u0026amp;\u0026amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); } } // AbstractQueuedSynchronizer.setHeadAndPropagate() private void setHeadAndPropagate(Node node, int propagate) { // h为旧的头节点  Node h = head; // 设置当前节点为新头节点  setHead(node); // 如果旧的头节点或新的头节点为空或者其等待状态小于0（表示状态为SIGNAL/PROPAGATE）  if (propagate \u0026gt; 0 || h == null || h.waitStatus \u0026lt; 0 || (h = head) == null || h.waitStatus \u0026lt; 0) { // 需要传播  // 取下一个节点  Node s = node.next; // 如果下一个节点为空，或者是需要获取读锁的节点  if (s == null || s.isShared()) // 唤醒下一个节点  doReleaseShared(); } } // AbstractQueuedSynchronizer.doReleaseShared() // 这个方法只会唤醒一个节点 private void doReleaseShared() { for (;;) { Node h = head; if (h != null \u0026amp;\u0026amp; h != tail) { int ws = h.waitStatus; // 如果头节点状态为SIGNAL，说明要唤醒下一个节点  if (ws == Node.SIGNAL) { if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases  // 唤醒下一个节点  unparkSuccessor(h); } else if (ws == 0 \u0026amp;\u0026amp; // 把头节点的状态改为PROPAGATE成功才会跳到下面的if  !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS  } // 如果唤醒后head没变，则跳出循环  if (h == head) // loop if head changed  break; } }   写锁流程\n// java.util.concurrent.locks.ReentrantReadWriteLock.WriteLock.lock() public void lock() { sync.acquire(1); } // java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire() public final void acquire(int arg) { // 先尝试获取锁  // 如果失败，则会进入队列中排队，后面的逻辑跟ReentrantLock一模一样了  if (!tryAcquire(arg) \u0026amp;\u0026amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } // java.util.concurrent.locks.ReentrantReadWriteLock.Sync.tryAcquire() protected final boolean tryAcquire(int acquires) { Thread current = Thread.currentThread(); // 状态变量state的值  int c = getState(); // 互斥锁被获取的次数  int w = exclusiveCount(c); if (c != 0) { // 如果c!=0且w==0，说明共享锁被获取的次数不为0  // 这句话整个的意思就是  // 如果共享锁被获取的次数不为0，或者被其它线程获取了互斥锁（写锁）  // 那么就返回false，获取写锁失败  if (w == 0 || current != getExclusiveOwnerThread()) return false; // 溢出检测  if (w + exclusiveCount(acquires) \u0026gt; MAX_COUNT) throw new Error(\u0026#34;Maximum lock count exceeded\u0026#34;); // 到这里说明当前线程已经获取过写锁，这里是重入了，直接把state加1即可  setState(c + acquires); // 获取写锁成功  return true; } // 如果c等于0，就尝试更新state的值（非公平模式writerShouldBlock()返回false）  // 如果失败了，说明获取写锁失败，返回false  // 如果成功了，说明获取写锁成功，把自己设置为占有者，并返回true  if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; setExclusiveOwnerThread(current); return true; } // 获取写锁失败了后面的逻辑跟ReentrantLock是一致的，进入队列排队，这里就不列源码了    总结\n  （1）ReentrantReadWriteLock采用读写锁的思想，能提高并发的吞吐量；\n（2）读锁使用的是共享锁，多个读锁可以一起获取锁，互相不会影响，即读读不互斥；\n（3）读写、写读和写写是会互斥的，前者占有着锁，后者需要进入AQS队列中排队；\n（4）多个连续的读线程是一个接着一个被唤醒的，而不是一次性唤醒所有读线程；\n（5）只有多个读锁都完全释放了才会唤醒下一个写线程；\n（6）只有写锁完全释放了才会唤醒下一个等待者，这个等待者有可能是读线程，也可能是写线程；\n  同一个线程先写后读，是什么情况\n会阻塞，获取不到读的锁\n  同一个线程先读后写\n正常\n  CAS是什么，怎么解决ABA问题 CAS是CPU的原子指令器，通过自选的方式，属于乐观锁，与java的悲观锁相比效率更高。\nABA，只的是多个线程同时在更新的时候，例如A线程要把target变为1，目前是2，A读到了2，然后修改成1后，又修改成2，然后B读到了2。\n解决方式\n  版本号：\nAtomicStampedReference：维护了一个版本号\nAtomicMarkableReference：维护了一个Boolean，标记是否更改过\n  ConcurrentHashMap的分段锁 你用过哪些Java.util.concurrent下的类   Semaphore\nSemaphore，信号量，它保存了一系列的许可（permits），每次调用acquire()都将消耗一个许可，每次调用release()都将归还一个许可。\n（1）Semaphore，也叫信号量，通常用于控制同一时刻对共享资源的访问上，也就是限流场景；\n（2）Semaphore的内部实现是基于AQS的共享锁来实现的；\n（3）Semaphore初始化的时候需要指定许可的次数，许可的次数是存储在state中；\n（4）获取一个许可时，则state值减1；\n（5）释放一个许可时，则state值加1；\n（6）可以动态减少n个许可；\n（7）可以动态增加n个许可吗:调用release(int permits)即可。我们知道释放许可的时候state的值会相应增加，再回头看看释放许可的源码，发现与ReentrantLock的释放锁还是有点区别的，Semaphore释放许可的时候并不会检查当前线程有没有获取过许可，所以可以调用释放许可的方法动态增加一些许可。\n  CountDownLatch\nCountDownLatch，可以翻译为倒计时器，但是似乎不太准确，它的含义是允许一个或多个线程等待其它线程的操作执行完毕后再执行后续的操作。\nCountDownLatch的通常用法和Thread.join()有点类似，等待其它线程都完成后再执行主任务。\n  CyclicBarrier\nCyclicBarrier，回环栅栏，它会阻塞一组线程直到这些线程同时达到某个条件才继续执行。它与CountDownLatch很类似，但又不同，CountDownLatch需要调用countDown()方法触发事件，而CyclicBarrier不需要，它就像一个栅栏一样，当一组线程都到达了栅栏处才继续往下走。\npublic class CyclicBarrierTest { public static void main(String[] args) { CyclicBarrier cyclicBarrier = new CyclicBarrier(3); for (int i = 0; i \u0026lt; 3; i++) { new Thread(()-\u0026gt;{ System.out.println(\u0026#34;before\u0026#34;); try { cyclicBarrier.await(); } catch (InterruptedException e) { e.printStackTrace(); } catch (BrokenBarrierException e) { e.printStackTrace(); } System.out.println(\u0026#34;after\u0026#34;); }).start(); } } }   Phaser\nPhaser，翻译为阶段，它适用于这样一种场景，一个大任务可以分为多个阶段完成，且每个阶段的任务可以多个线程并发执行，但是必须上一个阶段的任务都完成了才可以执行下一个阶段的任务。\n这种场景虽然使用CyclicBarrier或者CountryDownLatch也可以实现，但是要复杂的多。首先，具体需要多少个阶段是可能会变的，其次，每个阶段的任务数也可能会变的。相比于CyclicBarrier和CountDownLatch，Phaser更加灵活更加方便。\npublic class PhaserTest { public static final int PARTIES = 3; public static final int PHASES = 4; public static void main(String[] args) { Phaser phaser = new Phaser(PARTIES) { @Override protected boolean onAdvance(int phase, int registeredParties) { // 【本篇文章由公众号“彤哥读源码”原创，请支持原创，谢谢！】  System.out.println(\u0026#34;=======phase: \u0026#34; + phase + \u0026#34; finished=============\u0026#34;); return super.onAdvance(phase, registeredParties); } }; for (int i = 0; i \u0026lt; PARTIES; i++) { new Thread(()-\u0026gt;{ for (int j = 0; j \u0026lt; PHASES; j++) { System.out.println(String.format(\u0026#34;%s: phase: %d\u0026#34;, Thread.currentThread().getName(), j)); phaser.arriveAndAwaitAdvance(); } }, \u0026#34;Thread \u0026#34; + i).start(); } } }   讲一下线程池的几个参数含义 它有7个参数，分别为corePoolSize、maximumPoolSize、keepAliveTime、unit、workQueue、threadFactory、handler。\n  corePoolSize\n核心线程数。\n当正在运行的线程数小于核心线程数时，来一个任务就创建一个核心线程；\n当正在运行的线程数大于或等于核心线程数时，任务来了先不创建线程而是丢到任务队列中。\n  maximumPoolSize\n最大线程数。\n当任务队列满了时，来一个任务才创建一个非核心线程，但不能超过最大线程数。\n  keepAliveTime + unit\n线程保持空闲时间及单位。\n默认情况下，此两参数仅当正在运行的线程数大于核心线程数时才有效，即只针对非核心线程。\n但是，如果allowCoreThreadTimeOut被设置成了true，针对核心线程也有效。\n即当任务队列为空时，线程保持多久才会销毁，内部主要是通过阻塞队列带超时的poll(timeout, unit)方法实现的。\n  workQueue\n任务队列。\n当正在运行的线程数大于或等于核心线程数时，任务来了是先进入任务队列中的。\n这个队列必须是阻塞队列，所以像ConcurrentLinkedQueue就不能作为参数，因为它虽然是并发安全的队列，但是它不是阻塞队列。\n  threadFactory\n线程工厂。\n默认使用的是Executors工具类中的DefaultThreadFactory类，这个类有个缺点，创建的线程的名称是自动生成的，无法自定义以区分不同的线程池，且它们都是非守护线程。\n  handler\n拒绝策略。\n拒绝策略表示当任务队列满了且线程数也达到最大了，这时候再新加任务，线程池已经无法承受了，这些新来的任务应该按什么逻辑来处理。\n常用的拒绝策略有丢弃当前任务、丢弃最老的任务、抛出异常、调用者自己处理等待。\n默认的拒绝策略是抛出异常，即线程池无法承载了，调用者再往里面添加任务会抛出异常。\n默认的拒绝策略虽然比较简单粗暴，但是相对于丢弃任务策略明显要好很多，最起码调用者自己可以捕获这个异常再进行二次处理。\n  synchronized关键字，怎么优化的，膨胀的流程 简介\nsynchronized关键字是Java里面最基本的同步手段，它经过编译之后，会在同步块的前后分别生成 monitorenter 和 monitorexit 字节码指令，这两个字节码指令都需要一个引用类型的参数来指明要锁定和解锁的对象。\n实现原理\n在学习Java内存模型的时候，我们介绍过两个指令：lock 和 unlock。\nlock，锁定，作用于主内存的变量，它把主内存中的变量标识为一条线程独占状态。\nunlock，解锁，作用于主内存的变量，它把锁定的变量释放出来，释放出来的变量才可以被其它线程锁定。\n但是这两个指令并没有直接提供给用户使用，而是提供了两个更高层次的指令 monitorenter 和 monitorexit 来隐式地使用 lock 和 unlock 指令。\n而 synchronized 就是使用 monitorenter 和 monitorexit 这两个指令来实现的。\n根据JVM规范的要求，在执行monitorenter指令的时候，首先要去尝试获取对象的锁，如果这个对象没有被锁定，或者当前线程已经拥有了这个对象的锁，就把锁的计数器加1，相应地，在执行monitorexit的时候会把计数器减1，当计数器减小为0时，锁就释放了。\n 前面讲解Java内存模型的时候我们说过内存模型主要就是用来解决缓存一致性的问题的，而缓存一致性主要包括原子性、可见性、有序性。\n那么，synchronized关键字能否保证这三个特性呢？\n还是回到Java内存模型上来，synchronized关键字底层是通过monitorenter和monitorexit实现的，而这两个指令又是通过lock和unlock来实现的。\n而lock和unlock在Java内存模型中是必须满足下面四条规则的：\n（1）一个变量同一时刻只允许一条线程对其进行lock操作，但lock操作可以被同一个线程执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才能被解锁。\n（2）如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行load或assign操作初始化变量的值；\n（3）如果一个变量没有被lock操作锁定，则不允许对其执行unlock操作，也不允许unlock一个其它线程锁定的变量；\n（4）对一个变量执行unlock操作之前，必须先把此变量同步回主内存中，即执行store和write操作；\n通过规则（1），我们知道对于lock和unlock之间的代码，同一时刻只允许一个线程访问，所以，synchronized是具有原子性的。\n通过规则（1）（2）和（4），我们知道每次lock和unlock时都会从主内存加载变量或把变量刷新回主内存，而lock和unlock之间的变量（这里是指锁定的变量）是不会被其它线程修改的，所以，synchronized是具有可见性的。\n通过规则（1）和（3），我们知道所有对变量的加锁都要排队进行，且其它线程不允许解锁当前线程锁定的对象，所以，synchronized是具有有序性的。\n综上所述，synchronized是可以保证原子性、可见性和有序性的。\n 优化过程：\n（1）偏向锁，是指一段同步代码一直被一个线程访问，那么这个线程会自动获取锁，降低获取锁的代价。\n（2）轻量级锁，是指当锁是偏向锁时，被另一个线程所访问，偏向锁会升级为轻量级锁，这个线程会通过自旋的方式尝试获取锁，不会阻塞，提高性能。\n（3）重量级锁，是指当锁是轻量级锁时，当自旋的线程自旋了一定的次数后，还没有获取到锁，就会进入阻塞状态，该锁升级为重量级锁，重量级锁会使其他线程阻塞，性能降低。\nvolatile关键字 我们说过可见性是指当一个线程修改了共享变量的值，其它线程能立即感知到这种变化。而普通变量无法做到立即感知这一点，变量的值在线程之间的传递均需要通过主内存来完成，比如，线程A修改了一个普通变量的值，然后向主内存回写，另外一条线程B只有在线程A的回写完成之后再从主内存中读取变量的值，才能够读取到新变量的值，也就是新变量才能对线程B可见。\njava内存模型规定，volatile变量的每次修改都必须立即回写到主内存中，volatile变量的每次使用都必须从主内存刷新最新的值。\n  volatile可以禁止cpu语意重排，保证了有序性\n 普通变量仅仅会保证在该方法的执行过程中所有依赖赋值结果的地方都能获得正确的结果，而不能保证变量赋值操作的顺序与程序代码中的执行顺序一致，因为一个线程的方法执行过程中无法感知到这点，这就是“线程内表现为串行的语义”\n public class VolatileTest3 { private static Config config = null; private static volatile boolean initialized = false; public static void main(String[] args) { // 线程1负责初始化配置信息  new Thread(() -\u0026gt; { config = new Config(); config.name = \u0026#34;config\u0026#34;; initialized = true; }).start(); // 线程2检测到配置初始化完成后使用配置信息  new Thread(() -\u0026gt; { while (!initialized) { LockSupport.parkNanos(TimeUnit.MILLISECONDS.toNanos(100)); } // do sth with config  String name = config.name; }).start(); } } class Config { String name; } 在这个例子中，如果initialized不使用volatile来修饰，可能就会出现重排序，比如在初始化配置之前把initialized的值设置为了true，这样线程2读取到这个值为true了，就去使用配置了，这时候可能就会出现错误。\n  volatile提供了变量的可见性\n  缺陷，无法保证原子性\n  Java内存模型 什么是Java内存模型？\n多个缓存读写一致性以及乱序排序优化的问题，这就有了内存模型，它定义了共享内存系统中多线程读写操作行为的规范。\n Java内存模型（Java Memory Model，JMM）是在硬件内存模型基础上更高层的抽象，它屏蔽了各种硬件和操作系统对内存访问的差异性，从而实现让Java程序在各种平台下都能达到一致的并发效果。\nJava内存模型定义了程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出这样的底层细节。这里所说的变量包括实例字段、静态字段，但不包括局部变量和方法参数，因为它们是线程私有的，它们不会被共享，自然不存在竞争问题。\n为了获得更好的执行效能，Java内存模型并没有限制执行引擎使用处理器的特定寄存器或缓存来和主内存进行交互，也没有限制即时编译器调整代码的执行顺序等这类权利。\nJava内存模型规定了所有的变量都存储在主内存中，这里的主内存跟介绍硬件时所用的名字一样，两者可以类比，但此处仅指虚拟机中内存的一部分。\n除了主内存，每条线程还有自己的工作内存，此处可与CPU的高速缓存进行类比。工作内存中保存着该线程使用到的变量的主内存副本的拷贝，线程对变量的操作都必须在工作内存中进行，包括读取和赋值等，而不能直接读写主内存中的变量，不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递必须通过主内存来完成。\n Java内存模型规定了所有的变量都存储在主内存中，这里的主内存跟介绍硬件时所用的名字一样，两者可以类比，但此处仅指虚拟机中内存的一部分。\n除了主内存，每条线程还有自己的工作内存，此处可与CPU的高速缓存进行类比。工作内存中保存着该线程使用到的变量的主内存副本的拷贝，线程对变量的操作都必须在工作内存中进行，包括读取和赋值等，而不能直接读写主内存中的变量，不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递必须通过主内存来完成。\n Java内存模型就是为了解决多线程环境下共享变量的一致性问题，那么一致性包含哪些内容呢？\n一致性主要包含三大特性：原子性、可见性、有序性，下面我们就来看看Java内存模型是怎么实现这三大特性的。\n（1）原子性\n原子性是指一段操作一旦开始就会一直运行到底，中间不会被其它线程打断，这段操作可以是一个操作，也可以是多个操作。\n由Java内存模型来直接保证的原子性操作包括read、load、user、assign、store、write这两个操作，我们可以大致认为基本类型变量的读写是具备原子性的。\n如果应用需要一个更大范围的原子性，Java内存模型还提供了lock和unlock这两个操作来满足这种需求，尽管不能直接使用这两个操作，但我们可以使用它们更具体的实现synchronized来实现。\n因此，synchronized块之间的操作也是原子性的。\n（2）可见性\n可见性是指当一个线程修改了共享变量的值，其它线程能立即感知到这种变化。\nJava内存模型是通过在变更修改后同步回主内存，在变量读取前从主内存刷新变量值来实现的，它是依赖主内存的，无论是普通变量还是volatile变量都是如此。\n普通变量与volatile变量的主要区别是是否会在修改之后立即同步回主内存，以及是否在每次读取前立即从主内存刷新。因此我们可以说volatile变量保证了多线程环境下变量的可见性，但普通变量不能保证这一点。\n除了volatile之外，还有两个关键字也可以保证可见性，它们是synchronized和final。\nsynchronized的可见性是由“对一个变量执行unlock操作之前，必须先把此变量同步回主内存中，即执行store和write操作”这条规则获取的。\nfinal的可见性是指被final修饰的字段在构造器中一旦被初始化完成，那么其它线程中就能看见这个final字段了。\n（3）有序性\nJava程序中天然的有序性可以总结为一句话：如果在本线程中观察，所有的操作都是有序的；如果在另一个线程中观察，所有的操作都是无序的。\n前半句是指线程内表现为串行的语义，后半句是指“指令重排序”现象和“工作内存和主内存同步延迟”现象。\nJava中提供了volatile和synchronized两个关键字来保证有序性。\nvolatile天然就具有有序性，因为其禁止重排序。\nsynchronized的有序性是由“一个变量同一时刻只允许一条线程对其进行lock操作”这条规则获取的。\n ThreadLocal Java基础 说下Java的基本类型   byte/8bit/1B\n  char/16Bit/2B\n  short/16Bit/2B\n  int/32Bit/4B\n  float/32Bit/4B\n  long/64Bit/8B\n  double/64Bit/8B\n  boolen/~\n boolean 只有两个值：true、false，可以使用 1 bit 来存储，但是具体大小没有明确规定。JVM 会在编译时期将 boolean 类型的数据转换为 int，使用 1 来表示 true，0 表示 false。JVM 支持 boolean 数组，但是是通过读写 byte 数组来实现的。\n   自动拆包箱\nInteger x = 2; // 装箱 调用了 Integer.valueOf(2) int y = x; // 拆箱 调用了 X.intValue() 参考\nInteger a = 300; Integer b = 300; System.out.println(a == b);//返回false，因==比较的是对象的地址  Integer a = 127; Integer b = 127; System.out.println(a == b);//返回true，因java默认缓存了-128到127之间的值    缓存池\nnew Integer(123) 与 Integer.valueOf(123) 的区别在于：\n new Integer(123) 每次都会新建一个对象； Integer.valueOf(123) 会使用缓存池中的对象，多次调用会取得同一个对象的引用。  Integer x = new Integer(123); Integer y = new Integer(123); System.out.println(x == y); // false Integer z = Integer.valueOf(123); Integer k = Integer.valueOf(123); System.out.println(z == k); // true valueOf() 方法的实现比较简单，就是先判断值是否在缓存池中，如果在的话就直接返回缓存池的内容。\npublic static Integer valueOf(int i) { if (i \u0026gt;= IntegerCache.low \u0026amp;\u0026amp; i \u0026lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i); }   重载和重写  重写是使用注解@Override重写父类的方法 重载是同一个类，相同方法名，但是参数个数，类型，顺序，有一个不一样。返回值类型可以一样可以不一样  讲一下String String 被声明为 final，因此它不可被继承。(Integer 等包装类也不能被继承）\n在 Java 8 中，String 内部使用 char 数组存储数据。\npublic final class String implements java.io.Serializable, Comparable\u0026lt;String\u0026gt;, CharSequence { /** The value is used for character storage. */ private final char value[]; } 在 Java 9 之后，String 类的实现改用 byte 数组存储字符串，同时使用 coder 来标识使用了哪种编码。\npublic final class String implements java.io.Serializable, Comparable\u0026lt;String\u0026gt;, CharSequence { /** The value is used for character storage. */ private final byte[] value; /** The identifier of the encoding used to encode the bytes in {@code value}. */ private final byte coder; } value 数组被声明为 final，这意味着 value 数组初始化之后就不能再引用其它数组。并且 String 内部没有改变 value 数组的方法，因此可以保证 String 不可变。\n String Pool  字符串常量池（String Pool）保存着所有字符串字面量（literal strings），这些字面量在编译时期就确定。不仅如此，还可以使用 String 的 intern() 方法在运行过程将字符串添加到 String Pool 中。\n当一个字符串调用 intern() 方法时，如果 String Pool 中已经存在一个字符串和该字符串值相等（使用 equals() 方法进行确定），那么就会返回 String Pool 中字符串的引用；否则，就会在 String Pool 中添加一个新的字符串，并返回这个新字符串的引用。\n下面示例中，s1 和 s2 采用 new String() 的方式新建了两个不同字符串，而 s3 和 s4 是通过 s1.intern() 和 s2.intern() 方法取得同一个字符串引用。intern() 首先把 \u0026ldquo;aaa\u0026rdquo; 放到 String Pool 中，然后返回这个字符串引用，因此 s3 和 s4 引用的是同一个字符串。\nString s1 = new String(\u0026#34;aaa\u0026#34;); String s2 = new String(\u0026#34;aaa\u0026#34;); System.out.println(s1 == s2); // false String s3 = s1.intern(); String s4 = s2.intern(); System.out.println(s3 == s4); // true 如果是采用 \u0026ldquo;bbb\u0026rdquo; 这种字面量的形式创建字符串，会自动地将字符串放入 String Pool 中。\nString s5 = \u0026#34;bbb\u0026#34;; String s6 = \u0026#34;bbb\u0026#34;; System.out.println(s5 == s6); // true   new String(\u0026ldquo;abc\u0026rdquo;)\n使用这种方式一共会创建两个字符串对象（前提是 String Pool 中还没有 \u0026ldquo;abc\u0026rdquo; 字符串对象）。\n \u0026ldquo;abc\u0026rdquo; 属于字符串字面量，因此编译时期会在 String Pool 中创建一个字符串对象，指向这个 \u0026ldquo;abc\u0026rdquo; 字符串字面量； 而使用 new 的方式会在堆中创建一个字符串对象。  创建一个测试类，其 main 方法中使用这种方式来创建字符串对象。\npublic class NewStringTest { public static void main(String[] args) { String s = new String(\u0026#34;abc\u0026#34;); } }   讲一下final  final声明的数据为常量，初始化后不可以被更改 对于基本类型，final声明的变量，值不可以被更改 对于引用类型，final声明的变量，引用不可以被更改，也就是不能引用其他对象，但是被引用的对象本身可以修改 final修饰的方法，不能被子类重写 final修饰的类，不能被继承  讲一下Static   static修饰的变量叫静态变量，这个变量属于这个类，类的所有都共享变量，可以通过类名直接访问他，整个内存中只存在一份，在jvm方法区的静态常量池里\n  static修饰的方法叫静态方法，它不依赖于任何实例，所以静态方法必须要有实现，也就是不能abstract，内部也只能访问静态字段和静态方法，方法中不能有this或者super关键字，因为这两个关键字与具体的对象关联\n  static修饰的代码块，只会在类初始化的时候执行一次\n  static修饰的内部类是静态内部类，非静态内部类依赖于外部类的实例，也就是要先创建外部类的实例才可以用这个实例去创建非静态内部类，而静态内部类不需要。静态内部类不能访问外部类的非静态的变量和方法\npublic class OuterClass { class InnerClass { } static class StaticInnerClass { } public static void main(String[] args) { // InnerClass innerClass = new InnerClass(); // \u0026#39;OuterClass.this\u0026#39; cannot be referenced from a static context  OuterClass outerClass = new OuterClass(); InnerClass innerClass = outerClass.new InnerClass(); StaticInnerClass staticInnerClass = new StaticInnerClass(); } }   存在继承的情况下，初始化顺序为：\n 父类（静态变量、静态语句块） 子类（静态变量、静态语句块） 父类（实例变量、普通语句块） 父类（构造函数） 子类（实例变量、普通语句块） 子类（构造函数）    讲一下equals和hashCode以及clone   equals\n等价与相等\n 对于基本类型，== 判断两个值是否相等，基本类型没有 equals() 方法。 对于引用类型，== 判断两个变量是否引用同一个对象，而 equals() 判断引用的对象是否等价。  //重写 public class EqualExample { private int x; private int y; private int z; public EqualExample(int x, int y, int z) { this.x = x; this.y = y; this.z = z; } @Override public boolean equals(Object o) { if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; EqualExample that = (EqualExample) o; if (x != that.x) return false; if (y != that.y) return false; return z == that.z; } }   hashCode\nhashCode() 返回哈希值，而 equals() 是用来判断两个对象是否等价。等价的两个对象散列值一定相同，但是散列值相同的两个对象不一定等价，这是因为计算哈希值具有随机性，两个值不同的对象可能计算出相同的哈希值。\n所以在覆盖 equals() 方法时应当总是覆盖 hashCode() 方法，保证等价的两个对象哈希值也相等。\nHashSet 和 HashMap 等集合类使用了 hashCode() 方法来计算对象应该存储的位置，因此要将对象添加到这些集合类中，需要让对应的类实现 hashCode() 方法。\n  clone\nclone() 是 Object 的 protected 方法，它不是 public，一个类不显式去重写 clone()，其它类就不能直接去调用该类实例的 clone() 方法。\npublic class CloneExample { private int a; private int b; }\tCloneExample e1 = new CloneExample(); // CloneExample e2 = e1.clone(); // \u0026#39;clone()\u0026#39; has protected access in \u0026#39;java.lang.Object\u0026#39; 重写 clone() 得到以下实现：\npublic class CloneExample { private int a; private int b; @Override public CloneExample clone() throws CloneNotSupportedException { return (CloneExample)super.clone(); } } CloneExample e1 = new CloneExample(); try { CloneExample e2 = e1.clone(); } catch (CloneNotSupportedException e) { e.printStackTrace(); } java.lang.CloneNotSupportedException: CloneExample 以上抛出了 CloneNotSupportedException，这是因为 CloneExample 没有实现 Cloneable 接口。\n应该注意的是，clone() 方法并不是 Cloneable 接口的方法，而是 Object 的一个 protected 方法。Cloneable 接口只是规定，如果一个类没有实现 Cloneable 接口又调用了 clone() 方法，就会抛出 CloneNotSupportedException。\npublic class CloneExample implements Cloneable { private int a; private int b; @Override public Object clone() throws CloneNotSupportedException { return super.clone(); } }   如何实现浅拷贝和深拷贝   浅拷贝\n拷贝对象和原始对象的引用类型引用同一个对象。\n  深拷贝\n拷贝对象和原始对象的引用类型引用不同对象。\n  替代clone的方法\n重写一个工厂构造方法\n用ObjectInputStrem和ObjectOutputStream\n  java限定符 Java 中有三个访问权限修饰符：private、protected 以及 public，如果不加访问修饰符，表示包级可见。\n可以对类或类中的成员（字段和方法）加上访问修饰符。\n 类可见表示其它类可以用这个类创建实例对象。 成员可见表示其它类可以用这个类的实例对象访问到该成员；  接口和抽象类   抽象类\n抽象类和抽象方法都使用 abstract 关键字进行声明。如果一个类中包含抽象方法，那么这个类必须声明为抽象类。\n抽象类和普通类最大的区别是，抽象类不能被实例化，只能被继承。\n  接口\n接口是抽象类的延伸，在 Java 8 之前，它可以看成是一个完全抽象的类，也就是说它不能有任何的方法实现。\n从 Java 8 开始，接口也可以拥有默认的方法实现，这是因为不支持默认方法的接口的维护成本太高了。在 Java 8 之前，如果一个接口想要添加新的方法，那么要修改所有实现了该接口的类，让它们都实现新增的方法。\n接口的成员（字段 + 方法）默认都是 public 的，并且不允许定义为 private 或者 protected。从 Java 9 开始，允许将方法定义为 private，这样就能定义某些复用的代码又不会把方法暴露出去。\n接口的字段默认都是 static 和 final 的。\n  比较\n 从设计层面上看，抽象类提供了一种 IS-A 关系，需要满足里式替换原则，即子类对象必须能够替换掉所有父类对象。而接口更像是一种 LIKE-A 关系，它只是提供一种方法实现契约，并不要求接口和实现接口的类具有 IS-A 关系。 从使用上来看，一个类可以实现多个接口，但是不能继承多个抽象类。 接口的字段只能是 static 和 final 类型的，而抽象类的字段没有这种限制。 接口的成员只能是 public 的，而抽象类的成员可以有多种访问权限。    说一说你理解的多态  实现多态的必要条件：  继承 重写 父类引用指向子类对象：Parent p = new Child();   重写、接口、抽象类和抽象方法 多态实际上就是一种事物的不同体现，例如同样的human对象，实现可以是women也可以是man，这就是多态  讲一下泛型和注解   注解就是代码中的特殊标记，这些标记可以在编译、类加载、运行时被读取，并执行相对应的处理\n  开发中用到了哪些注解？\n我用到Spring特别多，常见的@Controller，@Param，@Service，有的项目会用到lombok注解，@Data，@Slf4j等。java原生也有@Overried，@Deprecated，@FunctionalInterface，java原生的注解多用于标记和检查。\n除了这些基本注解，还有一个注解叫元注解，用于描述注解的注解。常见的有@Retention,@Target。@Retention用于设置注解的生命周期，@Target用于设置注解的修饰地方，例如类、方法、参数，成员变量等\n @Retention注解传入的是RetentionPolicy枚举，该枚举有三个常量，分别是SOURCE、CLASS和RUNTIME，SOURCE代表着注解仅保留在源级别中，并由编译器忽略。CLASS代表着注解在编译时由编译器保留，但Java虚拟机（JVM）会忽略。RUNTIME代表着标记的注解会由JVM保留，因此运行时环境可以使用它。   从上面的图可以发现有个「注解抽象语法树」，这里其实就会去解析注解，然后做处理的逻辑。如果你想要在编译期间处理注解相关的逻辑，你需要继承AbstractProcessor 并实现process方法。比如可以看到lombok就用AnnotationProcessor继承了AbstractProcessor。lombok的实现原理就是在这（为什么使用了个@Data这样的注解就能有set/get等方法了，就是在这里加上去的）    泛型就是在创建对象或者调用方法时才明确具体的类型，使用泛型的好处就是代码更加简洁（不再需要强制转换），程序更加健壮（在编译期间没有警告，在运行期就不会出现ClassCastException异常），再明确一下泛型就是「在创建对象或调用方法的时候才明确下具体的类型」，而组件为了做到足够的通用性，是不知道「用户」传入什么类型参数进来的，所以在这种情况下用泛型就是很好的实践。\n一般会使用反射+泛型组合使用\n  讲一下反射和动态代理   反射：简单说反射就是Java可以给我们在运行时获取类的信息，核心是在运行时。\n运行时指的就是我们在编译器写的代码是 .java 文件，经过javac 编译会变成 .class 文件，class 文件会被JVM装载运行（这里就是真正运行着我们所写的代码（虽然是被编译过的），也就所谓的运行时。\n获取类的原信息，字段和方法用的比较多\n 每个类都有一个 Class 对象，包含了与类有关的信息。当编译一个新类时，会产生一个同名的 .class 文件，该文件内容保存着 Class 对象。\n类加载相当于 Class 对象的加载，类在第一次使用时才动态加载到 JVM 中。也可以使用 Class.forName(\u0026quot;com.mysql.jdbc.Driver\u0026quot;) 这种方式来控制类的加载，该方法会返回一个 Class 对象。\n反射可以提供运行时的类信息，并且这个类可以在运行时才加载进来，甚至在编译时期该类的 .class 不存在也可以加载进来。\nClass 和 java.lang.reflect 一起对反射提供了支持，java.lang.reflect 类库主要包含了以下三个类：\n Field ：可以使用 get() 和 set() 方法读取和修改 Field 对象关联的字段； Method ：可以使用 invoke() 方法调用与 Method 对象关联的方法； Constructor ：可以用 Constructor 的 newInstance() 创建新的对象。  反射的优点：\n 可扩展性 ：应用程序可以利用全限定名创建可扩展对象的实例，来使用来自外部的用户自定义类。 类浏览器和可视化开发环境 ：一个类浏览器需要可以枚举类的成员。可视化开发环境（如 IDE）可以从利用反射中可用的类型信息中受益，以帮助程序员编写正确的代码。 调试器和测试工具 ： 调试器需要能够检查一个类里的私有成员。测试工具可以利用反射来自动地调用类里定义的可被发现的 API 定义，以确保一组测试中有较高的代码覆盖率。  反射的缺点：\n尽管反射非常强大，但也不能滥用。如果一个功能可以不用反射完成，那么最好就不用。在我们使用反射技术时，下面几条内容应该牢记于心。\n 性能开销 ：反射涉及了动态类型的解析，所以 JVM 无法对这些代码进行优化。因此，反射操作的效率要比那些非反射操作低得多。我们应该避免在经常被执行的代码或对性能要求很高的程序中使用反射。 安全限制 ：使用反射技术要求程序必须在一个没有安全限制的环境中运行。如果一个程序必须在有安全限制的环境中运行，如 Applet，那么这就是个问题了。 内部暴露 ：由于反射允许代码执行一些在正常情况下不被允许的操作（比如访问私有的属性和方法），所以使用反射可能会导致意料之外的副作用，这可能导致代码功能失调并破坏可移植性。反射代码破坏了抽象性，因此当平台发生改变的时候，代码的行为就有可能也随着变化。     动态代理\nJDK自带的动态代理，实现InvocationHandler接口\nCGLIB，通过修改字节码文件达到代理\n  Java的几种引用，你用过几种 说说进程和线程的区别 Java集合 讲一讲集合类，常用的集合，以及在多线程下你是如何保集合安全的   ArrayList\n/** * 默认容量 */ private static final int DEFAULT_CAPACITY = 10; /** * 空数组，如果传入的容量为0时使用 */ private static final Object[] EMPTY_ELEMENTDATA = {}; /** * 空数组，传传入容量时使用，添加第一个元素的时候会重新初始为默认容量大小 */ private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {}; /** * 存储元素的数组 */ transient Object[] elementData; // non-private to simplify nested class access  /** * 集合中元素的个数 */ private int size; （1）ArrayList内部使用数组存储元素，当数组长度不够时进行扩容，每次加一半的空间，ArrayList不会进行缩容；\n（2）ArrayList支持随机访问，通过索引访问元素极快，时间复杂度为O(1)；\n（3）ArrayList添加元素到尾部极快，平均时间复杂度为O(1)；\n（4）ArrayList添加元素到中间比较慢，因为要搬移元素，平均时间复杂度为O(n)；\n（5）ArrayList从尾部删除元素极快，时间复杂度为O(1)；\n（6）ArrayList从中间删除元素比较慢，因为要搬移元素，平均时间复杂度为O(n)；\n（7）ArrayList支持求并集，调用addAll(Collection\u0026lt;? extends E\u0026gt; c)方法即可；\n（8）ArrayList支持求交集，调用retainAll(Collection\u0026lt;? extends E\u0026gt; c)方法即可；\n（7）ArrayList支持求单向差集，调用removeAll(Collection\u0026lt;? extends E\u0026gt; c)方法即可；\n  CopyOnWriteArrayList\n（1）CopyOnWriteArrayList使用ReentrantLock重入锁加锁，保证线程安全；\n（2）CopyOnWriteArrayList的写操作都要先拷贝一份新数组，在新数组中做修改，修改完了再用新数组替换老数组，所以空间复杂度是O(n)，性能比较低下；\n（3）CopyOnWriteArrayList的读操作支持随机访问，时间复杂度为O(1)；\n（4）CopyOnWriteArrayList采用读写分离的思想，读操作不加锁，写操作加锁，且写操作占用较大内存空间，所以适用于读多写少的场合；\n（5）CopyOnWriteArrayList只保证最终一致性，不保证实时一致性；\n  HashMap\n在Java中，HashMap的实现采用了（数组 + 链表 + 红黑树）的复杂结构，数组的一个元素又称作桶。\n在添加元素时，会根据hash值算出元素在数组中的位置，如果该位置没有元素，则直接把元素放置在此处，如果该位置有元素了，则把元素以链表的形式放置在链表的尾部。\n当一个链表的元素个数达到一定的数量（且数组的长度达到一定的长度）后，则把链表转化为红黑树，从而提高效率。\n数组的查询效率为O(1)，链表的查询效率是O(k)，红黑树的查询效率是O(log k)，k为桶中的元素个数，所以当元素数量非常多的时候，转化为红黑树能极大地提高效率。\n（1）容量\n容量为数组的长度，亦即桶的个数，默认为16，最大为2的30次方，当容量达到64时才可以树化。\n（2）装载因子\n装载因子用来计算容量达到多少时才进行扩容，默认装载因子为0.75。\n（3）树化\n树化，当容量达到64且链表的长度达到8时进行树化，当链表的长度小于6时反树化。\n总结\n（1）HashMap是一种散列表，采用（数组 + 链表 + 红黑树）的存储结构；\n（2）HashMap的默认初始容量为16（1\u0026laquo;4），默认装载因子为0.75f，容量总是2的n次方；\n（3）HashMap扩容时每次容量变为原来的两倍；\n（4）当桶的数量小于64时不会进行树化，只会扩容；\n（5）当桶的数量大于64且单个桶中元素的数量大于8时，进行树化；\n（6）当单个桶中元素数量小于6时，进行反树化；\n（7）HashMap是非线程安全的容器；\n（8）HashMap查找添加元素的时间复杂度都为O(1)；\n  JVM JVM是什么 java虚拟机\nJava内存模型 Java内存模型是跟「并发」相关的，它是为了屏蔽底层细节而提出的规范，希望在上层(Java层面上)在操作内存时在不同的平台上也有相同的效果\nJava编译到执行的过程   编译\n将源码文件编译成JVM可以解释的class文件。\n编译过程会对源代码程序做 「语法分析」「语义分析」「注解处理」等等处理，最后才生成字节码文件。\n比如对泛型的擦除和我们经常用的Lombok就是在编译阶段干的。\n  加载\n  装载\n【装载时机】为了节省内存的开销，并不会一次性把所有的类都装载至JVM，而是等到「有需要」的时候才进行装载（比如new和反射等等）\n【装载发生】class文件是通过「类加载器」装载到jvm中的，为了防止内存中出现多份同样的字节码，使用了双亲委派机制（它不会自己去尝试加载这个类，而是把请求委托给父加载器去完成，依次向上）\n【装载规则】JDK 中的本地方法类一般由根加载器（Bootstrp loader）装载，JDK 中内部实现的扩展类一般由扩展加载器（ExtClassLoader ）实现装载，而程序中的类文件则由系统加载器（AppClassLoader ）实现装载。\n装载这个阶段它做的事情可以总结为：查找并加载类的二进制数据，在JVM「堆」中创建一个java.lang.Class类的对象，并将类相关的信息存储在JVM「方法区」中，\n通过「装载」这个步骤后，现在已经把class文件装载到JVM中了，并创建出对应的Class对象以及类信息存储至方法区了。\n  连接\n 验证：验证类是否符合 Java 规范和 JVM 规范 准备：为类的静态变量分配内存，初始化为系统的初始值 解析：将符号引用转为直接引用的过程  通过「连接」这个步骤后，现在已经对class信息做校验并分配了内存空间和默认值了。\n  初始化\n收集class的静态变量、静态代码块、静态方法至()方法，随后从上往下开始执行。\n    解释\n把字节码转换为操作系统识别的指令\n  执行\n操作系统把解释器解析出来的指令码，调用系统的硬件执行最终的程序指令。\n  双亲委派机制是干什么的   **前置知识：**JDK中默认类加载器有三个：AppClassLoader、Ext ClassLoader、BootStrap ClassLoader。AppClassLoader的父加载器为Ext ClassLoader、Ext ClassLoader的父加载器为BootStrap ClassLoader。这里的父子关系并不是通过继承实现的，而是组合。\n  **什么是双亲委派机制：**加载器在加载过程中，先把类交由父类加载器进行加载，父类加载器没找到才由自身加载。\n  **双亲委派机制目的：**为了防止内存中存在多份同样的字节码（安全）\n  **类加载规则：**如果一个类由类加载器A加载，那么这个类的依赖类也是由「相同的类加载器」加载。\n  **如何打破双亲委派机制：**自定义ClassLoader，重写loadClass方法（只要不依次往上交给父加载器进行加载，就算是打破双亲委派机制）\n  **打破双亲委派机制案例：**Tomcat\n 为了Web应用程序类之间隔离，为每个应用程序创建WebAppClassLoader类加载器 为了Web应用程序类之间共享，把ShareClassLoader作为WebAppClassLoader的父类加载器，如果WebAppClassLoader加载器找不到，则尝试用ShareClassLoader进行加载 为了Tomcat本身与Web应用程序类隔离，用CatalinaClassLoader类加载器进行隔离，CatalinaClassLoader加载Tomcat本身的类 为了Tomcat与Web应用程序类共享，用CommonClassLoader作为CatalinaClassLoader和ShareClassLoader的父类加载器 ShareClassLoader、CatalinaClassLoader、CommonClassLoader的目录可以在Tomcat的catalina.properties进行配置    **线程上下文加载器：**由于类加载的规则，很可能导致父加载器加载时依赖子加载器的类，导致无法加载成功（BootStrap ClassLoader无法加载第三方库的类），所以存在「线程上下文加载器」来进行加载。\n  JVM内存结构 其中：堆和方法区是线程共享的，其他地方是线程隔离的\n  堆：\n嗯，「堆」是线程共享的区域，几乎类的实例和数组分配的内存都来自于它\n堆又可以细分为以下几个区域\n 伊甸园区 生存者区1，生存者区2 老年区    虚拟机栈：每个线程在创建的时候都会创建一个「虚拟机栈」，每次方法调用都会创建一个「栈帧」。每个「栈帧」会包含几块内容：局部变量表、操作数栈、动态连接和返回地址，了解了「虚拟机栈」的组成后，也不难猜出它的作用了：它保存方法了局部变量、部分变量的计算并参与了方法的调用和返回。\n就是保存了方法的局部变量表，方法的调用和返回都在里面\n  本地方法栈：本地方法栈跟虚拟机栈的功能类似，虚拟机栈用于管理 Java 函数的调用，而本地方法栈则用于管理本地方法的调用。这里的「本地方法」指的是「非Java方法」，一般本地方法是使用C语言实现的。和虚拟机栈保存的东西一样，只不过不是java方法\n  方法区：\nHotSpot虚拟机中，在JDK8中，已经用「元空间」来替代了「永久代」作为「方法区」的实现了。方法区主要是用来存放已被虚拟机加载的「类相关信息」：包括类信息、常量池。\n  类信息又包括了类的版本、字段、方法、接口和父类等信息\n  常量池又可以分「静态常量池」和「运行时常量池」\n静态常量池主要存储的是「字面量」以及「符号引用」等信息，静态常量池也包括了我们说的「字符串常量池」。\n「运行时常量池」存储的是「类加载」时生成的「直接引用」等信息。\n 又值得注意的是：从「逻辑分区」的角度而言「常量池」是属于「方法区」的，但自从在「JDK7」以后，就已经把「运行时常量池」和「静态常量池」转移到了「堆」内存中进行存储（对于「物理分区」来说「运行时常量池」和「静态常量池』就属于堆）\n 元空间和永久代最主要的区别就是：「元空间」存储不在虚拟机中，而是使用本地内存，JVM 不会再出现方法区的内存溢出，以往「永久代」经常因为内存不够用导致跑出OOM异常。\n    程序计数器：Java是多线程的语言，我们知道假设线程数大于CPU数，就很有可能有「线程切换」现象，切换意味着「中断」和「恢复」，那自然就需要有一块区域来保存「当前线程的执行信息」，所以，程序计数器就是用于记录各个线程执行的字节码的地址（分支、循环、跳转、异常、线程恢复等都依赖于计数器），简单点说就是记录线程中代码走到哪了\n  垃圾回收   如何判断是否是一个垃圾呢\n  引用计数法：\n引用计数法思路很简单：当对象被引用则+1，但对象引用失败则-1。当计数器为0时，说明对象不再被引用，可以被可回收，\n引用计数法最明显的缺点就是：如果对象存在循环依赖，那就无法定位该对象是否应该被回收（A依赖B，B依赖A）\n  可达性算法\n判断对象与GCROOT之间是否可达，不可达即是垃圾\nGCROOT\n「GC Roots」是一组必须「活跃」的引用。从「GC Root」出发，程序通过直接引用或者间接引用，能够找到可能正在被使用的对象\n  当前活跃的栈帧指向堆里的对象引用就可以是「GC Roots」\n 比如我们上次不是聊到JVM内存结构中的虚拟机栈吗，虚拟机栈里不是有栈帧吗，栈帧不是有局部变量吗？局部变量不就存储着引用嘛。\n那如果栈帧位于虚拟机栈的栈顶，是不是就可以说明这个栈帧是活跃的（换言之，是线程正在被调用的）\n既然是线程正在调用的，那栈帧里的指向「堆」的对象引用，是不是一定是「活跃」的引用？\n所以，当前活跃的栈帧指向堆里的对象引用就可以是「GC Roots」\n   比如类的静态变量引用是「GC Roots」，被「Java本地方法」所引用的对象也是「GC Roots」\n      回收过程\n  标记\n  清除\n直接清除会有「内存碎片」的问题：可能我有10M的空余内存，但程序申请9M内存空间却申请不下来（10M的内存空间是垃圾清除后的，不连续的）\n我把「标记」存活的对象「复制」到另一块空间，复制完了之后，直接把原有的整块空间给干掉！这样就没有内存碎片的问题了\n这种做法缺点又很明显：内存利用率低，得有一块新的区域给我复制(移动)过去\n还有一种「折中」的办法，我未必要有一块「大的完整空间」才能解决内存碎片的问题，我只要能在「当前区域」内进行移动\n把存活的对象移到一边，把垃圾移到一边，那再将垃圾一起删除掉，不就没有内存碎片了嘛\n这种专业的术语就叫做「整理」\n    STW：stop the world\n回收垃圾的时候，程序是有短暂的时间不能正常继续运作啊。不然JVM在回收的时候，用户线程还继续分配修改引用，JVM怎么搞\n  年轻代的垃圾收集器使用的都是「标记复制算法」\n所以在「堆内存」划分中，将年轻代划分出Survivor区（Survivor From 和Survivor To），目的就是为了有一块完整的内存空间供垃圾回收器进行拷贝(移动)\n  什么时候会从新生代进入老年代\n 如果对象太大了，就会直接进入老年代（对象创建时就很大 || Survivor区没办法存下该对象） 如果对象太老了，那就会晋升至老年代（每发生一次Minor GC ，存活的对象年龄+1，达到默认值15则晋升老年代 || 动态对象年龄判定 可以进入老年代）    当Eden区空间不足时，就会触发Minor GC\n  平时如何调优 一般调优JVM我们认为会有几种指标可以参考：『吞吐量』、『停顿时间』和『垃圾回收频率』\n 内存区域大小以及相关策略（比如整块堆内存占多少、新生代占多少、老年代占多少、Survivor占多少、晋升老年代的条件等等）  比如（-Xmx：设置堆的最大值、-Xms：设置堆的初始值、-Xmn：表示年轻代的大小、-XX:SurvivorRatio：伊甸区和幸存区的比例等等）\n（按经验来说：IO密集型的可以稍微把「年轻代」空间加大些，因为大多数对象都是在年轻代就会灭亡。内存计算密集型的可以稍微把「老年代」空间加大些，对象存活时间会更长些）\n  通过jps命令查看Java进程「基础」信息（进程号、主类）。这个命令很常用的就是用来看当前服务器有多少Java进程在运行，它们的进程号和加载主类是啥\n  jps -l 查看主类，进程\n  jps -v 查看jvm参数\n  通过jstat命令查看Java进程「统计类」相关的信息（类加载、编译相关信息统计，各个内存区域GC概况和统计）。这个命令很常用于看GC的情况\n  gc回收统计 jstat -gc pid\n  堆内存统计 jstat -gccapacity pid\n  jmap -dump:live,format=b,file=/home/tess.dump\n产生一个HeapDump文件\n  XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/heapdump.hprof\n增加oom的时候，自动导出当前堆的dump\n这个命令很常用于把JVM内存信息dump到文件，然后再用MAT( Memory Analyzer tool 内存解析工具)把文件进行分析\n  通过jinfo命令来查看和调整Java进程的「运行参数」。\n  通过jstack命令来查看JVM「线程信息」。这个命令用常用语排查死锁相关的问题\n  一个对象到底有多大，“对象在内存中长什么样子” 1.对象头中的Mark Word（标记字）主要用来表示对象的线程锁状态，另外还可以用来配合GC、存放该对象的hashCode；\n2.Klass Word是一个指向方法区中Class信息的指针，意味着该对象可随时知道自己是哪个Class的实例；\n3.数组长度也是占用64位（8字节）的空间，这是可选的，只有当本对象是一个数组对象时才会有这个部分；\n4.对象体是用于保存对象属性和值的主体部分，占用内存空间取决于对象的属性数量和类型；\n5.对齐字是为了减少堆内存的碎片空间（不一定准确）。\n网络 交换机和路由器区别 Nas知道吗 什么长链接，什么时候该用长链接，什么又是长轮训，短轮训。java怎么实现 java怎么写UDP？为什么要用UDP 异步请求知道吗？有什么场景可以用到吗，java怎么写？ 讲一下TCP/IP，它和HTTP的关系 什么是WebSocket，WS是长链接吗，WSS又有什么区别？ TCP长链接和HTTP长链接有什么区别 Netty干什么的，用过吗 你知道哪些网络模型？   OSI网络7层模型\n 应用层：各种web应用 表示层：数据格式标识，基本加解密 会话层：控制各个程序之间的会话能力，软件数据分发给其他不同的软件 传输层：TCP UDP协议 网络层：定义IP地址，定义路由的基本功能，实现设备之间的数据转发 数据链路层：定义数据的基本格式，如何传输、如何标识，例如网卡的MAC地址 物理层：物理设备的传输，例如网卡标准、网线标准    TCP/IP模型\n 应用层：各种基于TCP/IP的协议，例如HTTP、FTP、SMTP 传输层：TCP或者UDP协议 网络层：它负责为两台主机提供通信服务，并通过选择合适的路由将数据传递到目标主机。 网络接口层：物理设备的环境    五层网络模型\n由OSI7层模型演变而来\n  你知道哪些IO模型，BIO、NIO、AIO都是什么，他们的使用场景是什么   java中的IO模型\n  BIO\nBlocking IO，传统的同步阻塞IO，对应着java.io，例如文件的读取，输入输出流，Socket的网络编程\n  NIO\nNo Blocking IO/New IO，同步非阻塞IO，对应着jdk1.4之后进入的nio，对于java.nio，提供了Channel，Buffer，Selector等抽象\n  AIO\nAsync IO ，异步非阻塞IO，在 Java 7 中引入了 NIO 的改进版 NIO 2,它是异步非阻塞的IO模型\n    java中的io操作最终还是依赖于操作系统的io实现的，如在Linux 2.6以后，Java中的NIO和AIO都是通过 epoll\n  Linux中的IO模型\n  BIO\n 一个输入操作通常包括两个不同的阶段:\n 等待数据准备好 从内核向进程复制数据  对于一个套接字上的输入操作，第一步通常涉及等待数据从网络中到达，当所等待分组到达时，它被复制到内核中的某个缓冲区，第二步就是把数据从内核缓冲区复制到应用进程缓冲区。\n从上图可以看出，应用进程通过 系统调用 recvfrom 去接收数据，而由于内核数据没有准备好，应用进程就会阻塞，直到内核准备好数据并将其从内核复制到应用进程的缓冲区中或者发生错误才返回。最常见的错误就是系统调用被信号中断。进程从调用recvfrom开始到它返回的整段时间内是被阻塞的。\nLinux下的阻塞式I/O模型就对应了Java下的BIO模型，BIO的底层实现是调用操作系统的API去执行的，也就是调用操作系统的Socket套接字。\n   NIO\n 应用进程通过系统调用 recvfrom 不断的去和内核交互，直到内核数据报准备好，而如果内核无数据准备好，转而立即返回一个 EWOULDBLOCK的错误，过一段时间再次发送 recvfrom请求，在此期间进程可以做其他事情，不用一直等待，这就是非阻塞。\n当一个应用进程循环调用 recvfrom时，我们称之为轮询(polling)，应用进程持续轮询内核，以查看某个操作是否就绪。Java的NIO映射到Linux操作系统就是如上图所示的非阻塞I/O模型\n   I/O复用模型\n IO多路复用使用select/poll/epoll函数，多个进程的IO都可以注册在同一个 select 上，当用户进程调用该 select时，select去监听所有注册好的IO,如果所有被监听的IO需要的数据都没有准备好，那么 select调用进程会被阻塞，只要任意一个IO的数据报套接字变为可读，即数据报已经准备好，select 就返回套接字可读这一条件，然后调用 recvfrom把所读数据报复制到应用进程缓冲区。\n强调一点就是，IO多路复用模型并没有涉及到非阻塞，进程在发出select后，要一直阻塞等待其监听的所有IO操作至少有一个数据准备好才返回，强调阻塞状态，不存在非阻塞。\n而在 Java NIO中也可以实现多路复用，主要是利用多路复用器 Selector，与这里的 select函数类型，Selector会不断轮询注册在其上的通道Channel，如果有某一个Channel上面发生读或写事件，这个Channel处于就绪状态，就会被Selector轮询出来。\n   信号驱动式/io模型\n 应用进程预先向内核安装一个信号处理函数，然后立即返回，进程继续工作，不阻塞，当数据报准备好读取时，内核就为该进程产生一个信号通知进程，然后进程再调用recvfrom读取数据报。\n信号驱动式IO在数据准备阶段是异步的，当内核中有数据报准备后再通知进程，但是在调用 recvfrom操作进行数据拷贝时是同步的，所以总体来说，整个IO过程不能是异步的。\n   异步IO模型，AIO\n 应用进程调用aio_read函数，给内核传递描述符，缓存区指针，缓存区大小和文件偏移，并告诉内核当整个操作完成时如何通知进程，然后该系统调用立即返回，而且在等待I/O完成期间，我们的进程不被阻塞，进程可以去干其他事情，然后内核开始等待数据准备，数据准备好以后再拷贝数据到进程缓冲区，最后通知整个IO操作已完成。\nJava的AIO提供了异步通道API，其操作系统底层实现就是这个异步I/O模型\n     使用场景\n BIO方式适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中，JDK1.4以前的唯一选择，但程序直观简单易理解。\nNIO方式适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器，并发局限于应用中，编程比较复杂，JDK1.4开始支持。\nAIO方式适用于连接数目多且连接比较长（重操作）的架构，比如相册服务器，充分调用OS参与并发操作，编程比较复杂，JDK7开始支持。\n   讲一下Https、Http、Http1.0、Http1.1、Http2 什么是多路复用   IO多路复用是一种同步IO模型，实现一个线程可以监视多个文件句柄；一旦某个文件句柄就绪，就能够通知应用程序进行相应的读写操作；没有文件句柄就绪时会阻塞应用程序，交出cpu。多路是指多个网络连接多个句柄，复用指的是同一个线程（结合上图），实际上在代码中，一个线程去调用select方法，当没有连接准备好的时候，select阻塞。select返回连接列表，进行处理\nfds = [listen_fd] // 伪代码描述 while(1) { // 通过内核获取有读写事件发生的fd，只要有一个则返回，无则阻塞 // 整个过程只在调用select、poll、epoll这些调用的时候才会阻塞，accept/recv是不会阻塞 for (fd in select(fds)) { if (fd == listen_fd) { client_fd = accept(listen_fd) fds.append(client_fd) } elseif (len = recv(fd) \u0026amp;\u0026amp; len != -1) { // logic } } }   linux实现多路复用的方式\n  epoll的et和lt的区别\nepoll LT 与 ET模式的区别\n epoll有EPOLLLT和EPOLLET两种触发模式，LT是默认的模式，ET是“高速”模式。 LT模式下，只要这个fd还有数据可读，每次 epoll_wait都会返回它的事件，提醒用户程序去操作 ET模式下，它只会提示一次，直到下次再有数据流入之前都不会再提示了，无论fd中是否还有数据可读。所以在ET模式下，read一个fd的时候一定要把它的buffer读完，或者遇到EAGAIN错误    代码书写 聊聊设计模式，你知道哪些，用过哪些，为什么要用设计模式 数据结构 你知道哪些数据结构  树 线性表（数组和链表实现） 堆 图 字典（hashMap）  红黑树、B树、B+树、二叉树、完全平衡二叉树   树\n一种数据结构，每个元素可以有子树\n  二叉树\n一种“树”数据结构，满足每个元素最多只有2个子树。\n  遍历方式\n 前序遍历：中左右逐渐遍历，可以得到一条搜索路径，用于搜索。 中序遍历：左中右，可以得到一个有序列表。 后序遍历：用来计算一颗树算术表达式    满二叉树，所有除了叶子结点的节点都有2个节点\n  完全二叉树，叶子结点只会存在于倒数第一和倒数第二层，并且叶子结点都都偏左\n完全二叉树由于他的定义，可以使用数组来存放，而不用链表来存储，可以节省左右两个指针的大小空间。例如根节点是下标i，左节点下标就是2i，右节点下标就是2i+1\n  二叉搜索树(BST)\n根节点的值大于其左子树中任意一个节点的值，小于其右节点中任意一节点的值，这一规则适用于二叉查找树中的每一个节点。\n最好的时间复杂度是O(logn)，最快的情况会退化为链表\n  平衡二叉树(AVL)\n通过平衡的动作左旋和右旋，解决二叉搜索树退化为链表的问题。完全平衡二叉树是只保证左右子树的深度不会超过1\n  红黑树\n由于完全平衡二叉树要求左右子树深度不能超过1，导致每次插入一个新节点时都会带来平衡的动作。因为1特别苛刻，几乎每次都要平衡。最后平衡所花费的时间代价过高。\n解决，完全平衡二叉树平衡频率过于频繁。\n能够保证左右子树的高度不超过2倍时间复杂度log(n)\n 二叉搜索树：也称二叉查找树，或二叉排序树。定义也比较简单，要么是一颗空树，要么就是具有如下性质的二叉树： （1）若任意节点的左子树不空，则左子树上所有结点的值均小于它的根结点的 值； （2）若任意节点的右子树不空，则右子树上所有结点的值均大于它的根结点的 值； （3）任意节点的左、右子树也分别为二叉查找树； （4）没有键值相等的节点。\n平衡二叉树：在二叉搜索树的基础上多了两个重要的特点： （1）左右两子树的高度差的绝对值不能超过 1； （2）左右两子树也是一颗平衡二叉树。\n红黑树：红黑树是在普通二叉树上，对每个节点添加一个颜色属性形成的，需要同时满足一下五条性质： （1）节点是红色或者是黑色； （2）根节点是黑色； （3）每个叶节点（NIL 或空节点）是黑色； （4）每个红色节点的两个子节点都是黑色的（也就是说不存在两个连续的红色节 点）； （5）从任一节点到其没个叶节点的所有路径都包含相同数目的黑色节点。\n区别：AVL 树需要保持平衡，但它的旋转太耗时，而红黑树就是一个没有 AVL 树 那样平衡，因此插入、删除效率会高于 AVL 树，而 AVL 树的查找效率显然高于红黑树。\n   如果插入一个node引起了树的不平衡，AVL和RB-Tree(红黑树)都是最多只需要2次旋转操作，即两者都是O(1)；但是在删除node引起树的不平衡时，最坏情况下，AVL需要维护从被删node到root这条路径上所有node的平衡性，因此需要旋转的量级O(logN)，而RB-Tree最多只需3次(因为不需要严格的平衡，从根到叶子的最长的可能路径不多于最短的可能路径的两倍长)旋转以及修改节点的颜色，只需要O(1)的复杂度。\n  其次，AVL的结构相较RB-Tree来说更为平衡，在插入和删除node更容易引起Tree的unbalance，因此在大量数据需要插入或者删除时，AVL需要rebalance的频率会更高。因此，RB-Tree在需要大量插入和删除node的场景下，效率更高。自然，由于AVL高度平衡，因此AVL的search效率更高。\n  使用场景：IO多路复用epoll的实现采用红黑树组织管理sockfd，以支持快速的增删改查. ngnix中,用红黑树管理timer,因为红黑树是有序的,可以很快的得到距离当前最小的定时器. java中TreeMap，jdk1.8的hashmap的实现.\n      B树和B+树\nB树也是平时说的“B-”树，又叫平衡多路树。和二叉树不同，二叉树每个节点只会有2个子树。而B树有多个子树。M阶的B树是只最多子树是M个的B树。\n和二叉树一样，也是左小右大。\n B树节点存放数据，并且叶子节点不需要使用链表串联    手写一个链表，实现正向输出，反向输出，找到最中间的元素 什么是堆 堆是一种非线性结构，可以把堆看作一个数组，也可以被看作一个完全二叉树，通俗来讲堆其实就是利用完全二叉树的结构来维护的一维数组但堆并不一定是完全二叉树\n按照堆的特点可以把堆分为大顶堆和小顶堆 大顶堆：每个结点的值都大于或等于其左右孩子结点的值 小顶堆：每个结点的值都小于或等于其左右孩子结点的值\n使用堆的原因？ 如果仅仅是需要得到一个有序的序列，使用排序就可以很快完成，并不需要去组织一个新的数据结构。但是如果我们的需求是对于一个随时会有更新的序列，我要随时知道这个序列的最小值或最大值是什么。显然如果是线性结构，每次插入之后，假设原数组是有序的，那使用二分把它放在正确的位置也未尝不可，但是插入的时候从数组中留出空位就需要O(n)的时间复杂度，删除的时候亦然。\n时间复杂度\n插入和删除的时间复杂度是O(logn)\n场景：\njava中的Timer，就是通过堆来找到当前最小的时间戳，进行任务执行的\n环形队列   普通队列\n普通队列，数组实现时，出队后，原来的空间就浪费了。\n​\t环形队列，数组实现时，下标用模取运算，例如最大空间为5，模取后只会有0，1，2，3，4下标，组成了循环。\n front 变量的含义做一个调整： front 就指向队列的第一个元素, 也就是说 arr[front] 就是队列的第一个元素 front 的初始值 = 0 rear 变量的含义做一个调整：rear 指向队列的最后一个元素的后一个位置. 因为希望空出一个空间做为约定. rear 的初始值 = 0 当队列满时，条件是 (rear + 1) % maxSize == front 【满】 对队列为空的条件， rear == front 空 当我们这样分析， 队列中有效的数据的个数 (rear + maxSize - front) % maxSize // rear = 1 front = 0    时间轮\n使用场景，处理大批量的定时任务\n利用环形队列，队列的每个空间里存放的是任务的集合。\n例如以60秒为一个轮，70秒后执行一个任务。只需要一个timer按秒去旋转时间轮，70%60=10，到达第10个槽的时候，执行内部的所有任务即可。\n为了解决10秒和70秒落在同一个槽上，可以在任务身上加一个属性，圈数，例如10秒的任务圈数是0，70秒的任务是1，只有达到槽位置，并且圈数为0的任务才会被执行。\nkafaka的做法是，再做一个分钟轮，先转分钟轮。再转秒的轮。\n  算法 你能写出几个排序算法   冒泡\n 比较相邻的元素。如果第一个比第二个大，就交换它们两个； 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对，这样在最后的元素应该会是最大的数； 针对所有的元素重复以上的步骤，除了最后一个； 重复步骤1~3，直到排序完成。  int[] array=new int[]{2,4,62,6,457,2,3,5,7,8,9}; for (int i=0;i\u0026lt;array.length-1;i++){ for (int j = i+1; j \u0026lt; array.length; j++) { if(array[i]\u0026gt;array[j]){ int tmp=array[i]; array[i]=array[j]; array[j]=tmp; } } } System.out.println(Arrays.toString(array));   选择排序\n 初始状态：无序区为R[1..n]，有序区为空； 第i趟排序(i=1,2,3…n-1)开始时，当前有序区和无序区分别为R[1..i-1]和R(i..n）。该趟排序从当前无序区中-选出关键字最小的记录 R[k]，将它与无序区的第1个记录R交换，使R[1..i]和R[i+1..n)分别变为记录个数增加1个的新有序区和记录个数减少1个的新无序区； n-1趟结束，数组有序化了。  int[] array=new int[]{2,4,62,6,457,2,3,5,7,8,9}; for (int i = 0; i \u0026lt; array.length; i++) { int minIndex=i; for (int j = i; j \u0026lt; array.length; j++) { if(array[j]\u0026lt;=array[minIndex]){ minIndex=j; } } int tmp=array[i]; array[i]=array[minIndex]; array[minIndex]=tmp; } System.out.println(Arrays.toString(array));   插入排序\n 从第一个元素开始，该元素可以认为已经被排序； 取出下一个元素，在已经排序的元素序列中从后向前扫描； 如果该元素（已排序）大于新元素，将该元素移到下一位置； 重复步骤3，直到找到已排序的元素小于或者等于新元素的位置； 将新元素插入到该位置后； 重复步骤2~5。  int[] array=new int[]{2,4,62,6,457,2,3,5,7,8,9}; for (int i = 0; i \u0026lt; array.length; i++) { int cur=array[i]; for (int j = i-1; j \u0026gt;= 0; j--) { if(array[j]\u0026gt;cur){ array[j+1]=array[j]; }else { array[j+1]=cur; break; } } } System.out.println(Arrays.toString(array));   快排\n参考\npublic static void main(String[] args) { int[] array=new int[]{2,4,62,6,457,2,3,5,7,8,9}; sort(array,0,array.length-1); System.out.println(Arrays.toString(array)); } public static void sort(int[] arrays,int startIndex,int endIndex){ if(startIndex\u0026gt;=endIndex) return; int right=-1; int left=-1; for (int j = endIndex; j \u0026gt;=startIndex; j--) { if(arrays[j]\u0026lt;arrays[startIndex]){ right=j; break; } } if(right==-1){ //说明已经排序好了  //递归  sort(arrays,startIndex+1,endIndex); }else { for (int i = startIndex; i \u0026lt;= endIndex; i++) { //相交了，直接与基数互换  if(right==i){ int tmp=arrays[startIndex]; arrays[startIndex]=arrays[i]; arrays[i]=tmp; //当前轮走完，走子轮，  sort(arrays,startIndex,i-1); sort(arrays,i+1,endIndex); break; } if(arrays[i]\u0026gt;arrays[startIndex]){ left=i; break; } } if(left!=-1){ //交换  int tmp=arrays[left]; arrays[left]=arrays[right]; arrays[right]=tmp; //继续  sort(arrays,startIndex,endIndex); } } }   并归排序\npublic static void main(String[] args) { int[] array=new int[]{2,55,62,6,45,2,3,5,7,8,9,1,2,14,6,67,34,5,7,8,95,312,68,0,457,0}; array=mergeSort(array,0,array.length-1); System.out.println(Arrays.toString(array)); int[] ints = {1,2,3,0,0,0}; System.out.println(Arrays.toString(ints)); } public static int[] mergeSort(int[] array,int startIndex,int endIndex){ //数组长度  int length=endIndex-startIndex+1; if(length==1){ //只有一个，返回本身  return new int[]{array[startIndex]}; }else if(length==2){ //等于2,看是否需要交换  int left=array[startIndex]; int right=array[endIndex]; if(left\u0026gt;right){ //交换  int tmp=left; left=right; right=tmp; } return new int[]{left,right}; } else { int m = startIndex+length / 2; //合并  int[] left = mergeSort(array, startIndex, m-1); int[] right = mergeSort(array, m , endIndex); //左边一定\u0026lt;=右边  int[] r = new int[left.length + right.length]; int leftIndex=0; int rightIndex=0; while (leftIndex\u0026lt;left.length \u0026amp;\u0026amp; rightIndex\u0026lt;right.length){ if(left[leftIndex]\u0026lt;right[rightIndex]){ r[leftIndex+rightIndex]=left[leftIndex]; leftIndex++; }else { r[leftIndex+rightIndex]=right[rightIndex]; rightIndex++; } } while (leftIndex\u0026lt;left.length){ r[leftIndex+rightIndex]=left[leftIndex]; leftIndex++; } while (rightIndex\u0026lt;right.length){ r[leftIndex+rightIndex]=right[rightIndex]; rightIndex++; } return r; } }   桶排序\nint[] array=new int[]{2,4,62,6,457,2,3,5,7,8,9}; int[] ints = new int[500]; for (int i = 0; i \u0026lt; array.length; i++) { ints[array[i]]+=1; } for (int i = 0; i \u0026lt; ints.length; i++) { if(ints[i]!=0) for (int j = 0; j \u0026lt; ints[i]; j++) { System.out.print(i+\u0026#34;,\u0026#34;); } } }   你能写出几个查找算法 你能写出几个去重算法 LeetCode经典题目   回文串\n用数据结构栈去解决\nchar[] target=new char[]{\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;a\u0026#39;,\u0026#39;c\u0026#39;}; boolean jishu=target.length%2!=0; int middle=jishu?target.length/2-1:target.length/2; //前一半和后一半是否相同  for (int i = 0,j=target.length-1; i \u0026lt; middle; i++,j--) { if(target[i]!=target[j]){ System.out.println(\u0026#34;不是\u0026#34;); return; } } System.out.println(\u0026#34;是的\u0026#34;);   滑动窗口\n  LRU 操作系统 零拷贝是什么 简单点说就是，传统的从磁盘读取文件，再从网卡发出去。都是通过CPU来完成的\n因为用户进程是无法操作硬件的，必须切换到内核态。因此linux提供了read和write，2个函数。read，用户态切换到内核态，CPU发起IO请求，磁盘准备数据\n，准备好了通知CPU，CPU将数据放到PageCache，再从PageCache拷贝到用户缓冲区。这个过程CPU，全程参与，这个时候CPU不能做其他事情。\n为了解决CPU在复制文件的时候，不能做事情。出现了DMA(Direct Memory Access)，将复制的过程交给DMA处理，CPU只需要等待结果就可以了，期间可以执行其他事情。\n早期的读取文件，并传送到网卡流程\n首先，期间共发生了 4 次用户态与内核态的上下文切换，因为发生了两次系统调用，一次是 read() ，一次是 write()，每次系统调用都得先从用户态切换到内核态，等内核完成任务后，再从内核态切换回用户态。\n上下文切换到成本并不小，一次切换需要耗时几十纳秒到几微秒，虽然时间看上去很短，但是在高并发的场景下，这类时间容易被累积和放大，从而影响系统的性能。\n其次，还发生了 4 次数据拷贝，其中两次是 DMA 的拷贝，另外两次则是通过 CPU 拷贝的，下面说一下这个过程：\n 第一次拷贝，把磁盘上的数据拷贝到操作系统内核的缓冲区里，这个拷贝的过程是通过 DMA 搬运的。 第二次拷贝，把内核缓冲区的数据拷贝到用户的缓冲区里，于是我们应用程序就可以使用这部分数据了，这个拷贝到过程是由 CPU 完成的。 第三次拷贝，把刚才拷贝到用户的缓冲区里的数据，再拷贝到内核的 socket 的缓冲区里，这个过程依然还是由 CPU 搬运的。 第四次拷贝，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程又是由 DMA 搬运的。  实现零拷贝的方式\n  mmap + write\nmmap() 系统调用函数会直接把内核缓冲区里的数据「映射」到用户空间，这样，操作系统内核与用户空间就不需要再进行任何的数据拷贝操作。\n  sendfile\n在 Linux 内核版本 2.1 中，提供了一个专门发送文件的系统调用函数 sendfile()，函数形式如下：\n#include \u0026lt;sys/socket.h\u0026gt;ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count); 它的前两个参数分别是目的端和源端的文件描述符，后面两个参数是源端的偏移量和复制数据的长度，返回值是实际复制数据的长度。\n首先，它可以替代前面的 read() 和 write() 这两个系统调用，这样就可以减少一次系统调用，也就减少了 2 次上下文切换的开销。\n其次，该系统调用，可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态，这样就只有 2 次上下文切换，和 3 次数据拷贝。如下图：\n  参考\n顺序读写和随机读写 常见的解释在日志文件和innodb的索引文件。\n我们每次操作数据的增删改查的日志，都是通过顺序读写。\n因为索引是一种有序的数据结构B+树，每次有新数据来的时候，都会更新索引信息。通过计算找到索引应该在的地方。这个就是寻址。\n顺序读写就是只第一次寻址，然后后续写的动作都是在第一次寻址完后的地址上继续工作，不需要再寻址了。\n而随机读写是每次都要寻址的\n参考\n其他问题 OLAP和OLTP有什么区别 参考\n项目经验问答 我看你用过Hive，Spark，Es。讲讲你了解他们多少 这些都是大数据的组件，说到大数据不得不提一下hadoop，毕竟hive就是建立在hadoop的hdfs上的，hadoop有三大组件，hdfs用于处理海量存储，mapreduce用于处理海量计算，yarn用于海量下的资源调度。hive就是基于hdfs的一个能够使用sql的标准翻译mapreduce的工具，然后进行hdfs查询。可以理解为是一个navicat，spark高速的大数据计算引擎，与mapreduce最大的区别，在于mapreduce在每次计算的时候都会在磁盘上。而spark是纯内存计算，所以需要很大的内存，这就得看成本和数据量了，我在公司基本是1个T的内存，跑一个市的数据。Es通过倒排索引快速检索大数据的数据库。通过建立倒排索引，可以进行打分和统计，是非常棒的一个搜索工具。\n我看你写到用了模版模式，你模版模式用在哪了，你还用了什么其他设计模式吗 我们的整个系统流程是这样的，我们对外提供接口，我们调用下游的各家医院进行挂号的操作，然后在缴费的时候，不同医院对接的支付平台又不一样，但是订单的状态流转，以及支付平台都会提供主动查询和异步通知的。因此我们只需要抽象出一个支付的service，将订单更新的方法和支付结果的后续通知进行统一，具体的对接各家支付平台是具体的子类了。实际上这里既用了模版模式也用了策略模式。 我们将具体支付的子类，在项目启动的时候放在hashmap里，查询到不同医院的时候，直接从map里取对应的支付对象即可。\n其他的设计模式，例如单例，不过现在都是Spring了，基本很少写单例。常见的就那个双锁，还有利用静态内部类的。一般直接就使用懒汉的模式了。还有工厂模式，屏蔽具体的构造过程。还有spring本身内部就有很多模式，例如责任链模式，我负责的单点系统使用的是springSecurity，springSecurity就是标准的额责任链模式，因此security有很多filterChain,平时我们简单的security只有一个filterchain，而如果加入了oauth的话，会有多个。只有多个都通过了，才会成功。而每一个filterchain又是由多个filter组成，都会将当前的request和reponse传下去，包活authenication传下去，进行鉴权动作等。这就是典型的责任链模式，每种校验都对应一个filter，只要成功一个则成功。\n我看你写你到了挂号缴费，你是怎么避免订单和缴费之间的不同步问题 首先我在表设计上，使用的状态字段，通过增加支付中的字段，避免了一般情况下订单重复支付的问题。第二我们对接的支付平台，会提供主动查询和异步通知的方式，通知我们订单已支付，进行订单的更新。在收到支付成功的时候，我会使用分布式锁，进行订单再次查询，更新订单，以及挂号的动作。保证了只会有一个线程一瞬间进行订单的更新和挂号操作。\n我看你写了单点登录系统是你设计的，你是怎么设计的 基于oauth2.0，因为我们使用的springboot框架，spring提供了oauth2.0这样的模块。自然就拿来用了。spring做的很好，提供了一系列的接口供我们来做自定义，比如security中默认的查询客户端的是实现是jdbc，我写了个子类 ，用redis包了一下。因为客户端查询还是比较频繁的，不可能直接上数据库的。还有就是security的权限，标准的权限设计一般都是将权限和角色挂钩，而用户和角色挂钩。但是领导希望有些用户能有特殊权限。因此我们的权限表多出类型字段，即角色权限和用户权限，在查询的时候会将两种权限都查出来。并且入缓存。其余的也就没什么了，都是oauth的标准。通过用户授权然后获取token，拿着token进来处理。在登录的认证中，我们又自定义了granter，因为我们除了用户名和密码还需要机构号，其实就是实现spring提供的基类，然后配置到security上就可以了。有点模版模式。\n这里还有一个问题，我们的场景是这样的，我们有好多个应用，公用一个权限系统。如果A应用登录上去了，B也登录上去了。A点击退出登录。默认情况下，Spring会保存当前的会话中是A应用，但是B也点了退出登录。而用户一直用一个浏览器，就导致，原本是A的应用变成了B，最后两个标签页都是B应用了，我查了下源码，发现Spring保存在会话中默认情况下用的同一个key，导致B退出的时候覆盖了A，因此我把key变成原本的key加上client的id，这样就会有多个缓存，而不会因为后退出的改变前退出的client了。\n这个健康浏览器，只有查询的功能吗？这么大的海量数据，你是怎么存储的，怎么做到查询很快？ 参考\n因为只有查询的功能，因此我们并没有选择传统的rdbms，我们选择mongodb。首先我们这个项目只有查询功能，几乎没有更新操作，不需要事务。首先排除了rdbms，其次mongodb的集群分片功能能够满足我们庞大的数据。底层使用的b树，可以看到我们的项目是一个人为主体进行查询，都是以用户为主题，然后再进行查询，我们使用嵌入式文档，将用户的就诊记录和挂号记录，等医疗所组合成嵌入式文档，直接可以进行查询。底层的b树，数据直接会在节点上，不用跑到叶子结点，少了io，再加上他会将热点数据缓存到内存中。大大提高了我们查询的效率。相对于rdbms来说，mongodb是更好的选择。\n你项目里用到了消息队列吗？解决什么样的问题，看你用kafka 我的项目中需要用到支付，对接的是第三方支付平台。目前主流的支付流程都是通过移动端唤起h5或者app，不管哪种方式，支付平台都会提供2种方式来得到支付结果，1是前端直接返回，例如h5跳转回来，前端程序主动通知后台，后台主动查询地方系统接口。更新订单状态，2是在支付的时候会传给第三方系统一个异步回调地址，第三方系统在完成支付流程后，会通过调用这个地址，通知我们后台支付成功。 此时我需要调用下游接口，进行挂号动作。这个动作可能会很长时间，而且这个动作是同步的，并且挂号成功后，需要更新掉订单状态。使用了分布式锁在这里，保证只有一个线程可以进行挂号动作。 如果我不及时通知到第三方支付平台我成功收到的话，他会重复异步通知给我，导致我再次挂号。所以我使用了kafka做异步，先将信息发送到kafka中，然后直接回复完第三方系统。 然后再去消费kafka。之所以不用异步线程去处理，是因为这是支付完后的挂号动作，非常重要不能丢失，需要进行持久化，确保成功消费。\n我看到你用到netty，你聊聊netty，以及你用它干什么。 讲一下你最熟悉的项目，并且你在里面负责了什么，遇到了什么困难，如何解决的 简单自我介绍一下 我叫孙浩、今年26岁，19年毕业，我在18年的时候在第一家公司开始从实习生做起。\n目前在江苏曼荼罗软件股份有限公司，担任java开发，并且负责部分前端工作开发。最近负责的是标签系统和无锡挂缴查系统。在其中负责前后端开发。\n没有一线的流量并发工作经验，你是怎么考虑你的系统的 根据我的经验总结，只需要牢记一些常识就行：\n mysql 的 tps 你就按 5000 算，每秒超过 5000 请求，直接用 myql 肯定不行 单机 redis 的 qps 可以到 100k ，把一些数据 /缓存，存到 redis ，能有效提高并发 利用消息队列实现削峰，实现生产与消费的解耦 保证处理逻辑可以并行，可以扩展，谨慎使用锁 尽量将服务做成无状态可扩展的，把状态扔给 redis 或者其他高效的存储 对于频繁访问的数据一定要做缓存，然后去解决缓存的雪崩，穿透，失效等问题  ","permalink":"https://sunhao1256.github.io/posts/%E5%B8%B8%E8%A7%81%E9%A2%98%E7%9B%AE/","summary":"Redis redis有哪些数据结构，你用过哪些，做过什么事情   String\n最简单的数据结构，用于存放字符串，实际上在redis中存放的是字符数组，类似java中的arrayList，**Redis 为了对内存做极致的优化，不同长度的字符串使用不同的结构体来表示。**Redis 规定了字符串的长度不得超过 512 MB\n  List\n底层用的双向列表，类似java中的LinkedList，因为是链表所有，插入删除都是O(1)，查询是O(n)\n常见的命令\n  lpush从头添加元素，rpush从尾添加\n  lpop拿出头部的元素，rpop从尾部拿元素\n索引，lpush+lpop即可实现栈，rpush+lpop可以实现队列\n    Hash\n对应着java中的hashMap\n  Set\nRedis 的集合相当于 Java 语言中的 HashSet，它内部的键值对是无序、唯一的。它的内部实现相当于一个特殊的字典，字典中所有的 value 都是一个值 NULL。\n  Zset\n它类似于 Java 中 SortedSet 和 HashMap 的结合体，一方面它是一个 set，保证了内部 value 的唯一性，另一方面它可以为每个 value 赋予一个 score 值，用来代表排序的权重。\n使用场景：\n 排行榜，key是用户id，value是访问次数。 限流，key是用户id+接口id，value是时间戳，每次进方法之前，拿当前时间戳-interval，删除小于now-interval的元素，算出加入当前这次请求set中的个数是否大于max，大于则限流。    BloomFilter\n使用高效的数据结构解决是否存在的问题，可以解决穿透的问题\n  HyperLogLog\n可以用于基数的统计，例如UV统计\n  redis如何做到限流的 限流的几个方式","title":"八股文"},{"content":"终端 [root@LocalHost 桌面]# l\n root表示当前登录用户名 locahost表示当前登录的主机名 桌面 表示当前的工作目录 # 身份标识符 #表示为超级管理员 $表示为普通用户  目录结构  Bin：全称Binary，存放的都是一些二进制文件 Dev：主要存放一些外接设备，例如U盘等，在其中的设备是不能直接使用的，需要挂载（类似windows下的分盘） Etc：主要存放一些配置文件 Home：表示除了root用户以外的其他的家目录，类似windows下的user用户目录 Proc：该目录存放运行的进程文件 Root：该目录是root用户的家目录 SBin：该目录也是存放二进制文件，但是必须得有super权限的用户才能执行 Usr：用户的应用程序和文件都放在这个目录下类似于windows下的program files目录 Mnt：让用户临时挂在别的文件系统 Opt：一般存放安装软件包 Usr/local：存放安装软件后存在的软件目录 Var：存放不断变化的文件，例如日志文件  VI和VIM编辑器 所有的Linux系统都会内建VI文本编辑器，VIM具有程序编辑的能力，可以看成是VI的增强版\nVI和VIM的3种常见模式   正常模式\n在正常是模式下，可以使用快捷键来处理内容\n  插入/编辑模式\n在此模式下，可以输入内容，按i，I，o，O，a，A，r，R等任何一个字母就可以进入编辑模式，一般用i\n  命令行模式\n可以使用指令完成，读取，存盘，替换，离开，显示行号等动作\n  注释 单行注释：#\n多行注释：:\u0026laquo;!内容!\n快捷键的使用   行首0，行尾$\n  拷贝当前行：yy，拷贝当前向下n行：nyy，例如：5yy\n  粘贴：p\n  删除当前行：dd，删除当前行下n行：ndd，例如：5dd\n  查找：命令行模式下 / 关键字，例如：/hello，下一个n\n  设置文件行号：命令行模式下 ：set nu，关闭行号：set nonu\n  快速到顶行：正常模式下 gg\n  快速到底行：正常模式下G\n  撤销：正常模式下u\n  指定到行号：先显示行号，在正常模式下先输入行数，再按shift+g\n  o：进入输入模式，且进入下一行\n  复制，删除/剪切 yy：复制光标所在一行 3yy：复制光标所在行及向下2行 p：粘贴 dd：剪切/删除光标所在一行 3dd：剪切/删除光标所在行及向下两行 D：从当前的光标开始剪切一直到行末 d0：从当前光标开始剪切一直到行首 x：删除当前的光标，每次只会删除一个 X：删除当前光标前面的那个，每次只会删除一个 控制光标上下左右走：h左j下k上l右\n  定位： H：当前屏幕的上方 M：当前屏幕的中间 L：当前屏幕的下方 Ctrl+f：向下翻一页代码 Ctrl+b：向上翻一页代码 Ctrl+d：向下翻半页代码 Ctrl+u：向上翻半页代码 20G：快速的定位到第20行，定位到第1行就是1G，以此类推 G：快速的回到整个代码的最后一行 gg：快速回到整个代码的第一行 w：向后跳一个单词的长度，即调到下一个单词的开始处 b：向后跳一个单词的长度，即调到上一个单词的开始处\n  撤销 u：撤销刚刚的动作 Ctrl+r：反撤销\n  选中一片代码 v：选中一片代码 V：选中一片代码\n：向右移动代码\n\u0026laquo;：向左移动代码\n. ：重复执行上一次的命令\n  替换 r：替换一个字符 R：替换光标以及后面的字符 shift+zz：保存并退出\n  末行模式下 替换 将当前文件中的所有abc替换成123 :%s/abc/123/g 将第一行到第十行之间的abc替换成123 :1, 10s/abc/123/g** 查找 查找整个代码中的hello ：/hello n：下一个 N：上一个 保存和退出 :q 退出不保存 :wq 保存并退出 :q ! 强制退出不保存 :wq! 强制保存并退出\n  关机和重启  shutdown -h now ：表示立即关机 shutdown -h 1：表示1分钟后关机 shutdown -r now：表示立即重启 halt：直接关机 reboot：重启系统 sync：把内存数据同步到磁盘上，防止数据丢失  登录和注销  一般是使用普通账号进行登录，当权限不够的时候在用\u0026quot;su - 用户名\u0026quot;切换到系统管理员身份 logout注销用户  用户管理 每个用户至少存在一个用户组中。\n  添加用户： useradd [选项] 用户名，如果不指定用户组会给用户创建一个同名的用户组，并存放在其中。\nuseradd -d 路径 用户名，指定用户的访问路径\nuseradd -g 组名 用户名，指定用户的用户组\n  设置密码： passwd 用户名\n  查看当前目录路径： pwd\n  删除用户： userdel 用户名，userdel -r 用户名，删除用户且删除家目录，（一般不删除家目录）\n  查询用户信息： id 用户名\n  切换到其他用户： su -用户名\n  * `/etc/passwd`： 用户账户的详细信息在此文件中更新。 * `/etc/shadow`： 用户账户密码在此文件中更新。 * `/etc/group`： 新用户群组的详细信息在此文件中更新。 * `/etc/gshadow`： 新用户群组密码在此文件中更新。   用户组管理  新增：groupadd 组名 删除：groupdel 组名 修改用户的用户组：usermod -g 组名 用户名，修改用户的用户组 修改用户的登录目录：usermod -d 路径名 用户名  指定运行级别 系统的运行级别文件在/etc/inittab，可以设置默认的运行级别\n  0：关机\n  1：单用户\n  2：多用户无网络服务\n  3：多用户有网络服务\n  4：保留\n  5：图形化界面\n  6：重启\n切换到指定运行级别命令：init(级别)\n注意点：如果root密码丢失的话，可以指定运行级别为1，单用户级别，直接免密码登录root，然后修改密码。\n  帮助指令 man 命令\n文件目录类指令   pwd： 显示当前工作的绝对路径\n  ls： 查看当前目录结构\nls -[选项]\n-a：查出所有加上隐藏文件\n-l：横向展示文件信息\n-h：以人类的方式查看，可以显示文件具体大小单位\n  cd： 切换到其他目录\n  mkdir： 创建目录 mkdir[选项] 目录名\nmkdir -p 目录名，创建多级目录\n  rmdir：删除一个空目录（无法删除非空目录，需要使用rm -rf 目录名，才可以进行删除）\n  touch：创建一个或多个空文件\n  cp：拷贝文件到指定目录\ncp 文件名 目标路径\n\\cp ：如果有存在文件，强制覆盖\ncp -r 目录名 目标路径 ：递归拷贝整个文件夹\n  rm：移除文件或目录\nrm -r：递归删除整个文件夹\nrm -f：强制删除不提示\n  mv：移动文件与重命名\nmv a.txt b.txt 重命名\nmv /a /b 移动文件\n  cat：浏览文件，只读，不能修改，一般配合 |more分页显示\ncat -n 文件名 |more 分页显示行号浏览文件\n  more：以全屏方式去显示文件内容，空格下一页，enter下一行，ctrl+f下一页，ctrl+b上一页\n  less：与More不同的是，less不是一次将文件加载完才显示，所以对大型文件效率高，推荐查看日志文件\n  \u0026gt; ：输出重定向，覆盖原先内容（文件不存在就创建）\necho \u0026lsquo;test\u0026rsquo; test.txt\n  \u0026gt;\u0026gt;：追加指令\n  cal ：显示当前日历\n  echo：输入内容到控制台，经常输出环境变量\necho $PATH\n  head：用于显示文件的开头部分\nhead -n 5 文件名：查看文件的前5行，默认10行\n  tail：查看文件尾部输出内容\ntail 文件 查看文件最后10行\ntail -n 100 查看文件最后100行\ntail -f 实时输出文件\n  ln：软连接，类似windows的快捷方式\nln -s [原文件或者目录] [软连接名]（用pwd查看的时候，依然是软连接的所在的目录）\n  history：查看历史使用过的指令\nhistory n：查看最后的n条\n!188：执行历史的188号指令\n  时间日期类指令   date：显示当前日期时间\ndate：显示当前时间\ndate +%Y：显示当前年份\ndate +%m：显示月份\ndate +%M：显示分\ndate +‘%Y/%M’：显示2020/*\ndate -s 字符串时间：设置系统实际\n  cal：以日历的方式显示时间\n  搜索查找类指令   find：从指定目录向下递归遍历各个子目录，将满足条件的文件或者目录显示在终端\nfind [搜索范围] [选项]\nfind /root -name test.txt：在root下查找test.txt文件，可以使用*做模糊查询\nfind /root -user root：在root下查找是root用户创建的文件\nfind /root -size +20M：在root下查找大于20M的文件 ， +大于，-小于，不写是等于\n  locate：可以快速定位文件路径，locate无需遍历整个文件系统，但必须定期更新locate数据库\n使用updatedb\n  grep 和 | 管道指令\ngrep过滤查找，管道符 | 表示将前面一个命令的处理结果交给后面的命令处理\ngrep基本用法：grep[选项] 查找内容 原文件\ngrep常用选项：-n 显示匹配行以及行号 -i 忽略大小写\n例如： cat /root/testLog.log | grep -ni 300465\n  压缩和解压缩   gzip和gunzip\ngizp 文件（只能将文件压缩为*.gz文件，且不保留原文件）\ngunzip 文件.gz（解压文件，也不保留压缩文件）\n  zip和unzip\nzip [选项] xxx.zip 要压缩的内容（压缩文件，保留原文件）\n -r 递归压缩，压缩整个目录  unzip [选项] xxx.zip （解压文件，保留压缩文件）\n -d 目录地址 ，具体解压到哪    tar\ntar是指打包指令，最后打包的指令是.tar.gz文件\ntar [选项] xxx.tar.gz 压缩内容\n -c 产生.tar打包文件 -v 显示详细信息 -f 指定压缩后的文件名 -z 打包同时压缩 -x 解压.tar文件 -C 解压到指定目录下    -P tar默认是相对路径，可以使用P设置为绝对路径\n  压缩例如：tar -zcvf a.tar.gz test.txt test1.txt ；tar -zcvf a.tar.gz /home/\n解压例如：tar -zxvf a.tar.gz -C /\n组管理和权限管理 在Linux中的每一个用户都必须属于一个组，不能独立于组外，在linux中每个文件都有所有者、所在组、其他组的概念\n  文件/目录的所有者（谁创建了文件，就成为该文件的所有者）\n查看所有者 ls -ahl\n  修改文件所有者\nchown 用户名 文件名\n  修改文件所在组\nchgrp 组名 文件名\n  权限基本介绍 一个文件或目录的详细描述\n例如：\n-rw-r--r-- 1 root root 0 Feb 1 18:39 a.txt 0-10位说明：\n  0位表示文件类型\n  - ：普通文件\n  d：目录\n  l：链接文件，软连接（快捷方式）\n  c：字符设备（键盘，鼠标）\n  b：块文件（硬盘）\n    1-3位表示文件所有者拥有的权限\n  -6位表示文件所在组拥有的权限\n  7-9位表示文件其他组用户拥有的权限\n  10位表示 如果是文件，则表示文件的硬连接数，如果是目录表示子目录个数\n  rwx权限详解\n  rwx作用在文件上\n r：表示可读，可以查看 w：表示修改，可以修改，但不代表可以删除该文件，删除的前提条件是拥有文件所在目录写的权限，才可以删除 x：表示可以执行，表示可执行    rwx作用在目录上\n r：表示可读取，ls查看目录内容 w：表示可写，可以修改，目录内创建+删除+重命名目录 x：表示可执行，可以进入该目录    rwx用数字表示\n r：4 w：2 x：1  因此rwx=7\n   权限修改chmod 可以通过chmod修改文件或目录的权限\n  通过+ 、- 、= 来修改权限\n  u：表示所有者\n  g：表示所在组\n  o：表示其他人\n  a：表示所有人（o，g，u的和）\n例如：chmod u=rwx,g=rx,o=x 文件目录名，chmod u-x 文件目录名（让所有者失去x执行权限）,chmod u+x（让所有者加上x执行权限）\n    通过数字变更权限\n  r：4\n  w：2\n  x：1\n例如：chmod u=rwx,g=rx,o=x 文件名 相当于 chmod 751 文件名\n    修改文件所有者-chown\n chown 新用户 文件名（修改文件的所有者） chown 新用户:新组 文件名（修改文件的所有组和所有者） -R 如果是目录，则使其下所有的子文件或者目录递归生效    crond任务调度 命令：crontab[选项]\n  -e：编辑crontab 定时任务\n  -l：查询crontab 任务\n  -r：删除当前用户的所有crontab 任务\n  service crond restart ：(重启任务调度)\n可以写一个sheel脚本，然后去执行\n  分区与挂载 分区的方式  mbr分区  最多支持4个主分区 系统只能安装在主分区 扩展分区占用一个主分区 mbr最大只支持2TB，但有最好的兼容性   gtp分区  支持无限多个主分区（但操作系统下可能会限制，例如windows下最多支持128个分区） 最大支持18EB的容量（EB=1024PB，PB=1024TB） windows7 64位以后支持gtp   lsblk 可以查看当前分区情况  挂载   增加一块新硬盘\n  分区 fdisk /dev/硬盘名\n  格式化 mkfs -t 文件类型 分区路径。例如：mkfs -t ext4 /dev/sdb1\n  挂载 mount 分区路径 目标目录（只是临时挂载）\n  设置自动挂载：修改 /etc/fstab文件，增加自己的分区挂载到目标目录上，再使用mount -a 自动挂载\n  卸载 umount 分区路径\n  磁盘情况查询   df -h，df -l\n  du 查看某个目录下的磁盘使用情况\n可带参数\n -c 列出明细同时提供总数 \u0026ndash;max-depth=n 子目录深度为n -a 查所有包含文件 -h 带单位  例如：du -cha \u0026ndash;max-depth=1 /root\n  常用命令  统计目录下文件的个数 ls -al |grep \u0026lsquo;^-\u0026rsquo; | wc -l 统计目录下目录的个数 ls -al |grep \u0026lsquo;^d\u0026rsquo; | wc -l 统计目录下包含子目录文件的个数 ls -alR |grep \u0026lsquo;^-\u0026rsquo; | wc -l 查看目录树 tree  网络配置   修改linux ip地址为指定地址\n修改/etc/sysconfig/network-scripts/ifcfg-eth0\n   进程管理   基本介绍\nps命令是用来查看目前系统中有哪些正在执行，以及他们的执行状况\n可以配合grep使用\n常用选项\n -a 查看当前终端所有的进程信息 -u 以用户的格式显示进程信息 -x 显示后台进程运行的参数 -ef 展示父进程  显示字段\n  USER 用户名称\n  PID 进程识别号\n  %CPU 进程占用CPU百分比\n  %MEM进程占用内存百分比\n  VSZ 进程占用虚拟内存大小 （kb）\n  RSS 进程占用物理内存大小 （kb）\n  TTY 终端机号\n  STAT 进行状态，s表示进程是绘画的先导进程，N表示进程拥有比普通进程优先级更低的优先级，R表示正在运行，D表示短期等待，Z表示僵尸进程，T表示被追踪或者被停止\n  TIME 此进程所消耗CPU时间\n  CMD 正在执行的命令或进程名\n    终止进程kill和killAll\n  kill [选项] 进程号\n常用选项\n -9 表示强迫进程终止         kill 进程名(通过名称终止进程，可以使用通配符)\n  查看进程树 pstree\n-p显示进程ID，-u显示进程所在用户\n   服务管理 服务（Service）本质上就是一个进程，通常运行在后台，会监听一个端口，等待其他程序的请求，例如mysqld,sshd,防火墙等，因此我们又称为守护进程\nservice管理命令 service 服务名 start|stop|restart|reload|status\n在Centos7.0以后使用systemctl\n  ls -l /etc/init.d/ 查看系统有哪些服务\n  chkconfig可以给每个服务设置各个运行级别自启动/关闭\n 开启或关闭：chkconfig \u0026ndash;level 5 服务名 on/off    进程监控 top命令与ps不同之处在于，top会不停的更新数据\n常用选项\n -d 秒数 ：几秒后更新 默认3秒 -i ：不显示闲置或僵尸进程 -p 进程号：显示进程号 -u 用户名：监控指定的用户  交互操作\n  P：按cpu使用率排序\n  M：按内存使用排序\n  N：按PID排序\n  q：退出top\n  网络监控 netstat用来监控网络\n常用选项\n -an ：按照一定顺序排列 -p：显示那个进程在使用  Lsof管理 lsof是系统管理的工具，lsof可以代替ps和netstat的几乎全部工作\n关键选项   默认 : 没有选项，lsof列出活跃进程的所有打开文件\n  组合 : 可以将选项组合到一起，如-abc，但要当心哪些选项需要参数\n  -a : 结果进行“与”运算（而不是“或”）\n  -l : 在输出显示用户ID而不是用户名\n  -h : 获得帮助\n  -t : 仅获取进程ID\n  -U : 获取UNIX套接口地址\n  -F : 格式化输出结果，用于其它命令。可以通过多种方式格式化，如-F pcfn（用于进程id、命令名、文件描述符、文件名，并以空终止）\n  -i：显示所有连接（语法：lsof -i[46] [protocol][@hostname|hostaddr][:service|port]）\n例如：\n lsof -i 6：获取IPV6流量 lsof -i :3306：查看3306端口使用状态    参考连接 https://www.jianshu.com/p/a3aa6b01b2e1\nRPM包管理 rpm -ql |grep 查询内容\n常用选项\n -i ：安装 -v：提示 -h：进度条 -e：卸载RPM包（加上\u0026ndash;nodeps强制删除） -q：查询包  rpm -ivh RPM包全路径名称\nrpm -ivh –relocate = 路径\nYum Yum可以自动处理RPM依赖关系\n基本指令\n list：查看 install：安装  Shell脚本 起步  新建一个shell脚本，一般以.sh结尾 写入内容，保存 授予x权限 执行  shell变量 介绍 shell变量分为系统变量和用户自定义变量\n 系统变量：$HOME,$PWD,$SHELL,$USER,\u0026quot;$PATH\u0026quot;等等，比如echo $HOME 显示当前shell中所有的变量：set  定义变量 基本语法  定义变量：变量=值 撤销变量：unset 变量 声明静态变量：readonly 变量，注意：不能unset  定义规则  变量名称可以由字母，数字和下划线组成，但是不能以数字开头 等号两侧不能有空格 变量名称习惯性是大写  将命令的返回值赋值给变量  A=$(ls -la) A=`ls -la` 使用反引号（数字键左边的键）  设置环境变量  export 变量名=变量值（功能描述：将shell变量输出为环境变量） source 配置文件 （让修改后的配置文件立即生效） echo $变量名 （查询环境变量的值）  设置位置参数变量 例如 ./myshell.sh 100 200 我们可以在myshell脚本中获取到100,200的参数信息\n基本语法：\n $n：n为数字，$0表示命令本身，$(1-9)代表第一到第九个参数，十以上的参数需要用大括号 ${10} $*：这个变量命令表示所有参数，将所有参数看成一个整体 $@：也是表示所有参数，但把参数区分开来 $#：表示所有参数的个数  预定义变量  $$：当前进程的PID $!：后台运行的最后一个进程的进程号 $?：最后一次执行命令的状态，如果成功为0，如果不成功为开发者指定的一个值 以后台方式运行：在命令最后使用一个\u0026amp;  运算符 基本语法：\n  $((运算式))或$[运算式]\n  expr m + n（注意运算符间有空格）\n  expr m - n\n  expr \\*，/，%：乘除取余\nexpr需要用反引号\n  条件判断   基本语法\n[ condition ] （注意condition前后要有空格）\n非空返回true ，可以使用$?验证（0true，\u0026gt;1false）\n  常用判断\n 两个整数比较  =字符串比较 -lt小于 -le小于等于 -eq等于 -gt大于 -ge大于等于 -ne不等于   按照文件读写权限判断  -r有读 -w有写 -x有执行   按照文件类型判断  -f文件存在且是一个常规文件 -e文件存在 -d文件存在且是一个目录    示例：\n#!/bin/bash if [ $1 -ge 60 ] then echo \u0026#34;及格啦\u0026#34; elif [ $1 -ge 40 ] then echo \u0026#34;你废物\u0026#34; fi   case语句 基本语法示例：\n#!/bin/bash case $1 in \u0026#34;1\u0026#34;) echo \u0026#34;周一\u0026#34; ;; \u0026#34;2\u0026#34;) echo \u0026#34;周二\u0026#34;;; *) echo \u0026#34;other\u0026#34;;; esac for语句   for 变量 in 值1 值2 值3\u0026hellip;\ndo\n​\t程序\ndone\n示例：\n#!/bin/bash # 使用$* for i in \u0026#34;$*\u0026#34; do echo \u0026#34;$i\u0026#34; done #使用$@ for i in $@ do echo \u0026#34;param=$i\u0026#34; done   for((初始值；循环控制条件；变量变化))\ndo\n​\t程序\ndone\n示例：\n#!/bin/bash SUM=0 for ((i=1;i\u0026lt;=100;i++)) do SUM=$[$SUM + $i ] done echo $SUM   while循环 while [ condition ]\ndo\n​\t程序\ndone\n示例：\n#!/bin/bash RESULT=0 I=0 while [ $I -le $1 ] do RESULT=$[ $RESULT + $I ] I=$[ $I + 1 ] done echo $RESULT read读取控制台输入 基本语法\nread [选项] 参数\n -p：指定读取时的提示符； -t：指定读取值时的等待时间  示例：\nread -p \u0026#34;请输入一个数字\u0026#34; NUM echo $NUM 函数   系统函数\n basename [pathname][suffix] (常用于获取文件名) dirname （常用于返回路径名称）    自定义函数\n基本语法\n[ function ] functionname [()]{\n​\tAction;\n​\t[return int]\n}\n示例：\n#!/bin/bash # 计算输入的2个数字和 read -p \u0026#34;请输入第一个数字\u0026#34; NUM1 read -p \u0026#34;请输入第二个数字\u0026#34; NUM2 function getSum(){ SUM=$[ $NUM1 + $NUM2 ] echo \u0026#34;和是:$SUM\u0026#34; } getSum $NUM1 $NUM2   综合案例 需求：  每天凌晨2点10分，备份日志文件a.log到/data/backup/log 备份开始和备份结束有提示 备份后的文件以时间命名为文件名，并打包成压缩包.tar.gz保存 在备份的时候检查是否有10天前备份过的日志文件，有的话就将它删除  示例： #!/bin/bash # 定时备份日志文件 # 定义备份的路径 BACKUP=/data/backup/log # 获取当前时间作为文件名 DATETIME=`date +%Y_%m_%d_%H:%M:%S` echo \u0026#34;=====开始备份=====\u0026#34; echo \u0026#34;=====备份的目标路径为$BACKUP=====\u0026#34; echo \u0026#34;=====文件名$DATETIME.tar.gz=====\u0026#34; #检查目标路径是否存在如果不存在就创建 [ ! -d $BACKUP ] \u0026amp;\u0026amp; mkdir -p $BACKUP DESTINFLOG=/root/a.log # 检查目标文件是否存在 if [ ! -f $DESTINFLOG ] then echo \u0026#34;$DESTINFLOG文件不存在！\u0026#34; exit fi # 开始备份 cp $DESTINFLOG $BACKUP/$DATETIME.log #打包 (:会被识别为地址 需要--force-local) cd $BACKUP tar -zcvf $DATETIME.tar.gz $DATETIME.log --force-local #删除临时文件 rm -rf $DATETIME.log #检查是否有10天前的文件,全部删除 find $BACKUP -mtime +10 -name \u0026#34;*.tar.gz\u0026#34; -exec rm -rf {} \\; #结束 echo \u0026#34;=====备份结束=====\u0026#34; 防火墙 查看防火墙情况 firewall-cmd \u0026ndash;list -all\n增加TCP端口 firewall-cmd \u0026ndash;add-port=80/tcp \u0026ndash;permanent\n重新加载防火墙 firewall-cmd reload\n常用命令 firewall-cmd [选项]\n -h, \u0026ndash;help\t显示帮助信息； -V, \u0026ndash;version\t显示版本信息. （这个选项不能与其他选项组合）； -q, \u0026ndash;quiet\t不打印状态消息； –state\t显示firewalld的状态； –reload\t不中断服务的重新加载； –complete-reload\t中断所有连接的重新加载； –runtime-to-permanent\t将当前防火墙的规则永久保存； –check-config\t检查配置正确性； –get-log-denied\t获取记录被拒绝的日志； –set-log-denied=\t设置记录被拒绝的日志，只能为 ‘all’,‘unicast’,‘broadcast’,‘multicast’,‘off’ 其中的一个；\n 配置firewalld firewall-cmd --version # 查看版本 firewall-cmd --help # 查看帮助 # 查看设置： firewall-cmd --state # 显示状态 firewall-cmd --get-active-zones # 查看区域信息 firewall-cmd --get-zone-of-interface=eth0 # 查看指定接口所属区域 firewall-cmd --panic-on # 拒绝所有包 firewall-cmd --panic-off # 取消拒绝状态 firewall-cmd --query-panic # 查看是否拒绝 firewall-cmd --reload # 更新防火墙规则 firewall-cmd --complete-reload # 两者的区别就是第一个无需断开连接，就是firewalld特性之一动态添加规则，第二个需要断开连接，类似重启服务 # 将接口添加到区域，默认接口都在public firewall-cmd --zone=public --add-interface=eth0 # 永久生效再加上 --permanent 然后reload防火墙 # 设置默认接口区域，立即生效无需重启 firewall-cmd --set-default-zone=public # 查看所有打开的端口： firewall-cmd --zone=dmz --list-ports # 加入一个端口到区域： firewall-cmd --zone=dmz --add-port=8080/tcp # 若要永久生效方法同上 # 打开一个服务，类似于将端口可视化，服务需要在配置文件中添加，/etc/firewalld 目录下有services文件夹，这个不详细说了，详情参考文档 firewall-cmd --zone=work --add-service=smtp # 移除服务 firewall-cmd --zone=work --remove-service=smtp # 显示支持的区域列表 firewall-cmd --get-zones # 设置为家庭区域 firewall-cmd --set-default-zone=home # 查看当前区域 firewall-cmd --get-active-zones # 设置当前区域的接口 firewall-cmd --get-zone-of-interface=enp03s # 显示所有公共区域（public） firewall-cmd --zone=public --list-all # 临时修改网络接口（enp0s3）为内部区域（internal） firewall-cmd --zone=internal --change-interface=enp03s # 永久修改网络接口enp03s为内部区域（internal） firewall-cmd --permanent --zone=internal --change-interface=enp03s 服务管理 # 显示服务列表 Amanda, ftp, Samba和tftp等最重要的服务已经被FirewallD提供相应的服务，可以使用如下命令查看： firewall-cmd --get-services # 允许ssh服务通过 firewall-cmd --enable service=ssh # 禁止SSH服务通过 firewall-cmd --disable service=ssh # 打开TCP的8080端口 firewall-cmd --enable ports=8080/tcp # 临时允许Samba服务通过600秒 firewall-cmd --enable service=samba --timeout=600 # 显示当前服务 firewall-cmd --list-services # 添加HTTP服务到内部区域（internal） firewall-cmd --permanent --zone=internal --add-service=http firewall-cmd --reload # 在不改变状态的条件下重新加载防火墙 端口管理 # 打开443/TCP端口 firewall-cmd --add-port=443/tcp # 永久打开3690/TCP端口 firewall-cmd --permanent --add-port=3690/tcp # 永久打开端口好像需要reload一下，临时打开好像不用，如果用了reload临时打开的端口就失效了 # 其它服务也可能是这样的，这个没有测试 firewall-cmd --reload # 查看防火墙，添加的端口也可以看到 firewall-cmd --list-all 直接模式 # FirewallD包括一种直接模式，使用它可以完成一些工作，例如打开TCP协议的9999端口 firewall-cmd --direct -add-rule ipv4 filter INPUT 0 -p tcp --dport 9000 -j accept firewall-cmd --reload 自定义服务管理 （末尾带有 [P only] 的话表示该选项除了与（--permanent）之外，不能与其他选项一同使用！） --new-service=\u0026lt;服务名\u0026gt; 新建一个自定义服务 [P only] --new-service-from-file=\u0026lt;文件名\u0026gt; [--name=\u0026lt;服务名\u0026gt;] 从文件中读取配置用以新建一个自定义服务 [P only] --delete-service=\u0026lt;服务名\u0026gt; 删除一个已存在的服务 [P only] --load-service-defaults=\u0026lt;服务名\u0026gt; Load icmptype default settings [P only] --info-service=\u0026lt;服务名\u0026gt; 显示该服务的相关信息 --path-service=\u0026lt;服务名\u0026gt; 显示该服务的文件的相关路径 [P only] --service=\u0026lt;服务名\u0026gt; --set-description=\u0026lt;描述\u0026gt; 给该服务设置描述信息 [P only] --service=\u0026lt;服务名\u0026gt; --get-description 显示该服务的描述信息 [P only] --service=\u0026lt;服务名\u0026gt; --set-short=\u0026lt;描述\u0026gt; 给该服务设置一个简短的描述 [P only] --service=\u0026lt;服务名\u0026gt; --get-short 显示该服务的简短描述 [P only] --service=\u0026lt;服务名\u0026gt; --add-port=\u0026lt;端口号\u0026gt;[-\u0026lt;端口号\u0026gt;]/\u0026lt;protocol\u0026gt; 给该服务添加一个新的端口(端口段) [P only] --service=\u0026lt;服务名\u0026gt; --remove-port=\u0026lt;端口号\u0026gt;[-\u0026lt;端口号\u0026gt;]/\u0026lt;protocol\u0026gt; 从该服务上移除一个端口(端口段) [P only] --service=\u0026lt;服务名\u0026gt; --query-port=\u0026lt;端口号\u0026gt;[-\u0026lt;端口号\u0026gt;]/\u0026lt;protocol\u0026gt; 查询该服务是否添加了某个端口(端口段) [P only] --service=\u0026lt;服务名\u0026gt; --get-ports 显示该服务添加的所有端口 [P only] --service=\u0026lt;服务名\u0026gt; --add-protocol=\u0026lt;protocol\u0026gt; 为该服务添加一个协议 [P only] --service=\u0026lt;服务名\u0026gt; --remove-protocol=\u0026lt;protocol\u0026gt; 从该服务上移除一个协议 [P only] --service=\u0026lt;服务名\u0026gt; --query-protocol=\u0026lt;protocol\u0026gt; 查询该服务是否添加了某个协议 [P only] --service=\u0026lt;服务名\u0026gt; --get-protocols 显示该服务添加的所有协议 [P only] --service=\u0026lt;服务名\u0026gt; --add-source-port=\u0026lt;端口号\u0026gt;[-\u0026lt;端口号\u0026gt;]/\u0026lt;protocol\u0026gt; 添加新的源端口(端口段)到该服务 [P only] --service=\u0026lt;服务名\u0026gt; --remove-source-port=\u0026lt;端口号\u0026gt;[-\u0026lt;端口号\u0026gt;]/\u0026lt;protocol\u0026gt; 从该服务中删除源端口(端口段) [P only] --service=\u0026lt;服务名\u0026gt; --query-source-port=\u0026lt;端口号\u0026gt;[-\u0026lt;端口号\u0026gt;]/\u0026lt;protocol\u0026gt; 查询该服务是否添加了某个源端口(端口段) [P only] --service=\u0026lt;服务名\u0026gt; --get-source-ports 显示该服务所有源端口 [P only] --service=\u0026lt;服务名\u0026gt; --add-module=\u0026lt;module\u0026gt; 为该服务添加一个模块 [P only] --service=\u0026lt;服务名\u0026gt; --remove-module=\u0026lt;module\u0026gt; 为该服务移除一个模块 [P only] --service=\u0026lt;服务名\u0026gt; --query-module=\u0026lt;module\u0026gt; 查询该服务是否添加了某个模块 [P only] --service=\u0026lt;服务名\u0026gt; --get-modules 显示该服务添加的所有模块 [P only] --service=\u0026lt;服务名\u0026gt; --set-destination=\u0026lt;ipv\u0026gt;:\u0026lt;address\u0026gt;[/] Set destination for ipv to address in service [P only] --service=\u0026lt;服务名\u0026gt; --remove-destination=\u0026lt;ipv\u0026gt; Disable destination for ipv i service [P only] --service=\u0026lt;服务名\u0026gt; --query-destination=\u0026lt;ipv\u0026gt;:\u0026lt;address\u0026gt;[/] Return whether destination ipv is set for service [P only] --service=\u0026lt;服务名\u0026gt; --get-destinations List destinations in service [P only] 控制端口/服务  可以通过两种方式控制端口的开放，一种是指定端口号另一种是指定服务名。虽然开放 http 服务就是开放了 80 端口，但是还是不能通过端口号来关闭，也就是说通过指定服务名开放的就要通过指定服务名关闭；通过指定端口号开放的就要通过指定端口号关闭。还有一个要注意的就是指定端口的时候一定要指定是什么协议，tcp 还是 udp。知道这个之后以后就不用每次先关防火墙了，可以让防火墙真正的生效。\n firewall-cmd --add-service=mysql # 开放mysql端口 firewall-cmd --remove-service=http # 阻止http端口 firewall-cmd --list-services # 查看开放的服务 firewall-cmd --add-port=3306/tcp # 开放通过tcp访问3306 firewall-cmd --remove-port=80tcp # 阻止通过tcp访问3306 firewall-cmd --add-port=233/udp # 开放通过udp访问233 firewall-cmd --list-ports # 查看开放的端口 伪装IP firewall-cmd --query-masquerade # 检查是否允许伪装IP firewall-cmd --add-masquerade # 允许防火墙伪装IP firewall-cmd --remove-masquerade# 禁止防火墙伪装IP 端口转发  端口转发可以将指定地址访问指定的端口时，将流量转发至指定地址的指定端口。转发的目的如果不指定 ip 的话就默认为本机，如果指定了 ip 却没指定端口，则默认使用来源端口。 如果配置好端口转发之后不能用，可以检查下面两个问题：\n比如我将 80 端口转发至 8080 端口，首先检查本地的 80 端口和目标的 8080 端口是否开放监听了 其次检查是否允许伪装 IP，没允许的话要开启伪装 IP\n firewall-cmd --add-forward-port=port=80:proto=tcp:toport=8080 # 将80端口的流量转发至8080 firewall-cmd --add-forward-port=port=80:proto=tcp:toaddr=192.168.0.1 # 将80端口的流量转发至192.168.0.1 firewall-cmd --add-forward-port=port=80:proto=tcp:toaddr=192.168.0.1:toport=8080 # 将80端口的流量转发至192.168.0.1的8080端口   1)当我们想把某个端口隐藏起来的时候，就可以在防火墙上阻止那个端口访问，然后再开一个不规则的端口，之后配置防火 墙的端口转发，将流量转发过去。 2)端口转发还可以做流量分发，一个防火墙拖着好多台运行着不同服务的机器，然后用防火墙将不同端口的流量转发至不同机器。   开机启动服务 在linux下，有一个目录专门用以管理所有的服务的启动脚本的，即/etc/rc.d/init.d下。\n这时候，我们来试一下使用service的命令进行启动，可以看到，这时候就可以通过service的方式进行启动了，真实运维中也是如此，我们只需要把服务的启动脚本文件放在此处，就可以以service的方式启动了\nReids示例：\n每个服务都会配置一个init的脚本。例如redis在units下的，redis_init_script，就可以放在/etc/rc.d/init.d中\n通过chkconfig 服务名 on就可以开机启动\n# chkconfig: 2345 15 95 其中2345是默认启动级别，级别有0-6共7个级别。15是启动优先级，95是停止优先级，优先级范围是0－100，数字越大，优先级越低。\nJmap jmap -dump:format=b,file=文件名 [pid]\njmap -dump:format=b,file=/usr/local/base/02.hprof 12942 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/usr/local/base\nMemoryAnalyzer -vmargs -Xmx5g 信息查看 机器内核 /proc/version\nuname -a\n查看核心数 # 总核数 = 物理CPU个数 X 每颗物理CPU的核数  # 总逻辑CPU数 = 物理CPU个数 X 每颗物理CPU的核数 X 超线程数 # 查看物理CPU个数 cat /proc/cpuinfo| grep \u0026#34;physical id\u0026#34;| sort| uniq| wc -l # 查看每个物理CPU中core的个数(即核数) cat /proc/cpuinfo| grep \u0026#34;cpu cores\u0026#34;| uniq # 查看逻辑CPU的个数 cat /proc/cpuinfo| grep \u0026#34;processor\u0026#34;| wc -l ssh登陆 生成公私钥\nssh-keygen -t rsa -C \u0026ldquo;email\u0026rdquo;\n上传公钥到目标服务器\nscp -p ~/.ssh/id_rsa.pub root@\u0026lt;remote_ip\u0026gt;:/root/.ssh/authorized_keys\nscp上传下载 -o PubkeyAuthentication=no # 不实用pk下载 光标快捷键 光标操作快捷键，光标快捷键 这些光标操作快捷键适用mac/linux终端和chrome控制台，这些快捷键都是emacs的快捷键， 常用的快捷键： Ctrl + d 删除一个字符，相当于通常的Delete键(命令行若无所有字符，则相当于exit；处理多行标准输入时也表示eof) Ctrl + h 退格删除一个字符，相当于通常的Backspace键 Ctrl + u 删除光标之前到行首的字符 Ctrl + k 删除光标之前到行尾的字符 Ctrl + c 取消当前行输入的命令，相当于Ctrl + Break Ctrl + a 光标移动到行首(Ahead of line)，相当于通常的Home键 Ctrl + e 光标移动到行尾(End of line) Ctrl + f 光标向前(Forward)移动一个字符位置 Ctrl + b 光标往回(Backward)移动一个字符位置 Ctrl + l 清屏，相当于执行clear命令 Ctrl + p 调出命令历史中的前一条(Previous)命令，相当于通常的上箭头 Ctrl + n 调出命令历史中的下一条(Next)命令，相当于通常的上箭头 Ctrl + r 显示：号提示，根据用户输入查找相关历史命令(reverse-i-search) 次常用快捷键： Alt + f 光标向前(Forward)移动到下一个单词 Alt + b 光标往回(Backward)移动到前一个单词 Ctrl + w 删除从光标位置前到当前所处单词(Word)的开头 Alt + d 删除从光标位置到当前所处单词的末尾 Ctrl + y 粘贴最后一次被删除的单词    COMMAND ACTION     Shortcuts    Tab Auto-complete file and folder names   Ctrl + A Go to the beginning of the line you\u0026rsquo;re currently typing on   Ctrl + E Go to the end of the line you\u0026rsquo;re currently typing on   Ctrl + U Clear the line before the cursor   Ctrl + K Clear the line after the cursor   Ctrl + W Delete the word before the cursor   Ctrl + T Swap the last two characters before the cursor   Esc + T Swap the last two words before the cursor   Ctrl + L Clear the screen   Ctrl + C Kill whatever you\u0026rsquo;re running   Ctrl + D Exit the current shell   Option + → Move cursor one word forward   Option + ← Move cursor one word backward   Ctrl + F Move cursor one character forward   Ctrl + B Move cursor one character backward   Ctrl + Y Paste whatever was cut by the last command   Ctrl + Z Puts whatever you\u0026rsquo;re running into a suspended background process   Ctrl + _ Undo the last command   Option + Shift + Cmd + C Copy plain text   Shift + Cmd + V Paste the selection   exit End a shell session    查看cpu架构 arch\n设置网卡静态ip BOOTPROTO=static HWADDR=98:90:96:bd:1c:fc IPADDR=128.83.155.1 NETMASK=255.255.255.0 GATEWAY=128.83.155.250 DNS1=114.114.114.114 service network restart rpm和yum https://www.cnblogs.com/LiuChunfu/p/8052890.html\naarch64 x86_64 arm64 amd64 https://www.jianshu.com/p/2753c45af9bf\naarch64==arm64 是arm架构的\nx86_64=amd64 是x86架构的\nman详解 https://www.geek-share.com/detail/2728370984.html\n","permalink":"https://sunhao1256.github.io/posts/linux/","summary":"终端 [root@LocalHost 桌面]# l\n root表示当前登录用户名 locahost表示当前登录的主机名 桌面 表示当前的工作目录 # 身份标识符 #表示为超级管理员 $表示为普通用户  目录结构  Bin：全称Binary，存放的都是一些二进制文件 Dev：主要存放一些外接设备，例如U盘等，在其中的设备是不能直接使用的，需要挂载（类似windows下的分盘） Etc：主要存放一些配置文件 Home：表示除了root用户以外的其他的家目录，类似windows下的user用户目录 Proc：该目录存放运行的进程文件 Root：该目录是root用户的家目录 SBin：该目录也是存放二进制文件，但是必须得有super权限的用户才能执行 Usr：用户的应用程序和文件都放在这个目录下类似于windows下的program files目录 Mnt：让用户临时挂在别的文件系统 Opt：一般存放安装软件包 Usr/local：存放安装软件后存在的软件目录 Var：存放不断变化的文件，例如日志文件  VI和VIM编辑器 所有的Linux系统都会内建VI文本编辑器，VIM具有程序编辑的能力，可以看成是VI的增强版\nVI和VIM的3种常见模式   正常模式\n在正常是模式下，可以使用快捷键来处理内容\n  插入/编辑模式\n在此模式下，可以输入内容，按i，I，o，O，a，A，r，R等任何一个字母就可以进入编辑模式，一般用i\n  命令行模式\n可以使用指令完成，读取，存盘，替换，离开，显示行号等动作\n  注释 单行注释：#\n多行注释：:\u0026laquo;!内容!\n快捷键的使用   行首0，行尾$\n  拷贝当前行：yy，拷贝当前向下n行：nyy，例如：5yy\n  粘贴：p\n  删除当前行：dd，删除当前行下n行：ndd，例如：5dd\n  查找：命令行模式下 / 关键字，例如：/hello，下一个n\n  设置文件行号：命令行模式下 ：set nu，关闭行号：set nonu","title":"linux"},{"content":"Go 包管理 go mod init:初始化modules go mod download:下载modules到本地cache go mod edit:编辑go.mod文件，选项有-json、-require和-exclude，可以使用帮助go help mod edit go mod graph:以文本模式打印模块需求图 go mod tidy:检查，删除错误或者不使用的modules，下载没download的package go mod vendor:生成vendor目录 go mod verify:验证依赖是否正确 go mod why：查找依赖 ​ go test 执行一下，自动导包 ​ go list -m 主模块的打印路径 go list -m -f={{.Dir}} print主模块的根目录 go list -m all 查看当前的依赖和版本信息 ","permalink":"https://sunhao1256.github.io/posts/go/","summary":"Go 包管理 go mod init:初始化modules go mod download:下载modules到本地cache go mod edit:编辑go.mod文件，选项有-json、-require和-exclude，可以使用帮助go help mod edit go mod graph:以文本模式打印模块需求图 go mod tidy:检查，删除错误或者不使用的modules，下载没download的package go mod vendor:生成vendor目录 go mod verify:验证依赖是否正确 go mod why：查找依赖 ​ go test 执行一下，自动导包 ​ go list -m 主模块的打印路径 go list -m -f={{.Dir}} print主模块的根目录 go list -m all 查看当前的依赖和版本信息 ","title":""},{"content":"Gradle ","permalink":"https://sunhao1256.github.io/posts/gradle/","summary":"Gradle ","title":""},{"content":"快捷键   Finder绝对路径跳转\ncommand+shift+G\n  Finder绝对路径复制\ncommand+option+C\n  表情\ncontrol+cmmand+space\n  录屏\nShift-Command-5\n  截图\ncommand shift 4局部，3全屏\n  只显示桌面\ncommand f3\n  环境变量 加载顺序\n/etc/profile /etc/paths ~/.zprofile ~/.zshrc /etc/profile和/etc/paths是系统级别的，系统启动就会加载，zprofile是用户级别的 ~/.zshrc没有上述规则，它是zsh shell打开的时候载入的。\n# System-wide .profile for sh(1) if [ -x /usr/libexec/path_helper ]; then eval `/usr/libexec/path_helper -s` fi if [ \u0026#34;${BASH-no}\u0026#34; != \u0026#34;no\u0026#34; ]; then [ -r /etc/bashrc ] \u0026amp;\u0026amp; . /etc/bashrc fi path_helper是将/etc/paths和/etc/paths.d中定义的路径,加入环境变量. 苹果推荐使用这个\nMac下的Java,默认会直接装好Java命令.是通过**/usr/libexec/java_home**命令找环境变量中的JAVA_HOME变量,用于输出Java\nIterm2 command快捷键\n  ctrl+a\n行首\n  ctrl+e\n行尾\n  option+b\n前一个单词\n  option+f\n后一个单词\n  Chrome ctrl+shift+n打开一个无痕\n","permalink":"https://sunhao1256.github.io/posts/mac%E4%BD%BF%E7%94%A8/","summary":"快捷键   Finder绝对路径跳转\ncommand+shift+G\n  Finder绝对路径复制\ncommand+option+C\n  表情\ncontrol+cmmand+space\n  录屏\nShift-Command-5\n  截图\ncommand shift 4局部，3全屏\n  只显示桌面\ncommand f3\n  环境变量 加载顺序\n/etc/profile /etc/paths ~/.zprofile ~/.zshrc /etc/profile和/etc/paths是系统级别的，系统启动就会加载，zprofile是用户级别的 ~/.zshrc没有上述规则，它是zsh shell打开的时候载入的。\n# System-wide .profile for sh(1) if [ -x /usr/libexec/path_helper ]; then eval `/usr/libexec/path_helper -s` fi if [ \u0026#34;${BASH-no}\u0026#34; != \u0026#34;no\u0026#34; ]; then [ -r /etc/bashrc ] \u0026amp;\u0026amp; . /etc/bashrc fi path_helper是将/etc/paths和/etc/paths.d中定义的路径,加入环境变量. 苹果推荐使用这个","title":""},{"content":"netty是在什么地方创建SeverChannel的 在BootStrap调用bind方法时创建\nprivate ChannelFuture doBind(final SocketAddress localAddress) { final ChannelFuture regFuture = this.initAndRegister(); } initAndRegister方法\nfinal ChannelFuture initAndRegister() { Channel channel = null; try { channel = this.channelFactory.newChannel(); channelFactory是在bootstrap配置class时实例化的\n在AbstractBootstrap中\npublic B channel(Class\u0026lt;? extends C\u0026gt; channelClass) { return this.channelFactory((io.netty.channel.ChannelFactory)(new ReflectiveChannelFactory((Class)ObjectUtil.checkNotNull(channelClass, \u0026#34;channelClass\u0026#34;)))); } 因此是直接通过反射，创建了NioServerSocketChannel.class\npublic class NioServerSocketChannel extends AbstractNioMessageChannel implements ServerSocketChannel { private static final ChannelMetadata METADATA = new ChannelMetadata(false, 16); private static final SelectorProvider DEFAULT_SELECTOR_PROVIDER = SelectorProvider.provider(); private static final InternalLogger logger = InternalLoggerFactory.getInstance(NioServerSocketChannel.class); private final ServerSocketChannelConfig config; private static java.nio.channels.ServerSocketChannel newSocket(SelectorProvider provider) { try { //实际上就是调用了java的方法  return provider.openServerSocketChannel(); } catch (IOException var2) { throw new ChannelException(\u0026#34;Failed to open a server socket.\u0026#34;, var2); } } public NioServerSocketChannel() { this(newSocket(DEFAULT_SELECTOR_PROVIDER)); } public NioServerSocketChannel(SelectorProvider provider) { this(newSocket(provider)); } //super方法中配置了阻塞  public NioServerSocketChannel(java.nio.channels.ServerSocketChannel channel) { super((Channel)null, channel, 16); this.config = new NioServerSocketChannel.NioServerSocketChannelConfig(this, this.javaChannel().socket()); } protected AbstractNioChannel(Channel parent, SelectableChannel ch, int readInterestOp) { super(parent); this.ch = ch; this.readInterestOp = readInterestOp; try { //设置阻塞  ch.configureBlocking(false); } catch (IOException var7) { try { ch.close(); } catch (IOException var6) { logger.warn(\u0026#34;Failed to close a partially initialized socket.\u0026#34;, var6); } throw new ChannelException(\u0026#34;Failed to enter non-blocking mode.\u0026#34;, var7); } } protected AbstractChannel(Channel parent) { this.parent = parent; this.id = this.newId(); this.unsafe = this.newUnsafe(); this.pipeline = this.newChannelPipeline();//创建了管道 } ServerBootstrapAcceptor 服务端不管之前增加了多少handler，最后都会增加ServerBootstrapAcceptor\n在ServerBootstrap.class中\nvoid init(Channel channel) { setChannelOptions(channel, this.newOptionsArray(), logger); setAttributes(channel, (Entry[])this.attrs0().entrySet().toArray(EMPTY_ATTRIBUTE_ARRAY)); ChannelPipeline p = channel.pipeline(); final EventLoopGroup currentChildGroup = this.childGroup; final ChannelHandler currentChildHandler = this.childHandler; final Entry[] currentChildOptions; synchronized(this.childOptions) { currentChildOptions = (Entry[])this.childOptions.entrySet().toArray(EMPTY_OPTION_ARRAY); } final Entry\u0026lt;AttributeKey\u0026lt;?\u0026gt;, Object\u0026gt;[] currentChildAttrs = (Entry[])this.childAttrs.entrySet().toArray(EMPTY_ATTRIBUTE_ARRAY); p.addLast(new ChannelHandler[]{new ChannelInitializer\u0026lt;Channel\u0026gt;() { public void initChannel(final Channel ch) { final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = ServerBootstrap.this.config.handler(); if (handler != null) { pipeline.addLast(new ChannelHandler[]{handler}); } ch.eventLoop().execute(new Runnable() { public void run() { //在这里加入了默认的  //以后新的请求的都通过这个连接器处理，给新的连接分配一个nio线程  pipeline.addLast(new ChannelHandler[]{new ServerBootstrap.ServerBootstrapAcceptor(ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)}); } }); } }}); } netty服务端启动的几个过程：创建channel（创建jdk底层channel）、init初始化（最主要是添加连接器serverBootstrapAcceptor）、register（把第一步jdk底层创建channel注册到selector上面，并且把这个NioServerSocketChannel作为attachment添加进去），doBind（绑定端口，实现监听accept事件）\n  1、服务端的socket在哪里初始化？\n在bind方法中，initAndRegister中，实例化SocketChannel，使用的是反射方式，传入的就是bootstrap配置的channel.class。底层还是jdk的ServerSocketChannel对应普通方式的\nserverSocketChannel = ServerSocketChannel.open(); //设置为非阻塞模式 serverSocketChannel.configureBlocking(false); register是把创建好的注册到selector上，但没有监听事件，对应的是\n//监听客户端请求 //0表示只注册，不监听事件 serverSocketChannel.register(selector, 0); private static java.nio.channels.ServerSocketChannel newSocket(SelectorProvider provider) { try { return provider.openServerSocketChannel();//创建jdk的ServerSocketChannel  } catch (IOException var2) { throw new ChannelException(\u0026#34;Failed to open a server socket.\u0026#34;, var2); } }   2、在哪里进行accept连接？\n还是在bind方法中，doBind最终底层调用了jdk的端口绑定和监听accpet事件\npublic NioServerSocketChannel(java.nio.channels.ServerSocketChannel channel) { super((Channel)null, channel, 16);//16就是SelectionKey.OP_ACCEPT 1\u0026lt;\u0026lt;4  this.config = new NioServerSocketChannel.NioServerSocketChannelConfig(this, this.javaChannel().socket()); } 对应普通的就是\nserverSocketChannel.socket().bind(new InetSocketAddress(port),1024); //监听客户端请求 serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); bind最终是在NioServerSocketChannel执行的\nprotected void doBind(SocketAddress localAddress) throws Exception { if (PlatformDependent.javaVersion() \u0026gt;= 7) { this.javaChannel().bind(localAddress, this.config.getBacklog()); } else { this.javaChannel().socket().bind(localAddress, this.config.getBacklog()); } } accpet最终是在AbstractNioChannel的doBeginRead方法中，注册了构造方法传来的16，即accpet事件\nprotected void doBeginRead() throws Exception { SelectionKey selectionKey = this.selectionKey; if (selectionKey.isValid()) { this.readPending = true; int interestOps = selectionKey.interestOps(); if ((interestOps \u0026amp; this.readInterestOp) == 0) { selectionKey.interestOps(interestOps | this.readInterestOp); } } }   NioEventLoopGroup、NioEventLoop的关系 在NioEventLoopGroup实例化的时候，会做如下动作\n  创建线程创建(执行)器：new ThreadPerTaskExecutor()\nprotected MultithreadEventExecutorGroup(int nThreads, Executor executor, EventExecutorChooserFactory chooserFactory, Object... args) { this.terminatedChildren = new AtomicInteger(); this.terminationFuture = new DefaultPromise(GlobalEventExecutor.INSTANCE); if (nThreads \u0026lt;= 0) { throw new IllegalArgumentException(String.format(\u0026#34;nThreads: %d (expected: \u0026gt; 0)\u0026#34;, nThreads)); } else { if (executor == null) { //创建线程执行器  executor = new ThreadPerTaskExecutor(this.newDefaultThreadFactory()); } this.children = new EventExecutor[nThreads]; int j; for(int i = 0; i \u0026lt; nThreads; ++i) { boolean success = false; boolean var18 = false; try { var18 = true; //填充child  this.children[i] = this.newChild((Executor)executor, args); success = true; var18 = false; } catch (Exception var19) {   构造NioEventLoop：for{newChild()}\nprotected EventLoop newChild(Executor executor, Object... args) throws Exception { //填充的就是nioEventLoop  return new NioEventLoop(this, executor, (SelectorProvider)args[0], ((SelectStrategyFactory)args[1]).newSelectStrategy(), (RejectedExecutionHandler)args[2]); }   创建线程选择器：chooserFactory.newChooser()\nprivate static final class PowerOfTowEventExecutorChooser implements EventExecutorChooser { private final AtomicInteger idx = new AtomicInteger(); private final EventExecutor[] executors; PowerOfTowEventExecutorChooser(EventExecutor[] executors) { this.executors = executors; } @Override public EventExecutor next() { return executors[idx.getAndIncrement() \u0026amp; executors.length - 1]; } } private static final class GenericEventExecutorChooser implements EventExecutorChooser { private final AtomicInteger idx = new AtomicInteger(); private final EventExecutor[] executors; GenericEventExecutorChooser(EventExecutor[] executors) { this.executors = executors; } @Override public EventExecutor next() { return executors[Math.abs(idx.getAndIncrement() % executors.length)]; } } 模取运算除了%，还可以用\u0026amp;（length-1）\n  线程创建与运行的流程\n  NioEventLoopGroup顾名思义，就是NioEventLoopGroup的集合，内部维护了children数组，数组的内容就是NioEventLoop\n  当调用Loop去execute的时候，实际上是调用线程执行器ThreadPerTaskExecutor去执行，内部DefaultThreadFactory就是创建了FastThreadLocalThread线程。\n  Loop的execute方法，除了用DefaultThreadFactory创建并运行FastThreadLocalThread线程外，还会将任务放入Loop自身维护的一个无锁队列。并且运行自身的run方法\nprivate void doStartThread() { assert thread == null; executor.execute(new Runnable() { @Override public void run() { thread = Thread.currentThread(); if (interrupted) { thread.interrupt(); } boolean success = false; updateLastExecutionTime(); try { SingleThreadEventExecutor.this.run();//调用run方法  // nioEventLoop的run方法,无线循环去消费队列  for(;;) ..... .... .... final int ioRatio = this.ioRatio; boolean ranTasks; if (ioRatio == 100) { try { if (strategy \u0026gt; 0) { processSelectedKeys(); } } finally { // Ensure we always run tasks.  ranTasks = runAllTasks(); } } else if (strategy \u0026gt; 0) { final long ioStartTime = System.nanoTime(); try { processSelectedKeys(); } finally { // Ensure we always run tasks.  final long ioTime = System.nanoTime() - ioStartTime; ranTasks = runAllTasks(ioTime * (100 - ioRatio) / ioRatio);//通过ioRatio控制消费任务的速度，这里就是不断的循环去消费  } } else { ranTasks = runAllTasks(0); // This will run the minimum number of tasks  }     总结\n在创建NioEventLoopGroup后，内部会维护了一个children，children的内容就是nioEventLoop，并且创建loop的时候为每个loop创建了内部的无锁队列，默认长度是系统核心的2倍，然后调用group的register或者execute方法，都会执行next去取一个loop，next方法就是模取循环下一个线程。\nloop会执行execute方法，实现会将任务Runnable放入队列。然后第一次运行时调用了ThreadFactory去创建了新线程，这个新线程并不是直接就开始执行任务，而是无限循环消费loop内部维护的无锁队列。达到了，一个loop一个线程。\n  NioEventLoop启动 在绑定端口的时候做了启动线程的动作\nchannel.eventLoop().execute(new Runnable() { @Override public void run() { if (regFuture.isSuccess()) { channel.bind(localAddress, promise).addListener(ChannelFutureListener.CLOSE_ON_FAILURE); } else { promise.setFailure(regFuture.cause()); } } }); 这里的channel的eventLoop是通过register方法去绑定的，是在一开始Bootstrap的intAndRegister方法中执行\nfinal ChannelFuture initAndRegister() { Channel channel = null; try { channel = this.channelFactory.newChannel(); this.init(channel); } catch (Throwable var3) { if (channel != null) { channel.unsafe().closeForcibly(); return (new DefaultChannelPromise(channel, GlobalEventExecutor.INSTANCE)).setFailure(var3); } return (new DefaultChannelPromise(new FailedChannel(), GlobalEventExecutor.INSTANCE)).setFailure(var3); } //从group取一个loop绑定到channel上  ChannelFuture regFuture = this.config().group().register(channel); if (regFuture.cause() != null) { if (channel.isRegistered()) { channel.close(); } else { channel.unsafe().closeForcibly(); } } return regFuture; } NioEventLoop的run方法   select()检查是否有io事件\nnetty在这里检查是否需要select，需要的话，直接调用jdk的select方法，进行阻塞。\njdk的select方法，在linux下，会发生没有事件，但是select方法被触发导致的空轮训bug\nnetty的解决方式\nlong time = System.nanoTime(); //检查当前时间-本应该阻塞的时间\u0026gt;=阻塞之前的时间，即发生阻塞了。没有空轮训 if (time - TimeUnit.MILLISECONDS.toNanos(timeoutMillis) \u0026gt;= currentTimeNanos) { selectCnt = 1; //否则，空轮训超过默认的512次，重建selector } else if (SELECTOR_AUTO_REBUILD_THRESHOLD \u0026gt; 0 \u0026amp;\u0026amp; selectCnt \u0026gt;= SELECTOR_AUTO_REBUILD_THRESHOLD) { logger.warn(\u0026#34;Selector.select() returned prematurely {} times in a row; rebuilding Selector {}.\u0026#34;, selectCnt, selector); this.rebuildSelector(); selector = this.selector; selector.selectNow(); selectCnt = 1; break; }  rebuildSelector()方法就是将原来selector上的所有keys，绑定到新的selector上\n   processSelectedKeys()：处理io任务，即selectionKey中ready的事件，如accept、connect、read、write等\n底层取轮询io事件，都是通过NioUnsafe去处理的\nprivate void processSelectedKey(SelectionKey k, AbstractNioChannel ch) { final AbstractNioChannel.NioUnsafe unsafe = ch.unsafe(); if (!k.isValid()) { final EventLoop eventLoop; try { eventLoop = ch.eventLoop(); } catch (Throwable ignored) { // If the channel implementation throws an exception because there is no event loop, we ignore this  // because we are only trying to determine if ch is registered to this event loop and thus has authority  // to close ch.  return; } // Only close ch if ch is still registered to this EventLoop. ch could have deregistered from the event loop  // and thus the SelectionKey could be cancelled as part of the deregistration process, but the channel is  // still healthy and should not be closed.  // See https://github.com/netty/netty/issues/5125  if (eventLoop == this) { // close the channel if the key is not valid anymore  unsafe.close(unsafe.voidPromise()); } return; } try { //处理各种事件  int readyOps = k.readyOps(); // We first need to call finishConnect() before try to trigger a read(...) or write(...) as otherwise  // the NIO JDK channel implementation may throw a NotYetConnectedException.  if ((readyOps \u0026amp; SelectionKey.OP_CONNECT) != 0) { // remove OP_CONNECT as otherwise Selector.select(..) will always return without blocking  // See https://github.com/netty/netty/issues/924  int ops = k.interestOps(); ops \u0026amp;= ~SelectionKey.OP_CONNECT; k.interestOps(ops); unsafe.finishConnect(); } // Process OP_WRITE first as we may be able to write some queued buffers and so free memory.  if ((readyOps \u0026amp; SelectionKey.OP_WRITE) != 0) { // Call forceFlush which will also take care of clear the OP_WRITE once there is nothing left to write  ch.unsafe().forceFlush(); } // Also check for readOps of 0 to workaround possible JDK bug which may otherwise lead  // to a spin loop  if ((readyOps \u0026amp; (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) { unsafe.read(); } } catch (CancelledKeyException ignored) { unsafe.close(unsafe.voidPromise()); } }   runAllTasks()：处理异步任务队列里面的任务，也就是添加到taskQueue中的任务，如bind、channelActive等\n这里有个ioRatio，就是执行io任务和非io任务的时间比。用户可以自行设置。默认为50，可以看源码。如果是100的话，先执行完io任务，执行完之后才执行非io任务\nselectCnt++; cancelledKeys = 0; needsToSelectAgain = false; final int ioRatio = this.ioRatio; boolean ranTasks; if (ioRatio == 100) { try { if (strategy \u0026gt; 0) { processSelectedKeys(); } } finally { // Ensure we always run tasks.  ranTasks = runAllTasks(); } } else if (strategy \u0026gt; 0) { final long ioStartTime = System.nanoTime(); try { processSelectedKeys(); } finally { // Ensure we always run tasks.  final long ioTime = System.nanoTime() - ioStartTime; ranTasks = runAllTasks(ioTime * (100 - ioRatio) / ioRatio); } } else { ranTasks = runAllTasks(0); // This will run the minimum number of tasks  } if (ranTasks || strategy \u0026gt; 0) { if (selectCnt \u0026gt; MIN_PREMATURE_SELECTOR_RETURNS \u0026amp;\u0026amp; logger.isDebugEnabled()) { logger.debug(\u0026#34;Selector.select() returned prematurely {} times in a row for Selector {}.\u0026#34;, selectCnt - 1, selector); } selectCnt = 0; } else if (unexpectedSelectorWakeup(selectCnt)) { // Unexpected wakeup (unusual case)  selectCnt = 0; } protected boolean runAllTasks(long timeoutNanos) { fetchFromScheduledTaskQueue();//将定时任务队列里的到期任务放入队列中，如果队列满了，还放在定时任务队列里  Runnable task = pollTask();//取一个任务出来  if (task == null) { afterRunningAllTasks(); return false; } final long deadline = timeoutNanos \u0026gt; 0 ? ScheduledFutureTask.nanoTime() + timeoutNanos : 0; long runTasks = 0; long lastExecutionTime; for (;;) { safeExecute(task); runTasks ++; // Check timeout every 64 tasks because nanoTime() is relatively expensive.  // XXX: Hard-coded value - will make it configurable if it is really a problem.  if ((runTasks \u0026amp; 0x3F) == 0) { lastExecutionTime = ScheduledFutureTask.nanoTime(); if (lastExecutionTime \u0026gt;= deadline) { break; } } //不断处理任务  task = pollTask(); if (task == null) { lastExecutionTime = ScheduledFutureTask.nanoTime(); break; } } afterRunningAllTasks(); this.lastExecutionTime = lastExecutionTime; return true; }  定时任务的场景，例如心跳处理\n   服务端创建客户端连接流程 processSelectedKeys方法处理客户端连接，最后是落在底层的unsafe上。\nread方法最后会通知到管道上，通知所有的handler，\npublic void read() { assert eventLoop().inEventLoop(); final ChannelConfig config = config(); final ChannelPipeline pipeline = pipeline(); final RecvByteBufAllocator.Handle allocHandle = unsafe().recvBufAllocHandle(); allocHandle.reset(config); boolean closed = false; Throwable exception = null; try { try { do { //创建NioSocketChannel  int localRead = doReadMessages(readBuf); if (localRead == 0) { break; } if (localRead \u0026lt; 0) { closed = true; break; } allocHandle.incMessagesRead(localRead); } while (continueReading(allocHandle)); } catch (Throwable t) { exception = t; } int size = readBuf.size(); for (int i = 0; i \u0026lt; size; i ++) { readPending = false; //管道传入NioSocketChannel  pipeline.fireChannelRead(readBuf.get(i)); } 而我们知道在一开始创建NioServerSocketChannel的时候，在init中最后加入了ServerBootstrapAcceptor。而ServerBootstrapAcceptor就是处理客户端连接的\n@Override @SuppressWarnings(\u0026#34;unchecked\u0026#34;) public void channelRead(ChannelHandlerContext ctx, Object msg) { final Channel child = (Channel) msg; //得到上面的NioSocketChannel  //将一开始代码中的childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() {}传进来  child.pipeline().addLast(childHandler); //设置通道配置  setChannelOptions(child, childOptions, logger); //设置属性  setAttributes(child, childAttrs); try { //worker线程组注册channel  childGroup.register(child).addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { if (!future.isSuccess()) { forceClose(child, future.cause()); } } }); } catch (Throwable t) { forceClose(child, t); } }\t  小结\nServer在获取到读事件后，创建了客户端的SocketChannel，并且通过pipeline通知到服务端初始化时创建的ServerBootstrapAcceptor，通过ServerBootstrapAcceptor初始化childHandler，使用worker组进行注册SocketChannel，并且创建客户端Channel默认的监听事件时read，然后就和服务端一样，通过默认的HeadContext进行read方法，默认都是自动读的。然后就是通过group创建新线程去工作。循环调底层的jdk方法。再通过pipeline通知到各个handler\n  Pipeline   netty是如何判断ChannelHandler类型的\n答：通过传入是inbound还是outbound\n  对于ChannelHandler的添加应该遵循什么样的顺序\n答：inbound传播是从Head结点开始的，outbound传播是从Tail节点开始的，所以需要根据需要从这两个方面选择\n  用户手动触发事件传播，不同的触发方式有什么样的区别？\n可以这里回答：ctx.channel().write()和ctx.write()的区别，ctx.channel().write()从tail节点开始传播（对于outBound事件），ctx.write()从当前节点开始传播。\n  初始化 Pipeline是在channel创建的时候进行初始化的，并且维护了双向链表，默认的添加HeadContext和TailContext，节点是AbstractChannelHandlerContext\nprotected AbstractChannel(Channel parent) { this.parent = parent; id = newId(); unsafe = newUnsafe(); pipeline = newChannelPipeline(); } protected DefaultChannelPipeline(Channel channel) { this.channel = ObjectUtil.checkNotNull(channel, \u0026#34;channel\u0026#34;); succeededFuture = new SucceededChannelFuture(channel, null); voidPromise = new VoidChannelPromise(channel, true); tail = new TailContext(this); head = new HeadContext(this); head.next = tail; tail.prev = head; } ChannelHandlerContext public interface ChannelHandlerContext extends AttributeMap, ChannelInboundInvoker, ChannelOutboundInvoker { /** * Return the {@link Channel} which is bound to the {@link ChannelHandlerContext}. */ //所在的channel  Channel channel(); /** * Returns the {@link EventExecutor} which is used to execute an arbitrary task. */ //哪一个loop执行的  EventExecutor executor(); /** * The unique name of the {@link ChannelHandlerContext}.The name was used when then {@link ChannelHandler} * was added to the {@link ChannelPipeline}. This name can also be used to access the registered * {@link ChannelHandler} from the {@link ChannelPipeline}. */ String name(); /** * The {@link ChannelHandler} that is bound this {@link ChannelHandlerContext}. */ //干活的业务handler  ChannelHandler handler(); /** * Return {@code true} if the {@link ChannelHandler} which belongs to this context was removed * from the {@link ChannelPipeline}. Note that this method is only meant to be called from with in the * {@link EventLoop}. */ boolean isRemoved(); ... /** * Return the assigned {@link ByteBufAllocator} which will be used to allocate {@link ByteBuf}s. */ // 内存分配器  ByteBufAllocator alloc(); ... } ChannelHandler的添加 DefaultChannelPipeline的addLast方法\n@Override public final ChannelPipeline addLast(EventExecutorGroup group, String name, ChannelHandler handler) { final AbstractChannelHandlerContext newCtx; synchronized (this) { //检查handler是否重复，如果没@Shareable的话，不可以再添加了  checkMultiplicity(handler); //使用DefaultChannelHandlerContext，内部封装了具体的业务handler  newCtx = newContext(group, filterName(name, handler), handler); //连接到链表上去  addLast0(newCtx); // If the registered is false it means that the channel was not registered on an eventLoop yet.  // In this case we add the context to the pipeline and add a task that will call  // ChannelHandler.handlerAdded(...) once the channel is registered.  if (!registered) { newCtx.setAddPending(); callHandlerCallbackLater(newCtx, true); return this; } EventExecutor executor = newCtx.executor(); if (!executor.inEventLoop()) { callHandlerAddedInEventLoop(newCtx, executor); return this; } } callHandlerAdded0(newCtx); return this; } ChannelHandler删除 private AbstractChannelHandlerContext getContextOrDie(ChannelHandler handler) { AbstractChannelHandlerContext ctx = (AbstractChannelHandlerContext) context(handler); if (ctx == null) { throw new NoSuchElementException(handler.getClass().getName()); } else { return ctx; } } //从头到尾找  @Override public final ChannelHandlerContext context(ChannelHandler handler) { if (handler == null) { throw new NullPointerException(\u0026#34;handler\u0026#34;); } AbstractChannelHandlerContext ctx = head.next; for (;;) { if (ctx == null) { return null; } if (ctx.handler() == handler) { return ctx; } ctx = ctx.next; } } //不删除head和tail  private AbstractChannelHandlerContext remove(final AbstractChannelHandlerContext ctx) { assert ctx != head \u0026amp;\u0026amp; ctx != tail; synchronized (this) { remove0(ctx); // If the registered is false it means that the channel was not registered on an eventloop yet.  // In this case we remove the context from the pipeline and add a task that will call  // ChannelHandler.handlerRemoved(...) once the channel is registered.  if (!registered) { callHandlerCallbackLater(ctx, false); return ctx; } EventExecutor executor = ctx.executor(); if (!executor.inEventLoop()) { executor.execute(new Runnable() { @Override public void run() { callHandlerRemoved0(ctx); } }); return ctx; } } callHandlerRemoved0(ctx); return ctx; } //真正的删除  private static void remove0(AbstractChannelHandlerContext ctx) { AbstractChannelHandlerContext prev = ctx.prev; AbstractChannelHandlerContext next = ctx.next; prev.next = next; next.prev = prev; } //通知删除  final void callHandlerRemoved() throws Exception { try { // Only call handlerRemoved(...) if we called handlerAdded(...) before.  if (handlerState == ADD_COMPLETE) { handler().handlerRemoved(this); } } finally { // Mark the handler as removed in any case.  //标记handler删除了  setRemoved(); } } Inboud事件 根据上面的描述，最终loop会绑定到pipeline中，当processSelectedKeys触发后，最后会调用到pipeline的fireChannelRead方法，找到下一个inboundHandlerContext\npublic ChannelHandlerContext fireChannelRead(Object msg) { invokeChannelRead(this.findContextInbound(), msg); return this; } //找到下一个Inbound的handler  private AbstractChannelHandlerContext findContextInbound() { AbstractChannelHandlerContext ctx = this; do { ctx = ctx.next; } while(!ctx.inbound); return ctx; } //创建handlerContext  DefaultChannelHandlerContext(DefaultChannelPipeline pipeline, EventExecutor executor, String name, ChannelHandler handler) { //判断是否是inbound  super(pipeline, executor, name, isInbound(handler), isOutbound(handler)); if (handler == null) { throw new NullPointerException(\u0026#34;handler\u0026#34;); } else { this.handler = handler; } } private static boolean isInbound(ChannelHandler handler) { return handler instanceof ChannelInboundHandler; } //出发handler的方法，直接到用户的业务代码了  private void invokeChannelRead(Object msg) { if (this.invokeHandler()) { try { ((ChannelInboundHandler)this.handler()).channelRead(this, msg); } catch (Throwable var3) { this.notifyHandlerException(var3); } } else { this.fireChannelRead(msg); } } outBound事件 包含bind、connect、disconnect方法、close、deregister、read、write、flush等方法，这些方法更多的是主动向用户发起的操作。\n（而inBound事件更多的是事件的触发，如register、readComplete、active，比较被动的）\noutBound是从tail反过来在链表上传输的\nctx.channel().write()和ctx.write()的区别 ctx.channel().write()从tail节点开始传播，ctx.write()从当前节点开始传播（不包括当前节点，因为它首先会找到当前节点的下一个节点在执行write操作）。\nByteBuf   Pooled和Unpooled\n池化和不池化\n  Unsafe和非Unsafe\nunsafe通过操作底层unsafe的offset+index的方式去操作数据，非unsafe直接通过一个数组的下标（或者jdk底层的buffer）去操作数据。\n  Heap和Direct\nheap是依赖一个数组，direct是依赖jdk底层的ByteBuffer。\n  ByteBuffAllocator UnpooledByteBufAllocator 分配堆内内存 //如果jdk环境支持unsafe，则用unsafe操作内存空间 //heap 内存空间，底层就是一个数组 protected ByteBuf newHeapBuffer(int initialCapacity, int maxCapacity) { return PlatformDependent.hasUnsafe() ? new InstrumentedUnpooledUnsafeHeapByteBuf(this, initialCapacity, maxCapacity) : new InstrumentedUnpooledHeapByteBuf(this, initialCapacity, maxCapacity); } public UnpooledHeapByteBuf(ByteBufAllocator alloc, int initialCapacity, int maxCapacity) { super(maxCapacity); if (initialCapacity \u0026gt; maxCapacity) { throw new IllegalArgumentException(String.format( \u0026#34;initialCapacity(%d) \u0026gt; maxCapacity(%d)\u0026#34;, initialCapacity, maxCapacity)); } this.alloc = checkNotNull(alloc, \u0026#34;alloc\u0026#34;); //声明数组  setArray(allocateArray(initialCapacity)); setIndex(0, 0); } //创建数组  protected byte[] allocateArray(int initialCapacity) { return new byte[initialCapacity]; } 分配堆外内存 底层调用jdk的DirectBuffer\n@Override protected ByteBuf newDirectBuffer(int initialCapacity, int maxCapacity) { final ByteBuf buf; if (PlatformDependent.hasUnsafe()) { buf = noCleaner ? new InstrumentedUnpooledUnsafeNoCleanerDirectByteBuf(this, initialCapacity, maxCapacity) : new InstrumentedUnpooledUnsafeDirectByteBuf(this, initialCapacity, maxCapacity); } else { buf = new InstrumentedUnpooledDirectByteBuf(this, initialCapacity, maxCapacity); } return disableLeakDetector ? buf : toLeakAwareBuffer(buf); } public UnpooledDirectByteBuf(ByteBufAllocator alloc, int initialCapacity, int maxCapacity) { super(maxCapacity); ObjectUtil.checkNotNull(alloc, \u0026#34;alloc\u0026#34;); checkPositiveOrZero(initialCapacity, \u0026#34;initialCapacity\u0026#34;); checkPositiveOrZero(maxCapacity, \u0026#34;maxCapacity\u0026#34;); if (initialCapacity \u0026gt; maxCapacity) { throw new IllegalArgumentException(String.format( \u0026#34;initialCapacity(%d) \u0026gt; maxCapacity(%d)\u0026#34;, initialCapacity, maxCapacity)); } this.alloc = alloc; setByteBuffer(allocateDirect(initialCapacity), false); } protected ByteBuffer allocateDirect(int initialCapacity) { return ByteBuffer.allocateDirect(initialCapacity); } public static ByteBuffer allocateDirect(int capacity) { return new DirectByteBuffer(capacity); } void setByteBuffer(ByteBuffer buffer, boolean tryFree) { if (tryFree) { ByteBuffer oldBuffer = this.buffer; if (oldBuffer != null) { if (doNotFree) { doNotFree = false; } else { freeDirect(oldBuffer); } } } this.buffer = buffer; tmpNioBuf = null; capacity = buffer.remaining(); } final void setByteBuffer(ByteBuffer buffer, boolean tryFree) { super.setByteBuffer(buffer, tryFree); //计算内存地址，使用Unsafe去操作  memoryAddress = PlatformDependent.directBufferAddress(buffer); } //非 unsafe，直接调用jdk方法  protected byte _getByte(int index) { return buffer.get(index); } //获取内存地址，在用unsafe去调用  @Override protected byte _getByte(int index) { return UnsafeByteBufUtil.getByte(addr(index)); } //计算地址  final long addr(int index) { return memoryAddress + index; } PooledByteBufAllocator 分配堆内内存 @Override protected ByteBuf newHeapBuffer(int initialCapacity, int maxCapacity) { PoolThreadCache cache = threadCache.get();//取出当前线程的缓存，多线程情况下的处理  PoolArena\u0026lt;byte[]\u0026gt; heapArena = cache.heapArena; //取出当前缓存里的arena  final ByteBuf buf; if (heapArena != null) { buf = heapArena.allocate(cache, initialCapacity, maxCapacity); } else { buf = PlatformDependent.hasUnsafe() ? new UnpooledUnsafeHeapByteBuf(this, initialCapacity, maxCapacity) : new UnpooledHeapByteBuf(this, initialCapacity, maxCapacity); } return toLeakAwareBuffer(buf); } final class PoolThreadLocalCache extends FastThreadLocal\u0026lt;PoolThreadCache\u0026gt; { @Override protected synchronized PoolThreadCache initialValue() { final PoolArena\u0026lt;byte[]\u0026gt; heapArena = leastUsedArena(heapArenas); final PoolArena\u0026lt;ByteBuffer\u0026gt; directArena = leastUsedArena(directArenas); //FastThreadLocal就是ThreacLocal的快速版本，首次没有取到缓存的时候，会进行初始化动作  return new PoolThreadCache( heapArena, directArena, tinyCacheSize, smallCacheSize, normalCacheSize, DEFAULT_MAX_CACHED_BUFFER_CAPACITY, DEFAULT_CACHE_TRIM_INTERVAL); } ... } ByteToMessageDecoder 抽象的字节解码器\n@Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { if (msg instanceof ByteBuf) { CodecOutputList out = CodecOutputList.newInstance(); try { first = cumulation == null; //检查是否要扩容，默认netty实现是合并到一个ByteBuf上，需要内存复制，另一种是直接创建一个新的compositeByteBuf  cumulation = cumulator.cumulate(ctx.alloc(), first ? Unpooled.EMPTY_BUFFER : cumulation, (ByteBuf) msg); callDecode(ctx, cumulation, out); } catch (DecoderException e) { throw e; } catch (Exception e) { throw new DecoderException(e); } finally { try { if (cumulation != null \u0026amp;\u0026amp; !cumulation.isReadable()) { numReads = 0; cumulation.release(); cumulation = null; } else if (++numReads \u0026gt;= discardAfterReads) { // We did enough reads already try to discard some bytes so we not risk to see a OOME.  // See https://github.com/netty/netty/issues/4275  numReads = 0; discardSomeReadBytes(); } int size = out.size(); firedChannelRead |= out.insertSinceRecycled(); fireChannelRead(ctx, out, size); } finally { out.recycle(); } } } else { ctx.fireChannelRead(msg); } } //默认Cumulator实现，内存复制到一个ByteBuf上  public static final Cumulator MERGE_CUMULATOR = new Cumulator() { @Override public ByteBuf cumulate(ByteBufAllocator alloc, ByteBuf cumulation, ByteBuf in) { if (!cumulation.isReadable() \u0026amp;\u0026amp; in.isContiguous()) { // If cumulation is empty and input buffer is contiguous, use it directly  cumulation.release(); return in; } try { final int required = in.readableBytes(); if (required \u0026gt; cumulation.maxWritableBytes() || (required \u0026gt; cumulation.maxFastWritableBytes() \u0026amp;\u0026amp; cumulation.refCnt() \u0026gt; 1) || cumulation.isReadOnly()) { // Expand cumulation (by replacing it) under the following conditions:  // - cumulation cannot be resized to accommodate the additional data  // - cumulation can be expanded with a reallocation operation to accommodate but the buffer is  // assumed to be shared (e.g. refCnt() \u0026gt; 1) and the reallocation may not be safe.  return expandCumulation(alloc, cumulation, in); } cumulation.writeBytes(in, in.readerIndex(), required); in.readerIndex(in.writerIndex()); return cumulation; } finally { // We must release in in all cases as otherwise it may produce a leak if writeBytes(...) throw  // for whatever release (for example because of OutOfMemoryError)  in.release(); } } }; protected void callDecode(ChannelHandlerContext ctx, ByteBuf in, List\u0026lt;Object\u0026gt; out) { try { while (in.isReadable()) { final int outSize = out.size(); //解析到了数据  if (outSize \u0026gt; 0) { //通知到下一个handler  fireChannelRead(ctx, out, outSize); out.clear(); // Check if this handler was removed before continuing with decoding.  // If it was removed, it is not safe to continue to operate on the buffer.  //  // See:  // - https://github.com/netty/netty/issues/4635  if (ctx.isRemoved()) { break; } } int oldInputLength = in.readableBytes(); //子类实现decode  decodeRemovalReentryProtection(ctx, in, out); // Check if this handler was removed before continuing the loop.  // If it was removed, it is not safe to continue to operate on the buffer.  //  // See https://github.com/netty/netty/issues/1664  if (ctx.isRemoved()) { break; } //如果子类没有解析到对象  // 1 数据不够解析道对象的  // 2  if (out.isEmpty()) { //数据不够解析的，跳出while，等下一次继续  if (oldInputLength == in.readableBytes()) { break; } else { // 解析出来的东西，不够合成一个对象的，继续解析  continue; } } // 解析出对象了，但是数据没有减少，有问题啊，明显对象你自己搞出来的，不是从数据里拿的，你有问题  if (oldInputLength == in.readableBytes()) { throw new DecoderException( StringUtil.simpleClassName(getClass()) + \u0026#34;.decode() did not read anything but decoded a message.\u0026#34;); } // 如果只要解析一个，直接跳出  if (isSingleDecode()) { break; } } } catch (DecoderException e) { throw e; } catch (Exception cause) { throw new DecoderException(cause); } } ","permalink":"https://sunhao1256.github.io/posts/netty/","summary":"netty是在什么地方创建SeverChannel的 在BootStrap调用bind方法时创建\nprivate ChannelFuture doBind(final SocketAddress localAddress) { final ChannelFuture regFuture = this.initAndRegister(); } initAndRegister方法\nfinal ChannelFuture initAndRegister() { Channel channel = null; try { channel = this.channelFactory.newChannel(); channelFactory是在bootstrap配置class时实例化的\n在AbstractBootstrap中\npublic B channel(Class\u0026lt;? extends C\u0026gt; channelClass) { return this.channelFactory((io.netty.channel.ChannelFactory)(new ReflectiveChannelFactory((Class)ObjectUtil.checkNotNull(channelClass, \u0026#34;channelClass\u0026#34;)))); } 因此是直接通过反射，创建了NioServerSocketChannel.class\npublic class NioServerSocketChannel extends AbstractNioMessageChannel implements ServerSocketChannel { private static final ChannelMetadata METADATA = new ChannelMetadata(false, 16); private static final SelectorProvider DEFAULT_SELECTOR_PROVIDER = SelectorProvider.provider(); private static final InternalLogger logger = InternalLoggerFactory.","title":""},{"content":"@Override\r@Nullable\rpublic Object invoke(MethodInvocation mi) throws Throwable {\rif (!(mi instanceof ProxyMethodInvocation)) {\rthrow new IllegalStateException(\u0026quot;MethodInvocation is not a Spring ProxyMethodInvocation: \u0026quot; + mi);\r}\rProxyMethodInvocation pmi = (ProxyMethodInvocation) mi;\rProceedingJoinPoint pjp = lazyGetProceedingJoinPoint(pmi);\rJoinPointMatch jpm = getJoinPointMatch(pmi);\rreturn invokeAdviceMethod(pjp, jpm, null, null);\r}\r当在Sping中配置的Bean存在相互依赖，Spring是怎么处理的 针对原型Bean直接抛出异常，不支持。\n单例Bean，Spring使用3个Map做缓存，来处理。\n分别是：一级缓存Spring最终保存的单例对象Map，二级缓存建造Spring单例对象的匿名工厂对象返回的就是三级缓存需要的，三级缓存是允许提前被依赖的单例对象。\n阐述一个Bean获取的流程  尝试获取单例Bean 检查一级缓存是否有，没有的话，检查当前获取的Bean是否正在创建，如果正在创建即出现了Bean互相依赖情况，检查三级缓存是否已经有提前可被依赖的对象，如果没有的话，检查二级缓存是否有其工厂，有的话，使用工厂，实例化这个Bean，放入三级缓存里。供其他Bean依赖使用 没获取到，可能是原型Bean，也可能是单例Bean没有实例化 检查如果是原型Bean，而且正在创建中，即出现了原型Bean被依赖的情况，直接抛出异常 准备BeanDefinition，如果档期工厂没有相应的BD，而且父工厂又存在BD，使用父工厂的getBean方法去获取Bean 标记Bean创建过了 从当前工厂读取BD,并且转为RootBeanDefinition，获取期间，还要检查父工厂是否也有该Bean的BD，有的话，以父工厂得BD为基础，子工厂得BD覆盖掉其属性 检查BD是不是抽象的，无法实例化的类，抛出异常 检查BD中得DependsOn属性，针对所有Depend，循环实例化，如果检查到有Depend得Bean又依赖于当前目标Bean，抛出异常，互相提前依赖了。并且建立相关关系，所以DependOn意义是，依赖于一个完全实例化完成后的Bean 如果是单例的话，开始创建单例Bean，创建匿名工厂对象 标记单例Bean正在被创建 使用工厂对象去调用getObject方法 实际上执行了createBean方法 根据之前的RootBD，解析出需要实例化的Class对象 检查MethodOverrides目标方法是否存在Class对象中 在实例化对象之前，给InstantiationAwareBeanPostProcessor机会去改变实例，调用其postProcessBeforeInstantiation，AOP就是在这里实现的，此外，如果返回了，还会调用BPP的postProcessAfterInitialization，但不会调用postProcessBeforeInitialization了 如果没有被InstantiationAwareBeanPostProcessor改变了的话，开始进入真正的实例化方法 实例化一个BeanWrapperImpl去封装实例 解析Class对象，确定Class对象有Public修饰符 如果有FactoryMethod的话，直接调用FactoryMethod返回实例，封装在BeanWrapperImpl，这里面也会初始化initBeanWrapper，将属性编辑器注入到BeanWrapperImpl身上，用于后续的属性注入 开始解析构造函数或者是FactoryMethod，如果解析过了，直接去实例化 否则进入构造函数解析 解析之前，看BPP有没有提供了构造函数，即SmartInstantiationAwareBeanPostProcessor的determineCandidateConstructors方法执行，如果返回了构造函数，就用BPP的了。 没有的话，进入默认的解析，依赖先看缓存里有没有解析过的参数，因为构造方法注入的话，很消耗性能，没有缓存的话，先看用户获取bean时有没有传入args，即构造函数的参数。没有的话，而且只有一个候选的构造函数，就直接用使用无参的了，没有的话，先去解析参数，construct-arg，既可以时Index，也可以是name。根据用户传入的arg长度，去解析。 最后解析完成后，使用实例化策略去实例化即可，这里也可使用cglib去处理，然后封装在BeanWrapperImpl中 至此，BeanWapper里已经包含了我们的目标对象的实例了 然后创建二级缓存，将上一步BeanWapper里的实例，作为二级缓存返回的对象，加载缓存里 至此，二级缓存的工厂加入 了。当在一开始获bean，一级获取不到，获取二级有工厂的时候，就会把BeanWapper的实例暴露出去，供后续使用 然后开始初始化实例 将上面暴露出来的示例进行属性注入 给InstantiationAwareBeanPostProcessor的postProcessAfterInstantiation在属性注入之前最后一次机会，去改变Bean，并且阻止Bean的属性注入 判断属性注入的是byName还是byType，针对所有的非简单的属性，还有排除所有的ignoredDependencyInterfaces中的接口。进行getBean操作，保存到PropertyValues中 使用InstantiationAwareBeanPostProcessor的postProcessProperties，可以进行修改属性。继续使用postProcessPropertyValues，继续可以更该属性 得到所有属性后，应用属性到Bean实例身上，在应用属性的时候，会找到前工厂里的所有的TypeConverter去将属性变为需要的属性，如果变不成会报错 至此，属性赋值完毕 复制完毕后，开始初始化Bean，先激活所有的aware方法， 调用BPP的postProcessBeforeInitialization初始化之前方法，记住，这里的初始化，是Bean已经实例化之后的事情了，是执行其他事情的初始化 执行afterPropertiesSet方法，在执行init-methods方法 调用BPP的postProcessAfterInitialization初始化以后方法 至此返回暴露的bean，即getBean结束 最后处理销毁的方法，即出发destory-method的方法  Spring是如何处理掉循环依赖的  针对非单例Bean出现循环依赖直接抛出异常 单例Bean Spring存在3个缓存Map  Spring完全生成好的BeanMap，key是Bean的name，Value是实例对象 Spring生成Bean的工厂Map，key是Bean的name，value是实现了ObjectFactory接口的实例对象 Spring尚未初始化，即赋予属性或者其他初始化动作的Bean实例Map，key是Bean的name，value是工厂map的工厂的返回值，即ObjectFactory的getObject方法结果   假设存在对象A依赖于对象B，对象Bean依赖于对象A  Spring根据A的name，首先取BeanMap里找是否有A的实例，没有的话，检查A是否正在创建，如果正在创建，则说明出现了循环依赖。（需要获取A，发现A又在创建，表名有其他bean需要A），尝试从可提前依赖的BeanMap获取EarlyBeanReference，如果没有，则尝试从工厂Map里找A对应的工厂对象，如果有工厂对象，则调用工厂对象进行返回，并且将工厂返回的Bean实例作为EarlyBeanReference，放入未完全实例化结束BeanMap里，删除工厂Map对应的value。此时工厂Map为空。 此时，A没有正在创建，继续 标记A正在创建，根绝BeanDefinition生成Bean实例对象，（此时对象实例已经生成完毕，但是还没有初始化），并且把A的创建工厂，放入工厂Map，而这个创建工厂getObject返回值就是刚才生成的实例对象，并且给SmartInstantiationAwareBeanPostProcessor接口机会取改变这个EarlyBeanReference对象。 得到实例化后的A对象，开始注入A的属性，发现A的属性b，需要B对象。 B对象开始获取（此时，A还没有结束，即一级缓存中没有A，二级缓存中有A的工厂Map） B的获取如上述一致， 直至B实例化结束，开始注入B的属性，发现B的属性a，需要A对象 又到了A对象开始获取 此时，进入第一个流程，发现一级缓存里没有A，而A又正在创建中，出现循环依赖，去二级缓存里找A的工厂Map，调用工厂Map方法去，得到了EarlyBeanReference，放入三级缓存里，返回回去 即此时，B注入属性成功，并且返回了一个EarlyBeanReference，即当前正在创建的A对象实例。 B注入成功属性后，B实例化完全结束，结束后，清除B的二三级缓存，加入一级缓存并返回 此时回到了A的注入B属性逻辑中，A得到了B实例。而这个实例里的A属性对象，和当前获取A的对象是一个 A继续完成初始化动作，最后A实例化完全结束，清楚A的二三级缓存，加入一级缓存并返回   只有2个缓存行吗？为什么一定要3个  BeanMap无用质疑是需要的 如果只有工厂Map而没有，可提前依赖的BeanMap的话，那么在一开始从缓存中获取Bean，一级缓存无法获取到，直接就有工厂Bean，一旦有工厂就调用工厂返回的值，这样是不行的，因为在工厂调用Bean的时候，有很多动作就会进行重复，比如工厂获取的时候，可以给SmartInstantiationAwareBeanPostProcessor机会去更改EarlyBeanReference对象，重复执行了。第二，与工厂模式的思想违背，工厂只需要制造一次，而不是每次都制造。 如果只有可提前依赖的BeanMap，而没有工厂Map。实际上是可以的，只不过没有工厂的话，会将大部分工作都抛给创建Bean的流程里，例如SmartInstantiationAwareBeanPostProcessor等工厂应该负责的工作    ApplicationContext的Refresh方法  Enviroment，环境参数，根据不同的环境，实现Environment不同的子类，例如Web环境会实现，StandardServletEnvironment，默认是实现StandardEnvironment，包含很多环境变量，系统变量，java环境变量，Servlet环境变量 创建beanFactory作为成员变量，ApplicationContext自身也实现了BeanFactory接口，只不过具体实现的方法是成员变量的beanFactory的方法、 填充工厂  增加SPEL表达式解析器 属性编辑器注入 增加一个ApplicationContextAwareProcessor的BPP，在Bean实例化之后，激活实现了aware接口的方法的一个BPP 配置忽略某些类型的属性自动注入，增加某些类型自动注入   postProcessBeanFactory：留给子类去实现 记录启动路径 激活BeanFactoryPostProcessor，invokeBeanFactoryPostProcessors 注册BeanPostProcessor 初始化国际化文件 初始化initApplicationEventMulticaster，事件传送器，用于发送事件 注册事件监听器 设置ConversionService 锁定所有BeanDefinitions，防止改变 实例化剩下所有的no-lazy实例 调用所有实现LifeCycle接口的bean 发送ContextRefreshedEvent事件  BeanFactoryPostProcessor和BeanPostProcessor区别   BeanFactoryPostProcessor是可以修改Bean的元数据，是控制BeanFactory的，而BeanPostProcessor是Bean实例的处理器，可以修改Bean的实例\n  以PropertySourcesPlaceholderConfigurer为例\n很明显，作用就是对于Beanfactory的所有Beandefintion进行处理，即在xml里中配置的${}属性\n@Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException { try { Properties mergedProps = mergeProperties(); // Convert the merged properties, if necessary. \tconvertProperties(mergedProps); // Let the subclass process the properties. \tprocessProperties(beanFactory, mergedProps); } catch (IOException ex) { throw new BeanInitializationException(\u0026#34;Could not load properties\u0026#34;, ex); } } @Override protected void processProperties(ConfigurableListableBeanFactory beanFactoryToProcess, Properties props) throws BeansException { StringValueResolver valueResolver = new PlaceholderResolvingStringValueResolver(props); doProcessProperties(beanFactoryToProcess, valueResolver); } protected void doProcessProperties(ConfigurableListableBeanFactory beanFactoryToProcess, StringValueResolver valueResolver) { BeanDefinitionVisitor visitor = new BeanDefinitionVisitor(valueResolver); String[] beanNames = beanFactoryToProcess.getBeanDefinitionNames(); for (String curName : beanNames) { // Check that we\u0026#39;re not parsing our own bean definition, \t// to avoid failing on unresolvable placeholders in properties file locations. \tif (!(curName.equals(this.beanName) \u0026amp;\u0026amp; beanFactoryToProcess.equals(this.beanFactory))) { BeanDefinition bd = beanFactoryToProcess.getBeanDefinition(curName); try { visitor.visitBeanDefinition(bd); } catch (Exception ex) { throw new BeanDefinitionStoreException(bd.getResourceDescription(), curName, ex.getMessage(), ex); } } } // New in Spring 2.5: resolve placeholders in alias target names and aliases as well. \tbeanFactoryToProcess.resolveAliases(valueResolver); // New in Spring 3.0: resolve placeholders in embedded values such as annotation attributes. \tbeanFactoryToProcess.addEmbeddedValueResolver(valueResolver); } public void visitBeanDefinition(BeanDefinition beanDefinition) { visitParentName(beanDefinition); visitBeanClassName(beanDefinition); visitFactoryBeanName(beanDefinition); visitFactoryMethodName(beanDefinition); visitScope(beanDefinition); if (beanDefinition.hasPropertyValues()) { visitPropertyValues(beanDefinition.getPropertyValues()); } if (beanDefinition.hasConstructorArgumentValues()) { ConstructorArgumentValues cas = beanDefinition.getConstructorArgumentValues(); visitIndexedArgumentValues(cas.getIndexedArgumentValues()); visitGenericArgumentValues(cas.getGenericArgumentValues()); } }   上面的例子即可以看出BeanFactoryPostProcessor是对BeanFactory进行操作，是Bean还没实例化之前的动作\n  原理Spring AOP   Xml方式中，aspectj-autoproxy，标签默认创建一个AnnotationAwareAspectJAutoProxyCreator的BeanDefinition，注册到BeanDefinitionRegistry中\n  通过事件发送，通知到注册了\n  在Application的refresh中的finishBeanFactoryInitialization，会实例化该bean\n  AnnotationAwareAspectJAutoProxyCreator实现了Spring的BPP接口\n  正常情况下，AOP会在postProcessAfterInitialization方法执行后，wrapIfNecessary，会去找当前容器里所有的增强器，一个增强器里包含了，切入点，切入方法\n  首先会找到容器里所有的增强器，做缓存处理，对于每一个要获取的Bean都会走这个方法。具体的寻找方法，包括Spring老式的配置，即在XML里配置Bean，使用aop:config里的aop:ref和aop:point_cut，配置出来的，以及现在十分方便的使用aspectJ注解的@Aspect配合@PointCut，@Around，@Before，@After，@Throw\n  然后根据Bean的属性。检查找到的增强其里面是否有满足条件的。即查看是否满足AOP，表达式的，方法\n  如果这个bean有满足的增强器\n  则取获取代理对象，Spring有2中实现代理的方式，JDK自带的Proxy类，以及CGlib\n  JDK和GClib区别\n JDK只能针对实现了接口的类，生成代理，实现同样的接口方法，但里面调用的还是目标对象的方法 CGLIB是针对类实现代理，通过修改字节码方式，对目标对象生成一个其子类，覆写父类的方法，从而达到代理，所以类不能声明为final    Spring可以强制使用cglib，配置proxyTargetClass属性为true即可\n  根据上述找到的增强器，Spring根据配置，创建对应的AopProxy，JdkDynamicAopProxy或者CglibAopProxy\n  调用AopProxy的getProxy方法\n  JdkDynamicAopProxy\n  使用JDK自带的Proxy.newProxyInstance方式创建代理对象\nProxy.newProxyInstance(classLoader, this.proxiedInterfaces, this);   最后一个参数this，说明JdkDynamicAopProxy肯定实现了InvocationHandler，最后执行的目标方法就是invoke方法\n  在这里面处理了expose-proxy属性\n//AopContext 自身无法获取代理对象的处理 exposeProxy if (this.advised.exposeProxy) { // Make invocation available if necessary.  oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; }   然后根据传入的增强器，使用ReflectiveMethodInvocation封装，方法链，逐个调用。不同的advistor使用不同的实现类去实现，例如\n  AspectJAroundAdvice\r@Override @Nullable public Object invoke(MethodInvocation mi) throws Throwable { if (!(mi instanceof ProxyMethodInvocation)) { throw new IllegalStateException(\u0026#34;MethodInvocation is not a Spring ProxyMethodInvocation: \u0026#34; + mi); } ProxyMethodInvocation pmi = (ProxyMethodInvocation) mi; ProceedingJoinPoint pjp = lazyGetProceedingJoinPoint(pmi); JoinPointMatch jpm = getJoinPointMatch(pmi); return invokeAdviceMethod(pjp, jpm, null, null); } 这也就是为什么@Around的方法，入参可以是ProceedingJoinPoint\ninvokeAdviceMethodWithGivenArgs(argBinding(jp, jpMatch, returnValue, t));     直至所有的方法链调用结束\n  最后执行目标方法\n  处理返回对象\n    SpringMVC流程 SpringMvc会使用DispatcherServlet作为请求的入口。\n作为一个Servlet，init方法，执行后，DispatcherServlet会创建自己的IOC容器，并且把ServletContext中的IOC作为父容器，所以MVC的相关内容，例如Controller可以放在MVC的IOC中，而其余的，dao，service可以放在SevletContext里的IOC，好处就是隔离开了M层，如果要还Struts，可以直接更换，而不用考虑dao和service了。\ninit方法，除了创建MVC自己的容器，还根据DispatchServlet.properties里的内容，进行一系列的初始化动作。\nDispatcherServlet继承于FrameworkServlet。集成HttpServlet，最后从Servlet会执行到DispatchServlet的processRequest方法。processRequest中，Spring会将当前的请求requestAttributes放在RequestContextHolder中用ThreadLocal保存，所以后续的Controller都可以使用。\n随后走到doDispatch中，做一些必要的检查，然后根据容器里的handerMapping找到对应的hanlder，使用HandlerExecutionChain将符合该请求的拦截器，封装在一起，跨域也是在这里增加另一个拦截器\n准备好HandlerExecutionChain之后，进入流程。先调用所有的拦截器preHandler方法\nHandler有很多种，最后使用适配器模式，创建handlerAdapter去调用不同handler的具体执行方法。从而得到modelAndView\n然后调用拦截器的postHandler方法\n得到modelAndView，之后会使用ViewRovler解析view，最后获取requestDispatcher，forward或者是重定向到新的路径，并且把model，放入request的attribute里，从而进入下一个请求了，可以是reward也可以是redirect\n为什么在Controller的方法参数里，写HttpServletRequest就可以获得到请求对象，以及@RequestBody和@RequestParam 不管是xml中配置mvc:annotation-driven/，还是使用注解@EnableWebMvc，本质上都是在容器中注入了RequestMappingHandlerMapping这样的实例。实例实现了initalizingBean接口，在容器中实例化的时候，会将容器中所有的Bean找出来，检查Class是否被@Controller或者@RequestMapping修饰，找到即作为一个handler。\n然后去找到Hanlder对应的adapter，RequestMappingHandlerAdapter，Adapter的handler方法。\nhanlder方法的核心是，invokeHandlerMethod，通过反射调用目标方法，并且通过一些列配置，将方法需要的配置传入进去，其中解析方法参数的就是一些列的argumentResolvers。\nSpring依然是在RequestMappingHandlerAdapter的afterPropertiesSet()方法之后，。初始化了argumentResolvers\n如下\nprivate List\u0026lt;HandlerMethodArgumentResolver\u0026gt; getDefaultArgumentResolvers() { List\u0026lt;HandlerMethodArgumentResolver\u0026gt; resolvers = new ArrayList\u0026lt;\u0026gt;(30); // Annotation-based argument resolution  resolvers.add(new RequestParamMethodArgumentResolver(getBeanFactory(), false)); resolvers.add(new RequestParamMapMethodArgumentResolver()); resolvers.add(new PathVariableMethodArgumentResolver()); resolvers.add(new PathVariableMapMethodArgumentResolver()); resolvers.add(new MatrixVariableMethodArgumentResolver()); resolvers.add(new MatrixVariableMapMethodArgumentResolver()); resolvers.add(new ServletModelAttributeMethodProcessor(false)); resolvers.add(new RequestResponseBodyMethodProcessor(getMessageConverters(), this.requestResponseBodyAdvice)); resolvers.add(new RequestPartMethodArgumentResolver(getMessageConverters(), this.requestResponseBodyAdvice)); resolvers.add(new RequestHeaderMethodArgumentResolver(getBeanFactory())); resolvers.add(new RequestHeaderMapMethodArgumentResolver()); resolvers.add(new ServletCookieValueMethodArgumentResolver(getBeanFactory())); resolvers.add(new ExpressionValueMethodArgumentResolver(getBeanFactory())); resolvers.add(new SessionAttributeMethodArgumentResolver()); resolvers.add(new RequestAttributeMethodArgumentResolver()); // Type-based argument resolution  resolvers.add(new ServletRequestMethodArgumentResolver()); resolvers.add(new ServletResponseMethodArgumentResolver()); resolvers.add(new HttpEntityMethodProcessor(getMessageConverters(), this.requestResponseBodyAdvice)); resolvers.add(new RedirectAttributesMethodArgumentResolver()); resolvers.add(new ModelMethodProcessor()); resolvers.add(new MapMethodProcessor()); resolvers.add(new ErrorsMethodArgumentResolver()); resolvers.add(new SessionStatusMethodArgumentResolver()); resolvers.add(new UriComponentsBuilderMethodArgumentResolver()); if (KotlinDetector.isKotlinPresent()) { resolvers.add(new ContinuationHandlerMethodArgumentResolver()); } // Custom arguments  if (getCustomArgumentResolvers() != null) { resolvers.addAll(getCustomArgumentResolvers()); } // Catch-all  resolvers.add(new PrincipalMethodArgumentResolver()); resolvers.add(new RequestParamMethodArgumentResolver(getBeanFactory(), true)); resolvers.add(new ServletModelAttributeMethodProcessor(true)); return resolvers; } 通过 HandlerMethodArgumentResolver的supportsParameter方法\n以RequestParam为例\n首先RequestParamMethodArgumentResolver的父类AbstractNamedValueMethodArgumentResolver，进行校验，校验Hanlder的参数是否是必填，会将@RequestParams的required进行校验，从HttpServletRequest里的parameter进行校验。校验成功，会通过反射执行handler，并将参数传入Handler中。\n@RequestBody也是一样，使用的RequestResponseBodyMethodProcessor去处理参数的\n在处理@RequestBody的时候，RequestMappingHandlerAdapter的所有messageConverters，找到符合的，我们常用的application/json就是MappingJackson2HttpMessageConverter，需要引入jackson的核心包\n至于其他的Httpservlet都是是同对应的argumentResolve处理的\nSpringBoot的工作原理 Spring在诞生之初，配置类一直是令开发者吐槽的模块，当java5推出注解后，可以使用java类进行配置了，但依然很繁琐。而SpringBoot的最大的一个特点，就是解决复杂的配置。\nSpringBoot推出了一系列注解，他们可以将各类Spring boot starter，无感的注入到容器中。\nSpringBoot在SpringBoot的run方法里，完成了一些列工作。\n首先是构造方法会根据当前类路径下是否包含webflux，或者servlet相关类，从而决定实例化的容器对象。\n以常见的servlet为例，SpringBoot会实例化AnnotationConfigServletWebServerApplicationContext\n而在SpringBoot构造函数触发时，会寻找类路径下META/Spring.factories文件，下所有的ApplicationContextInitializer实例，和ApplicationListener实例，并且放入当前对象的属性中\n  核心的run方法，里首先还是从spring.factories里找到所有的SpringApplicationRunListener，调用其starting方法，\n  然后封装main方法的arg参数，校验环境，即我们可以在外部指明spring的profile.active=prod就是在这里指明的\n  准备好main的arg以及sytem的相关属性后，会调用所有SpringApplicationRunListener的environmentPrepared，也就是在这里面进行了Spring配置文件，application.yml或者是application.properties的处理\n  打印Banner\n  根据上述得到的实例化Class，实例化IOC容器\n  从spring.factories里找到SpringBootExceptionReporter用于异常打印\n  准备名称生成器，资源加载器，类加载器等。\n  调用Spring.factories里的ApplicationContextInitializer的initialize方法\n  调用ApplicationContextInitializer的contextPrepared方法\n  打印启动类信息，打印profile信息\n  加载启动类的注解信息，即启动类也可以是一个组件，注入到容器中，默认情况下，@SpringBootApplication里的@SpringBootConfiguration里有@Component注解，Spring会通过注解方式将其注入到容器中，细节就不说了，核心是@SpringBootConfiguration身上有@Configuration，而且有@Import注解，引入的是AutoConfigurationImportSelector\nSpringBoot在启动的时候，注入了ConfigurationClassPostProcessor该类实现了BeanDefinitionRegistryPostProcessor会在容器的refresh里的invokeBeanFactoryPostProcesser，里触发\npostProcessBeanDefinitionRegistry方法，会找到容器里所有的@Configuration实例，这里此时容器里有的就是启动类本身，然后会处理，@Configuration上的@Import，并且执行@Import类的process方法，即，最后依然调用的是selectImports方法，得到的就是Spring.factories里配置的**org.springframework.boot.autoconfigure.EnableAutoConfiguration=**的值，然后逐步解析所有的类，这样容器里就有第三方调用的所有信息了\npublic void process(AnnotationMetadata annotationMetadata, DeferredImportSelector deferredImportSelector) { Assert.state( deferredImportSelector instanceof AutoConfigurationImportSelector, () -\u0026gt; String.format(\u0026#34;Only %s implementations are supported, got %s\u0026#34;, AutoConfigurationImportSelector.class.getSimpleName(), deferredImportSelector.getClass().getName())); AutoConfigurationEntry autoConfigurationEntry = ((AutoConfigurationImportSelector) deferredImportSelector) .getAutoConfigurationEntry(getAutoConfigurationMetadata(), annotationMetadata); this.autoConfigurationEntries.add(autoConfigurationEntry); for (String importClassName : autoConfigurationEntry.getConfigurations()) { this.entries.putIfAbsent(importClassName, annotationMetadata); } } protected AutoConfigurationEntry getAutoConfigurationEntry( AutoConfigurationMetadata autoConfigurationMetadata, AnnotationMetadata annotationMetadata) { if (!isEnabled(annotationMetadata)) { return EMPTY_ENTRY; } AnnotationAttributes attributes = getAttributes(annotationMetadata); List\u0026lt;String\u0026gt; configurations = getCandidateConfigurations(annotationMetadata,//获取到所有的/META-INF/spring-factories中的configuration  attributes); configurations = removeDuplicates(configurations);//删除重复的  Set\u0026lt;String\u0026gt; exclusions = getExclusions(annotationMetadata, attributes); checkExcludedClasses(configurations, exclusions);//根据上面的属性excclusion  configurations.removeAll(exclusions); configurations = filter(configurations, autoConfigurationMetadata); fireAutoConfigurationImportEvents(configurations, exclusions);//通知导入成功  return new AutoConfigurationEntry(configurations, exclusions); }   Spring事务   Spring使用注解@Transactional放在方法，或者类上\n  @Transactional属性有\n transactionManager指明事务管理器，在多数据源的时候，需要指明 propagation传播行为默认是Propagation.REQUIRED，即当前如果存在事务，则用同一个事务，否则开启一个新事务 isolation隔离级别，默认是数据库的隔离级别，mysql默认时可重复度，幻读是通过MVCC和间隙锁解决的 timeout超时时间 readOnly是否只读 rollbackFor发生什么异常才会会滚，默认是RuntimeException rollbackForClassName noRollbackFor noRollbackForClassName    原理，@Transactional注解是基于AOP原理，容器在获取相应bean的时候，会去使用wrapifNecessary包装bean，Spring的流程是，从容器里找到所有的adviser，而@Transactional会在容器里注入BeanFactoryTransactionAttributeSourceAdvisor，从而最后得到的是代理对象，而代理对象针对于满足切面条件的bean，会做处理，@Transactional就是切面条件，会在目标方法执行之前开启一个事务，执行之后提交或者回滚一个事务，操作事务的都是TransactionManager\n  提问\n  如果在一个方法里异常被try-catch了，还会会滚吗？不会了，因为Sping处理提交事务是在切面的AfterRunning之后提交的，在那之前会使用try-catch捕捉，而目标自己捕捉过的话，Spring就捕捉不到了，除非在catch里再抛出\n  如果自己使用TransactionManager重新在获取一个事务，手动提交之前，抛出异常的话，会会滚吗？不会，会被Spring捕捉到\n  如果在抛出异常之前，就手动提交了，Spring会回滚吗，可能会 也可能不会，这和Spring事务的传播行为有关，默认情况下传播行为是，如果当前有事务了，就用当前事务，否则开启一个新事务。\n如果有@Transactional注解了，意味着Spring已经开启了一个事务了，后续自己手动开启的事务，就是之前的事务了，并非一个新事务，Spring在提交事务之前，会判断是否为一个新事务，是的话，才会进行提交，否则不会有动作。所有如果传播行为不变的话，会回滚的，如果是强制开启新的事务的传播行为，则不会会滚\n    讲讲你会的设计模式，Spring里面用到了哪些设计模式 Java中的Date是线程安全的吗？你是如何保证线程安全的 讲讲ThreadLocal 和java的内存模型吧 WebAsyncTask WebAsyncTask，是基于Servlet3.0异步Servlet的特性，用于提高容器的吞吐量，客户端请求进来时，当前的容器分配的线程会直接返回，并会开启一个新线程用于处理客户端请求，当新线程结束时，客户端才会收到请求。而容器的线程就可以回收用于新的请求，提高了吞吐量\n拦截器和过滤器的区别 首先，拦截器与过滤器不是一起的，拦截器是Spring的，而过滤器filter是javax提供的，filter会在拦截器之前执行，拦截器可以达到更细粒控制请求。拦截器可以获得到具体执行的handler，可以对handler做个性化操作。过滤器可以做的，拦截器都可以做到，拦截器做的，过滤器做不了。\n聊一下mybatis 什么是mybatis的懒加载 mybatis的mapper是如何与数据库连接的 什么是索引，索引为什么可以加查询 Innodb索引实现 B树和B+树 Redis使用，部署，哨兵 TCP三次握手 乐观锁，悲观锁，举例 设计模式 Redis扩容 CAS概念，原子类的实现 Synchronize 底层原理 AQS 网络模型，你知道的网络协议 HTTPS的连接过程，SSL 单链表算法，反转，查找 jvm垃圾回收机制 工作流引擎 Spring MVC webFlux netty redis为什么这么快 Mysql的explain K8S 讲一讲反射，以及你工作中用到的地方 java反射，提供给我们方式去动态创建类，或者是动态执行方法，当我们因为某些条件，不知道目标应该执行什么方法的时候，就可以使用反射。\n例如，请假，如果超过2天，就执行某方法，否则执行另一个方法，我们就可以用反射\n反射也被大量应用于mybatis和spring之中，spring中aop，创建bean的动作都是反射，因为他们无论是执行方法还是构建实例都是未知的参数和条件\n","permalink":"https://sunhao1256.github.io/posts/spring%E6%95%B4%E7%90%86/","summary":"@Override\r@Nullable\rpublic Object invoke(MethodInvocation mi) throws Throwable {\rif (!(mi instanceof ProxyMethodInvocation)) {\rthrow new IllegalStateException(\u0026quot;MethodInvocation is not a Spring ProxyMethodInvocation: \u0026quot; + mi);\r}\rProxyMethodInvocation pmi = (ProxyMethodInvocation) mi;\rProceedingJoinPoint pjp = lazyGetProceedingJoinPoint(pmi);\rJoinPointMatch jpm = getJoinPointMatch(pmi);\rreturn invokeAdviceMethod(pjp, jpm, null, null);\r}\r当在Sping中配置的Bean存在相互依赖，Spring是怎么处理的 针对原型Bean直接抛出异常，不支持。\n单例Bean，Spring使用3个Map做缓存，来处理。\n分别是：一级缓存Spring最终保存的单例对象Map，二级缓存建造Spring单例对象的匿名工厂对象返回的就是三级缓存需要的，三级缓存是允许提前被依赖的单例对象。\n阐述一个Bean获取的流程  尝试获取单例Bean 检查一级缓存是否有，没有的话，检查当前获取的Bean是否正在创建，如果正在创建即出现了Bean互相依赖情况，检查三级缓存是否已经有提前可被依赖的对象，如果没有的话，检查二级缓存是否有其工厂，有的话，使用工厂，实例化这个Bean，放入三级缓存里。供其他Bean依赖使用 没获取到，可能是原型Bean，也可能是单例Bean没有实例化 检查如果是原型Bean，而且正在创建中，即出现了原型Bean被依赖的情况，直接抛出异常 准备BeanDefinition，如果档期工厂没有相应的BD，而且父工厂又存在BD，使用父工厂的getBean方法去获取Bean 标记Bean创建过了 从当前工厂读取BD,并且转为RootBeanDefinition，获取期间，还要检查父工厂是否也有该Bean的BD，有的话，以父工厂得BD为基础，子工厂得BD覆盖掉其属性 检查BD是不是抽象的，无法实例化的类，抛出异常 检查BD中得DependsOn属性，针对所有Depend，循环实例化，如果检查到有Depend得Bean又依赖于当前目标Bean，抛出异常，互相提前依赖了。并且建立相关关系，所以DependOn意义是，依赖于一个完全实例化完成后的Bean 如果是单例的话，开始创建单例Bean，创建匿名工厂对象 标记单例Bean正在被创建 使用工厂对象去调用getObject方法 实际上执行了createBean方法 根据之前的RootBD，解析出需要实例化的Class对象 检查MethodOverrides目标方法是否存在Class对象中 在实例化对象之前，给InstantiationAwareBeanPostProcessor机会去改变实例，调用其postProcessBeforeInstantiation，AOP就是在这里实现的，此外，如果返回了，还会调用BPP的postProcessAfterInitialization，但不会调用postProcessBeforeInitialization了 如果没有被InstantiationAwareBeanPostProcessor改变了的话，开始进入真正的实例化方法 实例化一个BeanWrapperImpl去封装实例 解析Class对象，确定Class对象有Public修饰符 如果有FactoryMethod的话，直接调用FactoryMethod返回实例，封装在BeanWrapperImpl，这里面也会初始化initBeanWrapper，将属性编辑器注入到BeanWrapperImpl身上，用于后续的属性注入 开始解析构造函数或者是FactoryMethod，如果解析过了，直接去实例化 否则进入构造函数解析 解析之前，看BPP有没有提供了构造函数，即SmartInstantiationAwareBeanPostProcessor的determineCandidateConstructors方法执行，如果返回了构造函数，就用BPP的了。 没有的话，进入默认的解析，依赖先看缓存里有没有解析过的参数，因为构造方法注入的话，很消耗性能，没有缓存的话，先看用户获取bean时有没有传入args，即构造函数的参数。没有的话，而且只有一个候选的构造函数，就直接用使用无参的了，没有的话，先去解析参数，construct-arg，既可以时Index，也可以是name。根据用户传入的arg长度，去解析。 最后解析完成后，使用实例化策略去实例化即可，这里也可使用cglib去处理，然后封装在BeanWrapperImpl中 至此，BeanWapper里已经包含了我们的目标对象的实例了 然后创建二级缓存，将上一步BeanWapper里的实例，作为二级缓存返回的对象，加载缓存里 至此，二级缓存的工厂加入 了。当在一开始获bean，一级获取不到，获取二级有工厂的时候，就会把BeanWapper的实例暴露出去，供后续使用 然后开始初始化实例 将上面暴露出来的示例进行属性注入 给InstantiationAwareBeanPostProcessor的postProcessAfterInstantiation在属性注入之前最后一次机会，去改变Bean，并且阻止Bean的属性注入 判断属性注入的是byName还是byType，针对所有的非简单的属性，还有排除所有的ignoredDependencyInterfaces中的接口。进行getBean操作，保存到PropertyValues中 使用InstantiationAwareBeanPostProcessor的postProcessProperties，可以进行修改属性。继续使用postProcessPropertyValues，继续可以更该属性 得到所有属性后，应用属性到Bean实例身上，在应用属性的时候，会找到前工厂里的所有的TypeConverter去将属性变为需要的属性，如果变不成会报错 至此，属性赋值完毕 复制完毕后，开始初始化Bean，先激活所有的aware方法， 调用BPP的postProcessBeforeInitialization初始化之前方法，记住，这里的初始化，是Bean已经实例化之后的事情了，是执行其他事情的初始化 执行afterPropertiesSet方法，在执行init-methods方法 调用BPP的postProcessAfterInitialization初始化以后方法 至此返回暴露的bean，即getBean结束 最后处理销毁的方法，即出发destory-method的方法  Spring是如何处理掉循环依赖的  针对非单例Bean出现循环依赖直接抛出异常 单例Bean Spring存在3个缓存Map  Spring完全生成好的BeanMap，key是Bean的name，Value是实例对象 Spring生成Bean的工厂Map，key是Bean的name，value是实现了ObjectFactory接口的实例对象 Spring尚未初始化，即赋予属性或者其他初始化动作的Bean实例Map，key是Bean的name，value是工厂map的工厂的返回值，即ObjectFactory的getObject方法结果   假设存在对象A依赖于对象B，对象Bean依赖于对象A  Spring根据A的name，首先取BeanMap里找是否有A的实例，没有的话，检查A是否正在创建，如果正在创建，则说明出现了循环依赖。（需要获取A，发现A又在创建，表名有其他bean需要A），尝试从可提前依赖的BeanMap获取EarlyBeanReference，如果没有，则尝试从工厂Map里找A对应的工厂对象，如果有工厂对象，则调用工厂对象进行返回，并且将工厂返回的Bean实例作为EarlyBeanReference，放入未完全实例化结束BeanMap里，删除工厂Map对应的value。此时工厂Map为空。 此时，A没有正在创建，继续 标记A正在创建，根绝BeanDefinition生成Bean实例对象，（此时对象实例已经生成完毕，但是还没有初始化），并且把A的创建工厂，放入工厂Map，而这个创建工厂getObject返回值就是刚才生成的实例对象，并且给SmartInstantiationAwareBeanPostProcessor接口机会取改变这个EarlyBeanReference对象。 得到实例化后的A对象，开始注入A的属性，发现A的属性b，需要B对象。 B对象开始获取（此时，A还没有结束，即一级缓存中没有A，二级缓存中有A的工厂Map） B的获取如上述一致， 直至B实例化结束，开始注入B的属性，发现B的属性a，需要A对象 又到了A对象开始获取 此时，进入第一个流程，发现一级缓存里没有A，而A又正在创建中，出现循环依赖，去二级缓存里找A的工厂Map，调用工厂Map方法去，得到了EarlyBeanReference，放入三级缓存里，返回回去 即此时，B注入属性成功，并且返回了一个EarlyBeanReference，即当前正在创建的A对象实例。 B注入成功属性后，B实例化完全结束，结束后，清除B的二三级缓存，加入一级缓存并返回 此时回到了A的注入B属性逻辑中，A得到了B实例。而这个实例里的A属性对象，和当前获取A的对象是一个 A继续完成初始化动作，最后A实例化完全结束，清楚A的二三级缓存，加入一级缓存并返回   只有2个缓存行吗？为什么一定要3个  BeanMap无用质疑是需要的 如果只有工厂Map而没有，可提前依赖的BeanMap的话，那么在一开始从缓存中获取Bean，一级缓存无法获取到，直接就有工厂Bean，一旦有工厂就调用工厂返回的值，这样是不行的，因为在工厂调用Bean的时候，有很多动作就会进行重复，比如工厂获取的时候，可以给SmartInstantiationAwareBeanPostProcessor机会去更改EarlyBeanReference对象，重复执行了。第二，与工厂模式的思想违背，工厂只需要制造一次，而不是每次都制造。 如果只有可提前依赖的BeanMap，而没有工厂Map。实际上是可以的，只不过没有工厂的话，会将大部分工作都抛给创建Bean的流程里，例如SmartInstantiationAwareBeanPostProcessor等工厂应该负责的工作    ApplicationContext的Refresh方法  Enviroment，环境参数，根据不同的环境，实现Environment不同的子类，例如Web环境会实现，StandardServletEnvironment，默认是实现StandardEnvironment，包含很多环境变量，系统变量，java环境变量，Servlet环境变量 创建beanFactory作为成员变量，ApplicationContext自身也实现了BeanFactory接口，只不过具体实现的方法是成员变量的beanFactory的方法、 填充工厂  增加SPEL表达式解析器 属性编辑器注入 增加一个ApplicationContextAwareProcessor的BPP，在Bean实例化之后，激活实现了aware接口的方法的一个BPP 配置忽略某些类型的属性自动注入，增加某些类型自动注入   postProcessBeanFactory：留给子类去实现 记录启动路径 激活BeanFactoryPostProcessor，invokeBeanFactoryPostProcessors 注册BeanPostProcessor 初始化国际化文件 初始化initApplicationEventMulticaster，事件传送器，用于发送事件 注册事件监听器 设置ConversionService 锁定所有BeanDefinitions，防止改变 实例化剩下所有的no-lazy实例 调用所有实现LifeCycle接口的bean 发送ContextRefreshedEvent事件  BeanFactoryPostProcessor和BeanPostProcessor区别   BeanFactoryPostProcessor是可以修改Bean的元数据，是控制BeanFactory的，而BeanPostProcessor是Bean实例的处理器，可以修改Bean的实例","title":""},{"content":"Wait UnSafe UnSafe是为java底层类库使用的，不应该被用户所使用，因为他的权限太高，可以做很多事情，例如修改私有字段的值、抛出异常、使用堆外内存、CAS操作基于CPU的CAS指令，以达到原子操作。Park()阻塞线程、UnPark()唤醒线程。\n UnSafe有一个属性静态theUnsafe，可以通过反射的方式获取到Unsafe实例\n Field theUnsafe = Unsafe.class.getDeclaredField(\u0026#34;theUnsafe\u0026#34;); theUnsafe.setAccessible(true); unsafe = (Unsafe) theUnsafe.get(null);  JUC下面大量使用了CAS操作，它们的底层是调用的Unsafe的CompareAndSwapXXX()方法。这种方式广泛运用于无锁算法，与java中标准的悲观锁机制相比，它可以利用CAS处理器指令提供极大的加速。\n AtomicInteger AtomicInteger是java提供的原子类\n 原子操作是指不会被线程调度机制打断的操作，这种操作一旦开始，就一直运行到结束，中间不会有任何线程上下文切换。\n原子操作可以是一个步骤，也可以是多个操作步骤，但是其顺序不可以被打乱，也不可以被切割而只执行其中的一部分，将整个操作视作一个整体是原子性的核心特征。\n我们这里说的原子操作与数据库ACID中的原子性，笔者认为最大区别在于，数据库中的原子性主要运用在事务中，一个事务之内的所有更新操作要么都成功，要么都失败，事务是有回滚机制的，而我们这里说的原子操作是没有回滚的，这是最大的区别。\n 底层其实就是用UnSafe类去操作的\nValue是volatile声明的，保证多线程的可见性，volatile只能保证可见性和禁止重排序，但并不能保证原子性，所以需要cas操作\npublic class AtomicInteger extends Number implements java.io.Serializable { private static final long serialVersionUID = 6214790243416807050L; /* * This class intended to be implemented using VarHandles, but there * are unresolved cyclic startup dependencies. */ private static final jdk.internal.misc.Unsafe U = jdk.internal.misc.Unsafe.getUnsafe(); private static final long VALUE = U.objectFieldOffset(AtomicInteger.class, \u0026#34;value\u0026#34;); private volatile int value; public final boolean compareAndSet(int expectedValue, int newValue) { return U.compareAndSetInt(this, VALUE, expectedValue, newValue); } 自增的方法也是调用Unsafe的自增方法，实际上是进行自旋操作去保证更新成功\npublic final int getAndAdd(int delta) { return U.getAndAddInt(this, VALUE, delta); } @HotSpotIntrinsicCandidate public final int getAndAddInt(Object o, long offset, int delta) { int v; do { v = getIntVolatile(o, offset); } while (!weakCompareAndSetInt(o, offset, v, v + delta)); return v; } AtomicStampedReference 虽然CAS解决了高并发情况下的问题，但是带来的一个问题就是ABA问题。\nCAS是Compare and swap，只有目标值等于某个值时才会进行更新\n例如要0更新为1的时候，发生如下操作\nB线程读取到了0 B线程阻塞了\nA线程读取到了0\nA线程把0变成2\nA线程又把2变成了0\nB线程恢复，继续比较发现还是0，就把0变成1\nABA的危害主要在无锁场景中\n例如在栈中\npackage com.java.demo.jmm; import java.util.concurrent.atomic.AtomicReference; /** * 无锁栈 */ public class ABA { static class Node{ int value; Node next; public Node(int value) { this.value = value; } } public static AtomicReference\u0026lt;Node\u0026gt; top=new AtomicReference\u0026lt;\u0026gt;(); public static void push(Node newNode){ for (;;){ //获取站顶  Node node = top.get(); //把新节点放在顶部  newNode.next=node; //cas更新  if(top.compareAndSet(node,newNode)){ return; } } } public static Node pop(){ for (;;){ //获得栈顶元素  Node t = top.get(); if(t==null){ return null; } Node next=t.next; if(top.compareAndSet(t,next)){ t.next=null; return t; } } } public static void main(String[] args) { //两个线程去操作  //先入栈1，2，3  push(new Node(1)); push(new Node(2)); push(new Node(3)); new Thread(()-\u0026gt;{ // 线程1出栈一个元素  pop(); }).start(); new Thread(()-\u0026gt;{ // 线程2出栈两个元素  Node A = pop(); //3  Node B = pop(); //2  // 线程2又把A入栈了  push(A); // 3又进去了  }).start(); //线程1 出3的时候阻塞了，线程2先出3，然后再出2，测试top就剩1一个。3节点已经再1线程那里读到了，在自己的工作空间里，3的后节点是2，  //因此，线程2又把3放进去，1发现是又是3了更新成功，就放了一个2，在top，而2元素在2线程的时候已经出栈了，就没有next节点了，导致最后  //栈里就一个2节点  } } 上面的栈ABA问题\n（1）版本号\n比如，上面的栈结构增加一个版本号用于控制，每次CAS的同时检查版本号有没有变过。\n还有一些数据结构喜欢使用高位存储一个邮戳来保证CAS的安全。\n（2）不重复使用节点的引用\n比如，上面的栈结构在线程2执行push()入栈操作的时候新建一个节点传入，而不是复用节点1的引用；\n（3）直接操作元素而不是节点\n比如，上面的栈结构push()方法不应该传入一个节点（Node），而是传入元素值（int的value）。\nJava提供的AtomicStampedReference就是通过邮戳\n（1）在多线程环境下使用无锁结构要注意ABA问题；\n（2）ABA的解决一般使用版本号来控制，并保证数据结构使用元素值来传递，且每次添加元素都新建节点承载元素值；\n（3）AtomicStampedReference内部使用Pair来存储元素值及其版本号；\nLongAdder LongAdder和AtomicLong的区别\n在高并发场景下，特别是写多的场景下，LongAdder要比AtomicLong快很多\n（1）LongAdder通过base和cells数组来存储值；\n（2）不同的线程会hash到不同的cell上去更新，减少了竞争；\n（3）LongAdder的性能非常高，最终会达到一种无竞争的状态；\n伪共享 缓存是由缓存行组成的，通常是 64 字节（常用处理器的缓存行是 64 字节的，比较旧的处理器缓存行是 32 字节），并且它有效地引用主内存中的一块地址。\n一个 Java 的 long 类型是 8 字节，因此在一个缓存行中可以存 8 个 long 类型的变量。\n在程序运行的过程中，缓存每次更新都从主内存中加载连续的 64 个字节。因此，如果访问一个 long 类型的数组时，当数组中的一个值被加载到缓存中时，另外 7 个元素也会被加载到缓存中。\n但是，如果使用的数据结构中的项在内存中不是彼此相邻的，比如链表，那么将得不到免费缓存加载带来的好处。\n不过，这种免费加载也有一个坏处。设想如果我们有个 long 类型的变量 a，它不是数组的一部分，而是一个单独的变量，并且还有另外一个 long 类型的变量 b 紧挨着它，那么当加载 a 的时候将免费加载 b。\n看起来似乎没有什么毛病，但是如果一个 CPU 核心的线程在对 a 进行修改，另一个 CPU 核心的线程却在对 b 进行读取。\n当前者修改 a 时，会把 a 和 b 同时加载到前者核心的缓存行中，更新完 a 后其它所有包含 a 的缓存行都将失效，因为其它缓存中的 a 不是最新值了。\n而当后者读取 b 时，发现这个缓存行已经失效了，需要从主内存中重新加载。\n请记住，我们的缓存都是以缓存行作为一个单位来处理的，所以失效 a 的缓存的同时，也会把 b 失效，反之亦然。\n这样就出现了一个问题，b 和 a 完全不相干，每次却要因为 a 的更新需要从主内存重新读取，它被缓存未命中给拖慢了。\n这就是传说中的伪共享。\n使用 @sun.misc.Contended 注解（java8）\n@sun.misc.Contended class MyLong { volatile long value; } 默认使用这个注解是无效的，需要在JVM启动参数加上-XX:-RestrictContended才会生效，，再次运行程序发现时间是718ms。\n注意，以上三种方式中的前两种是通过加字段的形式实现的，加的字段又没有地方使用，可能会被jvm优化掉，所以建议使用第三种方式。\n锁名词解释 （1）公平锁/非公平锁\n公平锁，是指按照线程申请的顺序获取锁。\n非公平锁，是指不是按照线程申请的顺序获取锁，有可能后申请的线程反而先获取到锁，假如先来的线程一直获取不到锁，会造成锁饥饿现象。\nReentrantLock中可以通过构造方法指定是否为公平锁，默认为非公平锁，非公平锁的优点在于吞吐量大。\nsynchronized无法指定为公平锁，一直都是非公平锁。\n（2）可重入锁\n可重入锁，是指一个线程获取锁之后再尝试获取锁时会自动获取锁，可重入锁的优点是避免死锁。\nReentrantLock和synchronized都是可重入锁。\n（3）独享锁/共享锁\n独享锁，是指锁一次只能被一个线程持有。\n共享锁，是指锁一次可以被多个线程持有。\nReentrantLock和synchronized都是独享锁，ReadWriteLock的读锁是共享锁，写锁是独享锁。\n（4）互斥锁/读写锁\n与独享锁/共享锁的概念差不多，是独享锁/共享锁的具体实现。\nReentrantLock和synchronized都是互斥锁\nReadWriteLock是读写锁\n（5）乐观锁/悲观锁\n悲观锁，是指认为对于同一个数据的并发操作必然会发生修改，即使不会发生修改也这么认为，所以一定要加锁。\n乐观锁，是指认为对于同一个数据的并发操作不一定会发生修改，在更新数据的时候，尝试去更新数据，如果失败就不断尝试。\n悲观锁适用于写操作多的场景，乐观锁适用于读操作多的场景。\n（6）分段锁\n分段锁，是一种锁的设计思路，它细化了锁的粒度，主要运用在ConcurrentHashMap中，实现高效的并发操作，当操作不需要更新整个数组时，就只锁数组中的一项就可以了。\n（7）偏向锁/轻量级锁/重量级锁\n这三个锁主要是针对synchronized进行优化使用的，主要是通过对象监视器在对象头中的字段来表明的。\n偏向锁，是指一段同步代码一直被一个线程访问，那么这个线程会自动获取锁，降低获取锁的代价。\n轻量级锁，是指当锁是偏向锁时，被另一个线程所访问，偏向锁会升级为轻量级锁，这个线程会通过自旋的方式尝试获取锁，不会阻塞，提高性能。\n重量级锁，是指当锁是轻量级锁时，当自旋的线程自旋了一定的次数后，还没有获取到锁，就会进入阻塞状态，该锁升级为重量级锁，重量级锁会使其他线程阻塞，性能降低。\n（8）自旋锁\n自旋锁，是指尝试获取锁的线程不会阻塞，而是循环的方式不断尝试，这样的好处是减少线程的上下文切换带来的开锁，提高性能，缺点是循环会消耗CPU。\n（9）监视器锁\nsynchronized的实现方式，使用monitorenter和monitorexit来实现。\n（10）mutex锁\n互斥锁，LockSupport.part()底层是通过mutex实现的。\nJMM的原子性、可见性、有序性 Java内存模型就是为了解决多线程环境下共享变量的一致性问题，那么一致性包含哪些内容呢？\n一致性主要包含三大特性：原子性、可见性、有序性，下面我们就来看看Java内存模型是怎么实现这三大特性的。\n（1）原子性\n原子性是指一段操作一旦开始就会一直运行到底，中间不会被其它线程打断，这段操作可以是一个操作，也可以是多个操作。\n由Java内存模型来直接保证的原子性操作包括read、load、user、assign、store、write这两个操作，我们可以大致认为基本类型变量的读写是具备原子性的。\n如果应用需要一个更大范围的原子性，Java内存模型还提供了lock和unlock这两个操作来满足这种需求，尽管不能直接使用这两个操作，但我们可以使用它们更具体的实现synchronized来实现。\n因此，synchronized块之间的操作也是原子性的。\n（2）可见性\n可见性是指当一个线程修改了共享变量的值，其它线程能立即感知到这种变化。\nJava内存模型是通过在变更修改后同步回主内存，在变量读取前从主内存刷新变量值来实现的，它是依赖主内存的，无论是普通变量还是volatile变量都是如此。\n普通变量与volatile变量的主要区别是是否会在修改之后立即同步回主内存，以及是否在每次读取前立即从主内存刷新。因此我们可以说volatile变量保证了多线程环境下变量的可见性，但普通变量不能保证这一点。\n除了volatile之外，还有两个关键字也可以保证可见性，它们是synchronized和final。\nsynchronized的可见性是由“对一个变量执行unlock操作之前，必须先把此变量同步回主内存中，即执行store和write操作”这条规则获取的。\nfinal的可见性是指被final修饰的字段在构造器中一旦被初始化完成，那么其它线程中就能看见这个final字段了。\n（3）有序性\nJava程序中天然的有序性可以总结为一句话：如果在本线程中观察，所有的操作都是有序的；如果在另一个线程中观察，所有的操作都是无序的。\n前半句是指线程内表现为串行的语义，后半句是指“指令重排序”现象和“工作内存和主内存同步延迟”现象。\nJava中提供了volatile和synchronized两个关键字来保证有序性。\nvolatile天然就具有有序性，因为其禁止重排序。\nsynchronized的有序性是由“一个变量同一时刻只允许一条线程对其进行lock操作”这条规则获取的。\nSynchronized Java在不断进化，同样地，Java中像synchronized这种古老的东西也在不断进化，比如ConcurrentHashMap在jdk7的时候还是使用ReentrantLock加锁的，在jdk8的时候已经换成了原生的synchronized了，可见synchronized有原生的支持，它的进化空间还是很大的。\n那么，synchronized有哪些进化中的状态呢？\n我们这里稍做一些简单地介绍：\n（1）偏向锁，是指一段同步代码一直被一个线程访问，那么这个线程会自动获取锁，降低获取锁的代价。\n（2）轻量级锁，是指当锁是偏向锁时，被另一个线程所访问，偏向锁会升级为轻量级锁，这个线程会通过自旋的方式尝试获取锁，不会阻塞，提高性能。\n（3）重量级锁，是指当锁是轻量级锁时，当自旋的线程自旋了一定的次数后，还没有获取到锁，就会进入阻塞状态，该锁升级为重量级锁，重量级锁会使其他线程阻塞，性能降低。\n总结：\n（1）synchronized在编译时会在同步块前后生成monitorenter和monitorexit字节码指令；\n（2）monitorenter和monitorexit字节码指令需要一个引用类型的参数，基本类型不可以哦；\n（3）monitorenter和monitorexit字节码指令更底层是使用Java内存模型的lock和unlock指令；\n（4）synchronized是可重入锁；\n（5）synchronized是非公平锁；\n（6）synchronized可以同时保证原子性、可见性、有序性；\n（7）synchronized有三种状态：偏向锁、轻量级锁、重量级锁；\n自己实现一个锁 package com.java.demo.lock; import com.java.demo.jmm.UnSafeTest; import sun.misc.Unsafe; import java.lang.reflect.Field; /** * 自定义锁 * 多线程尝试去更新state，更新成功的线程进入执行，更新不成功的直接进入队列，进行阻塞，等待，直至拿到锁的线程释放锁 * * */ public class MyLock { /** * 状态 */ private volatile int state; //用于cas更新  private static Unsafe unsafe; private static long stateOffset; private static long tailOffset; // 链表头  private volatile Node head; // 链表尾  private volatile Node tail; private Node empty = new Node(); public MyLock() { head = tail = empty; } static { try { //准备 unsafe  Field theUnsafe = Unsafe.class.getDeclaredField(\u0026#34;theUnsafe\u0026#34;); theUnsafe.setAccessible(true); unsafe = (Unsafe) theUnsafe.get(null); stateOffset = unsafe.objectFieldOffset(MyLock.class.getDeclaredField(\u0026#34;state\u0026#34;)); tailOffset = unsafe.objectFieldOffset(MyLock.class.getDeclaredField(\u0026#34;tail\u0026#34;)); }catch (Exception e){ e.printStackTrace(); } } private boolean compareAndSetState(int expect, int update) { return unsafe.compareAndSwapInt(this, stateOffset, expect, update); } // 原子更新tail字段  private boolean compareAndSetTail(Node expect, Node update) { return unsafe.compareAndSwapObject(this, tailOffset, expect, update); } public void lock() { // 尝试更新state字段，更新成功说明占有了锁  if (compareAndSetState(0, 1)) { return; } // 未更新成功的线程则入队  Node node = enqueue(); Node prev = node.prev; // 再次尝试获取锁，需要检测上一个节点是不是head，按入队顺序加锁  while (node.prev != head || !compareAndSetState(0, 1)) { // 未获取到锁，阻塞  unsafe.park(false, 0L); } // 下面不需要原子更新，因为同时只有一个线程访问到这里  // 获取到锁了且上一个节点是head  // head后移一位  head = node; // 清空当前节点的内容，协助GC  node.thread = null; // 将上一个节点从链表中剔除，协助GC  node.prev = null; prev.next = null; } // 入队  private Node enqueue() { while (true) { // 获取尾节点  Node t = tail; // 构造新节点  Node node = new Node(Thread.currentThread(), t); // 不断尝试原子更新尾节点  if (compareAndSetTail(t, node)) { // 更新尾节点成功了，让原尾节点的next指针指向当前节点  t.next = node; return node; } } } // 解锁  public void unlock() { // 把state更新成0，这里不需要原子更新，因为同时只有一个线程访问到这里  state = 0; // 下一个待唤醒的节点  Node next = head.next; // 下一个节点不为空，就唤醒它  if (next != null) { unsafe.unpark(next.thread); } } private static class Node { // 存储的元素为线程  Thread thread; // 前一个节点（可以没有，但实现起来很困难）  Node prev; // 后一个节点  Node next; public Node() { } public Node(Thread thread, Node prev) { this.thread = thread; this.prev = prev; } } } AQS AQS的全称是AbstractQueuedSynchronizer，它的定位是为Java中几乎所有的锁和同步器提供一个基础框架。\nAQS是基于FIFO的队列实现的，并且内部维护了一个状态变量state，通过原子更新这个状态变量state即可以实现加锁解锁操作\nAQS中维护了一个队列，这个队列使用双链表实现，用于保存等待锁排队的线程；\nReentrantLock 公平锁 static final class FairSync extends Sync { private static final long serialVersionUID = -3000897897090466540L; /** * Fair version of tryAcquire. Don\u0026#39;t grant access unless * recursive call or no waiters or is first. */ @ReservedStackAccess protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { --------------------- //核心！！！！  //判断了队列中是否有前辈节点，没有前辈节点才会成功  if (!hasQueuedPredecessors() \u0026amp;\u0026amp; compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc \u0026lt; 0) throw new Error(\u0026#34;Maximum lock count exceeded\u0026#34;); setState(nextc); return true; } return false; } } 和非公平的区别核心就在hasQueuedPredecessors方法\nfinal boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc \u0026lt; 0) // overflow  throw new Error(\u0026#34;Maximum lock count exceeded\u0026#34;); setState(nextc); return true; } return false; } 条件锁 ","permalink":"https://sunhao1256.github.io/posts/%E5%A4%9A%E7%BA%BF%E7%A8%8B/","summary":"Wait UnSafe UnSafe是为java底层类库使用的，不应该被用户所使用，因为他的权限太高，可以做很多事情，例如修改私有字段的值、抛出异常、使用堆外内存、CAS操作基于CPU的CAS指令，以达到原子操作。Park()阻塞线程、UnPark()唤醒线程。\n UnSafe有一个属性静态theUnsafe，可以通过反射的方式获取到Unsafe实例\n Field theUnsafe = Unsafe.class.getDeclaredField(\u0026#34;theUnsafe\u0026#34;); theUnsafe.setAccessible(true); unsafe = (Unsafe) theUnsafe.get(null);  JUC下面大量使用了CAS操作，它们的底层是调用的Unsafe的CompareAndSwapXXX()方法。这种方式广泛运用于无锁算法，与java中标准的悲观锁机制相比，它可以利用CAS处理器指令提供极大的加速。\n AtomicInteger AtomicInteger是java提供的原子类\n 原子操作是指不会被线程调度机制打断的操作，这种操作一旦开始，就一直运行到结束，中间不会有任何线程上下文切换。\n原子操作可以是一个步骤，也可以是多个操作步骤，但是其顺序不可以被打乱，也不可以被切割而只执行其中的一部分，将整个操作视作一个整体是原子性的核心特征。\n我们这里说的原子操作与数据库ACID中的原子性，笔者认为最大区别在于，数据库中的原子性主要运用在事务中，一个事务之内的所有更新操作要么都成功，要么都失败，事务是有回滚机制的，而我们这里说的原子操作是没有回滚的，这是最大的区别。\n 底层其实就是用UnSafe类去操作的\nValue是volatile声明的，保证多线程的可见性，volatile只能保证可见性和禁止重排序，但并不能保证原子性，所以需要cas操作\npublic class AtomicInteger extends Number implements java.io.Serializable { private static final long serialVersionUID = 6214790243416807050L; /* * This class intended to be implemented using VarHandles, but there * are unresolved cyclic startup dependencies. */ private static final jdk.internal.misc.Unsafe U = jdk.internal.misc.Unsafe.getUnsafe(); private static final long VALUE = U.","title":""},{"content":"平时疑问   浏览器输入一个地址，整个流程\n  如果线上流量暴增，全都打到一个 upstream 上了，怎么排查\n  如何在 nginx 的 access log 中查出请求前 10 的 ip\n  台阶问题，假如对于上台阶，可以一次上一阶，也可以一次上两阶，写一个方法，实现输入台阶数，输出可以有多少种上法。\n  广度优先和深度优先\n  spring reactive，响应式聊下，什么时候适合用？背压是什么东西，backpress\n  压缩算法，怎么就“压缩”了？如何减少体积的？\n  实时一致性，最终一致性是什么？什么场景下用那种，如何实现的？\n  实时一致性:\n微服务中，场景用户使用积分兑换优惠券，积分service先扣除积分，优惠券service再进行发券动作，如果网络问题，积分扣成功了，但是优惠券发失败了。用户会投诉，必须要证优惠券和积分要在同一个分布式事务中.\n解决方案：市面上的分布式事务，阿里的seata\n  最终一致性:\n微服务中，用户选择商品下单，商品service进行库存扣件，订单service生成订单，交易service生成交易订单。如果网络原因导致，交易service生成交易订单失败了。并没有影响，只需要通过措施重新弥补交易service去生成交易订单即可。\n解决方法：mq，通过mq的重试机制以及持久化等特性，每一个微服务与下游微服务进行交互动作都是通过mq的消息。保证消息能够被消费，长时间未消费可以告警。\n    消息堆积如何处理？以及产生的危害。\n  怎么保证接口幂等\n  如何评判一个服务的好坏？你是如何进行压测的？查看了哪些指标\n  对象存储，文件存储，块存储。区别\n  服务器卡了，字都快打不动了，咋回事，怎么排查\n  用过mysql行锁吗\n用过，在一些比较简单的微服务场景，或者无法使用其他中间件的前提下。如果需要部署多节点的话，最方便的分布式锁就是mysql，因为我们的db库基本都是单节点的mysql或者mariadb。使用起来其实很简单，就是一个update语句，更新version字段。也就是所谓的乐观锁。开启一个事务，先select锁，然后尝试更新锁，在没完成业务的之前是不提交锁的，所以，其他线程会在获取锁的时候就停下来。因为update，delete，insert默认都是带for update，即行锁的。当然select不会阻塞，除非主动的设置for update。这样就是最基础的一个分布式锁了。切记锁字段必须要有索引，否则锁整个表。就G了\n  netty玩过吗，玩过哪些东西，能干啥\n  你看过一个springboot的启动内存吗？大吗？为啥这么大，怎么瘦身呢，为什么一个go就只要几十M\n  activity7了解过吗\n  规则引擎了解了解？\n  git cherry-pick是啥\n  你们平时是如何开发的，用jira，说说jira的几个问题类型，epic，之类的。\n  大量sql都超过了200ms。怎么排查\n  你写了一个服务，怎么压测的？怎么得到qps,qps的计算公式\n  为什么main线程执行结束了，jvm虚拟机还不退出。\njvm退出的条件是，当前虚拟机中只存在守护线程了，只要存活非守护线程，则jvm不会退出直到线程执行完毕。所以，如果你用了一个有多线程功能的包，但是测试的时候，main线程结束的，整个jvm都退出了，原因就是这个包，创建线程的时候是守护线程。当然main线程是不可以设为守护线程的。\n  字典树有什么场景可以使用？\n  amd64,arm64,x86_64,aarch,都是啥\n  背压理解吗，微服务中下游服务扛不住并发会崩了。有实战过吗\n场景：A服务调用B服务某个接口。耗时，并且需要资源巨大的接口。B不一定是你自己的微服务，可能是别人提供的部署在公网环境的服务。客户端通过A接口调用B，现在要求B不能崩，而且A的接口需要全部请求下来，不能丢，可以异步。 方案：mq\n  GRPC是什么，用过吗\n  脑裂\n  rabbitmq怎么保证顺序消费\n  ","permalink":"https://sunhao1256.github.io/posts/%E5%B9%B3%E6%97%B6%E7%96%91%E9%97%AE/","summary":"平时疑问   浏览器输入一个地址，整个流程\n  如果线上流量暴增，全都打到一个 upstream 上了，怎么排查\n  如何在 nginx 的 access log 中查出请求前 10 的 ip\n  台阶问题，假如对于上台阶，可以一次上一阶，也可以一次上两阶，写一个方法，实现输入台阶数，输出可以有多少种上法。\n  广度优先和深度优先\n  spring reactive，响应式聊下，什么时候适合用？背压是什么东西，backpress\n  压缩算法，怎么就“压缩”了？如何减少体积的？\n  实时一致性，最终一致性是什么？什么场景下用那种，如何实现的？\n  实时一致性:\n微服务中，场景用户使用积分兑换优惠券，积分service先扣除积分，优惠券service再进行发券动作，如果网络问题，积分扣成功了，但是优惠券发失败了。用户会投诉，必须要证优惠券和积分要在同一个分布式事务中.\n解决方案：市面上的分布式事务，阿里的seata\n  最终一致性:\n微服务中，用户选择商品下单，商品service进行库存扣件，订单service生成订单，交易service生成交易订单。如果网络原因导致，交易service生成交易订单失败了。并没有影响，只需要通过措施重新弥补交易service去生成交易订单即可。\n解决方法：mq，通过mq的重试机制以及持久化等特性，每一个微服务与下游微服务进行交互动作都是通过mq的消息。保证消息能够被消费，长时间未消费可以告警。\n    消息堆积如何处理？以及产生的危害。\n  怎么保证接口幂等\n  如何评判一个服务的好坏？你是如何进行压测的？查看了哪些指标\n  对象存储，文件存储，块存储。区别\n  服务器卡了，字都快打不动了，咋回事，怎么排查\n  用过mysql行锁吗\n用过，在一些比较简单的微服务场景，或者无法使用其他中间件的前提下。如果需要部署多节点的话，最方便的分布式锁就是mysql，因为我们的db库基本都是单节点的mysql或者mariadb。使用起来其实很简单，就是一个update语句，更新version字段。也就是所谓的乐观锁。开启一个事务，先select锁，然后尝试更新锁，在没完成业务的之前是不提交锁的，所以，其他线程会在获取锁的时候就停下来。因为update，delete，insert默认都是带for update，即行锁的。当然select不会阻塞，除非主动的设置for update。这样就是最基础的一个分布式锁了。切记锁字段必须要有索引，否则锁整个表。就G了\n  netty玩过吗，玩过哪些东西，能干啥","title":""},{"content":"堆 堆是一种非线性结构，可以把堆看作一个数组，也可以被看作一个完全二叉树，通俗来讲堆其实就是利用完全二叉树的结构来维护的一维数组但堆并不一定是完全二叉树\n按照堆的特点可以把堆分为大顶堆和小顶堆 大顶堆：每个结点的值都大于或等于其左右孩子结点的值 小顶堆：每个结点的值都小于或等于其左右孩子结点的值\n使用堆的原因？ 如果仅仅是需要得到一个有序的序列，使用排序就可以很快完成，并不需要去组织一个新的数据结构。但是如果我们的需求是对于一个随时会有更新的序列，我要随时知道这个序列的最小值或最大值是什么。显然如果是线性结构，每次插入之后，假设原数组是有序的，那使用二分把它放在正确的位置也未尝不可，但是插入的时候从数组中留出空位就需要O(n)的时间复杂度，删除的时候亦然。\n时间复杂度 插入和删除的时间复杂度是O(logn)\n环形队列(数组) 普通队列 普通队列，数组实现时，出队后，原来的空间就浪费了。\n环形队列 环形队列，数组实现时，下标用模取运算，例如最大空间为5，模取后只会有0，1，2，3，4下标，组成了循环。\n front 变量的含义做一个调整： front 就指向队列的第一个元素, 也就是说 arr[front] 就是队列的第一个元素 front 的初始值 = 0 rear 变量的含义做一个调整：rear 指向队列的最后一个元素的后一个位置. 因为希望空出一个空间做为约定. rear 的初始值 = 0 当队列满时，条件是 (rear + 1) % maxSize == front 【满】 对队列为空的条件， rear == front 空 当我们这样分析， 队列中有效的数据的个数 (rear + maxSize - front) % maxSize // rear = 1 front = 0  时间轮 使用场景，处理大批量的定时任务\n利用环形队列，队列的每个空间里存放的是任务的集合。\n例如以60秒为一个轮，70秒后执行一个任务。只需要一个timer按秒去旋转时间轮，70%60=10，到达第10个槽的时候，执行内部的所有任务即可。\n为了解决10秒和70秒落在同一个槽上，可以在任务身上加一个属性，圈数，例如10秒的任务圈数是0，70秒的任务是1，只有达到槽位置，并且圈数为0的任务才会被执行。\nkafaka的做法是，再做一个分钟轮，先转分钟轮。再转秒的轮。\n树 二叉搜索树(BST) 根节点的值大于其左子树中任意一个节点的值，小于其右节点中任意一节点的值，这一规则适用于二叉查找树中的每一个节点。\n完全平衡二叉树(AVL) 解决二叉树极端下变成链表\n红黑树 解决，完全平衡二叉树平衡频率过于频繁。\n时间复杂度log(n)\n 二叉搜索树：也称二叉查找树，或二叉排序树。定义也比较简单，要么是一颗空树，要么就是具有如下性质的二叉树： （1）若任意节点的左子树不空，则左子树上所有结点的值均小于它的根结点的 值； （2）若任意节点的右子树不空，则右子树上所有结点的值均大于它的根结点的 值； （3）任意节点的左、右子树也分别为二叉查找树； （4）没有键值相等的节点。\n平衡二叉树：在二叉搜索树的基础上多了两个重要的特点： （1）左右两子树的高度差的绝对值不能超过 1； （2）左右两子树也是一颗平衡二叉树。\n红黑树：红黑树是在普通二叉树上，对每个节点添加一个颜色属性形成的，需要同时满足一下五条性质： （1）节点是红色或者是黑色； （2）根节点是黑色； （3）每个叶节点（NIL 或空节点）是黑色； （4）每个红色节点的两个子节点都是黑色的（也就是说不存在两个连续的红色节 点）； （5）从任一节点到其没个叶节点的所有路径都包含相同数目的黑色节点。\n区别：AVL 树需要保持平衡，但它的旋转太耗时，而红黑树就是一个没有 AVL 树 那样平衡，因此插入、删除效率会高于 AVL 树，而 AVL 树的查找效率显然高于红黑树。\n   如果插入一个node引起了树的不平衡，AVL和RB-Tree(红黑树)都是最多只需要2次旋转操作，即两者都是O(1)；但是在删除node引起树的不平衡时，最坏情况下，AVL需要维护从被删node到root这条路径上所有node的平衡性，因此需要旋转的量级O(logN)，而RB-Tree最多只需3次(因为不需要严格的平衡，从根到叶子的最长的可能路径不多于最短的可能路径的两倍长)旋转以及修改节点的颜色，只需要O(1)的复杂度。\n  其次，AVL的结构相较RB-Tree来说更为平衡，在插入和删除node更容易引起Tree的unbalance，因此在大量数据需要插入或者删除时，AVL需要rebalance的频率会更高。因此，RB-Tree在需要大量插入和删除node的场景下，效率更高。自然，由于AVL高度平衡，因此AVL的search效率更高。\n  IO多路复用epoll的实现采用红黑树组织管理sockfd，以支持快速的增删改查. ngnix中,用红黑树管理timer,因为红黑树是有序的,可以很快的得到距离当前最小的定时器. java中TreeMap，jdk1.8的hashmap的实现.\n","permalink":"https://sunhao1256.github.io/posts/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","summary":"堆 堆是一种非线性结构，可以把堆看作一个数组，也可以被看作一个完全二叉树，通俗来讲堆其实就是利用完全二叉树的结构来维护的一维数组但堆并不一定是完全二叉树\n按照堆的特点可以把堆分为大顶堆和小顶堆 大顶堆：每个结点的值都大于或等于其左右孩子结点的值 小顶堆：每个结点的值都小于或等于其左右孩子结点的值\n使用堆的原因？ 如果仅仅是需要得到一个有序的序列，使用排序就可以很快完成，并不需要去组织一个新的数据结构。但是如果我们的需求是对于一个随时会有更新的序列，我要随时知道这个序列的最小值或最大值是什么。显然如果是线性结构，每次插入之后，假设原数组是有序的，那使用二分把它放在正确的位置也未尝不可，但是插入的时候从数组中留出空位就需要O(n)的时间复杂度，删除的时候亦然。\n时间复杂度 插入和删除的时间复杂度是O(logn)\n环形队列(数组) 普通队列 普通队列，数组实现时，出队后，原来的空间就浪费了。\n环形队列 环形队列，数组实现时，下标用模取运算，例如最大空间为5，模取后只会有0，1，2，3，4下标，组成了循环。\n front 变量的含义做一个调整： front 就指向队列的第一个元素, 也就是说 arr[front] 就是队列的第一个元素 front 的初始值 = 0 rear 变量的含义做一个调整：rear 指向队列的最后一个元素的后一个位置. 因为希望空出一个空间做为约定. rear 的初始值 = 0 当队列满时，条件是 (rear + 1) % maxSize == front 【满】 对队列为空的条件， rear == front 空 当我们这样分析， 队列中有效的数据的个数 (rear + maxSize - front) % maxSize // rear = 1 front = 0  时间轮 使用场景，处理大批量的定时任务\n利用环形队列，队列的每个空间里存放的是任务的集合。\n例如以60秒为一个轮，70秒后执行一个任务。只需要一个timer按秒去旋转时间轮，70%60=10，到达第10个槽的时候，执行内部的所有任务即可。\n为了解决10秒和70秒落在同一个槽上，可以在任务身上加一个属性，圈数，例如10秒的任务圈数是0，70秒的任务是1，只有达到槽位置，并且圈数为0的任务才会被执行。","title":""}]