<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>Hao Sun</title>
<meta name=keywords content>
<meta name=description content="聊聊redis，平时你怎么用的 redis是一个高性能的缓存中间件。是一个kv的缓存数据库，他的数据都是存放在内存中的。当然他也有持久化的方案。这个等会儿说。 redis作为一个缓存数据库有他自己的数据结构，常见的有string，用于保存字符串，有最长的限制，我记得应该是512MB，List，列表数据结构类似于java中的linkedList，使用双链表，因此插入和删除复杂度是O1，查询时ON，可以重复。set类似于java中的hashset，无序，而且是不可以存放相同元素的。hash对应着java中的hashmap，经典的字典结构。zset，具有分数的set，他既是一个set，保证了value的唯一，还提供一个分数。平时可以用作排名的统计，也可以用于限流的方案。
此外redis还提供了其他的module，例如bloomfilter，布隆过滤器是使用一个位数组，用于存放大量的数据，解决的场景在于判断元素是否在大量数据中，存在误差，因为不隆过滤器就是通过多次的hash得到hash值然后放在位数组上，必然会产生冲突，只要hash次数多，数组够大，也能提高精度。如果不是分布式的项目中，可以使用google提供的gauva工具包。我们的一个常见场景，处理缓存穿透，例如查询用户信息，id根本不存在，除了在逻辑代码上处理，依然会打到数据库中，因此我们在启动项目的时候，可以将用户的id加载到不隆过滤器中，这样可以避免缓存穿透的问题。
redis除了缓存穿透，还有缓存击穿和雪崩的问题。击穿和雪崩其实两个差不多，击穿指的是某一个热点的key，在一瞬间失效过期，但是有大量的并发打这个key，导致全部打到了数据库，导致数据库挂了，对于这种··热点key，直接设置不过期就行了，然后再更新数据的时候，同时更新缓存即可。而雪崩，只的是多个key同一个时间挂了，也是并发，只不过查的东西不一样罢 了。还是一样，可以设置不过期。或者加一个随机数，保证过期时间有点差距就可以了。
说到这个缓存，其实这个缓存一致性也很重要。不管是先更新缓存，还是先更新数据库，实际上都会有问题。
首先缓存一定是删除，不可能是更新。这里其实是一个懒加载的思想，只有需要的时候，才会加入缓存。例如某个数据进缓存了，1分钟更新了10次，但访问只访问了1次，我没必要去更新10次。只有他需要的时候我才去加载一次缓存。
如果我先删除缓存，再更新数据库的话，我缓存删除完毕了，但是数据库还没更新完成，第二个请求来的时候，发现没有缓存读数据库，然后读到旧数据，并且把旧数据写到了缓存中，导致缓存一直是旧的。解决方案是，延时双删，就是当第一个线程更新完数据库的时候，进行一个sleep，并且再进行删除缓存。sleep，就是线程读数据库加写缓存的时间，估算一下即可。这样的话，再有线程来就又读新的数据库，并且进缓存了。
如果我先更新数据库，再删除缓存的话，如果我更新数据库成功了，但是缓存删除失败了，或者更新失败了，那线程读的就一直都是旧数据了。我们可以利用消息队列的重试机制，让消息队列去进行数据的更新，这中间的耗时是可以接受的。不过引入了一个消息队列，运维成本增高了。
最后对于一致性不高的，能容忍很多的，直接就给缓存设置一个过期过期时间，每次更新数据库的时候，不进行缓存删除。其实我遇到的没有这么高的并发，基本上都是删除缓存就完事了。
上面说到redis的持久化方案，redis有两种aof，和rdb。我就提一下，aof就是记录redis的命令，他是因为只是记录命令的日志，因此redis使用的顺序写，不需要进行寻址，所以效率极高，因此他能够每秒记录一次，也就是说最多丢失一秒的数据。RDB就是快照，每5分钟进行一次快照，相当于备份。RDB恢复的速度很快，AOF慢，实际情况的话，一般都是组合使用，使用RDB先恢复备份，最后再通过AOF进行补全。
redis除了提供了持久化，实际上还有主从备份，哨兵模式，还有集群，哨兵的节点主要就是监控其他redis节点的运行状态，然后当出现损坏的主节点时，重新选择新的主节点。主从备份，和mysql的主从很类似，主只进行写的动作，从节点进行读。他们之间通过psync进行数据同步，当一个节点加入的时候，会发一个psync到主节点，主节点发一个rdb快找给从节点，然后从节点加载到内存中。完成同步rdb，而期间的其他命令，都是通过buffer，也同步到从节点。
最后我再说一下redis为什么这么快吧。
首先redis是基于内存的，这就是他快的最大特点。
第二为什么redis的qps这么高，他明明是单线程的。这里要说一下，redis并不全是单线程的，一个数据分从网络传过来，再存进缓存，是两个动作，redis的单线程是在处理数据数据放进内存的时候，是单线程。为什么不使用多线程在这里呢，我们知道多线程带来的就是锁。并发等问题redis是io密集型的，cpu并不是他的瓶颈，而提高io效率的方法并不是就多线程一种方式。因此在读写缓存的时候使用的单线程。
在提升io利用率这方面，redis使用了多路复用的技术。因此redis使用的单线程去接口并发下的网络套接字，没有使用多线程，减少线程之间切换的开销，以及多线程带来的对象共享问题，因此redis被大家称为是单线程的。">
<meta name=author content="Hao Sun">
<link rel=canonical href=https://sunhao1256.github.io/posts/%E8%87%AA%E7%AD%94/>
<link crossorigin=anonymous href=/assets/css/stylesheet.min.c88963fe2d79462000fd0fb1b3737783c32855d340583e4523343f8735c787f0.css integrity="sha256-yIlj/i15RiAA/Q+xs3N3g8MoVdNAWD5FIzQ/hzXHh/A=" rel="preload stylesheet" as=style>
<script defer crossorigin=anonymous src=/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://sunhao1256.github.io/%3Clink%20/%20abs%20url%3E>
<link rel=icon type=image/png sizes=16x16 href=https://sunhao1256.github.io/%3Clink%20/%20abs%20url%3E>
<link rel=icon type=image/png sizes=32x32 href=https://sunhao1256.github.io/%3Clink%20/%20abs%20url%3E>
<link rel=apple-touch-icon href=https://sunhao1256.github.io/%3Clink%20/%20abs%20url%3E>
<link rel=mask-icon href=https://sunhao1256.github.io/%3Clink%20/%20abs%20url%3E>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<meta name=generator content="Hugo 0.89.0">
<noscript>
<style>#theme-toggle,.top-link{display:none}</style>
<style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style>
</noscript><meta property="og:title" content>
<meta property="og:description" content="聊聊redis，平时你怎么用的 redis是一个高性能的缓存中间件。是一个kv的缓存数据库，他的数据都是存放在内存中的。当然他也有持久化的方案。这个等会儿说。 redis作为一个缓存数据库有他自己的数据结构，常见的有string，用于保存字符串，有最长的限制，我记得应该是512MB，List，列表数据结构类似于java中的linkedList，使用双链表，因此插入和删除复杂度是O1，查询时ON，可以重复。set类似于java中的hashset，无序，而且是不可以存放相同元素的。hash对应着java中的hashmap，经典的字典结构。zset，具有分数的set，他既是一个set，保证了value的唯一，还提供一个分数。平时可以用作排名的统计，也可以用于限流的方案。
此外redis还提供了其他的module，例如bloomfilter，布隆过滤器是使用一个位数组，用于存放大量的数据，解决的场景在于判断元素是否在大量数据中，存在误差，因为不隆过滤器就是通过多次的hash得到hash值然后放在位数组上，必然会产生冲突，只要hash次数多，数组够大，也能提高精度。如果不是分布式的项目中，可以使用google提供的gauva工具包。我们的一个常见场景，处理缓存穿透，例如查询用户信息，id根本不存在，除了在逻辑代码上处理，依然会打到数据库中，因此我们在启动项目的时候，可以将用户的id加载到不隆过滤器中，这样可以避免缓存穿透的问题。
redis除了缓存穿透，还有缓存击穿和雪崩的问题。击穿和雪崩其实两个差不多，击穿指的是某一个热点的key，在一瞬间失效过期，但是有大量的并发打这个key，导致全部打到了数据库，导致数据库挂了，对于这种··热点key，直接设置不过期就行了，然后再更新数据的时候，同时更新缓存即可。而雪崩，只的是多个key同一个时间挂了，也是并发，只不过查的东西不一样罢 了。还是一样，可以设置不过期。或者加一个随机数，保证过期时间有点差距就可以了。
说到这个缓存，其实这个缓存一致性也很重要。不管是先更新缓存，还是先更新数据库，实际上都会有问题。
首先缓存一定是删除，不可能是更新。这里其实是一个懒加载的思想，只有需要的时候，才会加入缓存。例如某个数据进缓存了，1分钟更新了10次，但访问只访问了1次，我没必要去更新10次。只有他需要的时候我才去加载一次缓存。
如果我先删除缓存，再更新数据库的话，我缓存删除完毕了，但是数据库还没更新完成，第二个请求来的时候，发现没有缓存读数据库，然后读到旧数据，并且把旧数据写到了缓存中，导致缓存一直是旧的。解决方案是，延时双删，就是当第一个线程更新完数据库的时候，进行一个sleep，并且再进行删除缓存。sleep，就是线程读数据库加写缓存的时间，估算一下即可。这样的话，再有线程来就又读新的数据库，并且进缓存了。
如果我先更新数据库，再删除缓存的话，如果我更新数据库成功了，但是缓存删除失败了，或者更新失败了，那线程读的就一直都是旧数据了。我们可以利用消息队列的重试机制，让消息队列去进行数据的更新，这中间的耗时是可以接受的。不过引入了一个消息队列，运维成本增高了。
最后对于一致性不高的，能容忍很多的，直接就给缓存设置一个过期过期时间，每次更新数据库的时候，不进行缓存删除。其实我遇到的没有这么高的并发，基本上都是删除缓存就完事了。
上面说到redis的持久化方案，redis有两种aof，和rdb。我就提一下，aof就是记录redis的命令，他是因为只是记录命令的日志，因此redis使用的顺序写，不需要进行寻址，所以效率极高，因此他能够每秒记录一次，也就是说最多丢失一秒的数据。RDB就是快照，每5分钟进行一次快照，相当于备份。RDB恢复的速度很快，AOF慢，实际情况的话，一般都是组合使用，使用RDB先恢复备份，最后再通过AOF进行补全。
redis除了提供了持久化，实际上还有主从备份，哨兵模式，还有集群，哨兵的节点主要就是监控其他redis节点的运行状态，然后当出现损坏的主节点时，重新选择新的主节点。主从备份，和mysql的主从很类似，主只进行写的动作，从节点进行读。他们之间通过psync进行数据同步，当一个节点加入的时候，会发一个psync到主节点，主节点发一个rdb快找给从节点，然后从节点加载到内存中。完成同步rdb，而期间的其他命令，都是通过buffer，也同步到从节点。
最后我再说一下redis为什么这么快吧。
首先redis是基于内存的，这就是他快的最大特点。
第二为什么redis的qps这么高，他明明是单线程的。这里要说一下，redis并不全是单线程的，一个数据分从网络传过来，再存进缓存，是两个动作，redis的单线程是在处理数据数据放进内存的时候，是单线程。为什么不使用多线程在这里呢，我们知道多线程带来的就是锁。并发等问题redis是io密集型的，cpu并不是他的瓶颈，而提高io效率的方法并不是就多线程一种方式。因此在读写缓存的时候使用的单线程。
在提升io利用率这方面，redis使用了多路复用的技术。因此redis使用的单线程去接口并发下的网络套接字，没有使用多线程，减少线程之间切换的开销，以及多线程带来的对象共享问题，因此redis被大家称为是单线程的。">
<meta property="og:type" content="article">
<meta property="og:url" content="https://sunhao1256.github.io/posts/%E8%87%AA%E7%AD%94/"><meta property="og:image" content="https://sunhao1256.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts">
<meta property="og:site_name" content="Hao Sun">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://sunhao1256.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E">
<meta name=twitter:title content>
<meta name=twitter:description content="聊聊redis，平时你怎么用的 redis是一个高性能的缓存中间件。是一个kv的缓存数据库，他的数据都是存放在内存中的。当然他也有持久化的方案。这个等会儿说。 redis作为一个缓存数据库有他自己的数据结构，常见的有string，用于保存字符串，有最长的限制，我记得应该是512MB，List，列表数据结构类似于java中的linkedList，使用双链表，因此插入和删除复杂度是O1，查询时ON，可以重复。set类似于java中的hashset，无序，而且是不可以存放相同元素的。hash对应着java中的hashmap，经典的字典结构。zset，具有分数的set，他既是一个set，保证了value的唯一，还提供一个分数。平时可以用作排名的统计，也可以用于限流的方案。
此外redis还提供了其他的module，例如bloomfilter，布隆过滤器是使用一个位数组，用于存放大量的数据，解决的场景在于判断元素是否在大量数据中，存在误差，因为不隆过滤器就是通过多次的hash得到hash值然后放在位数组上，必然会产生冲突，只要hash次数多，数组够大，也能提高精度。如果不是分布式的项目中，可以使用google提供的gauva工具包。我们的一个常见场景，处理缓存穿透，例如查询用户信息，id根本不存在，除了在逻辑代码上处理，依然会打到数据库中，因此我们在启动项目的时候，可以将用户的id加载到不隆过滤器中，这样可以避免缓存穿透的问题。
redis除了缓存穿透，还有缓存击穿和雪崩的问题。击穿和雪崩其实两个差不多，击穿指的是某一个热点的key，在一瞬间失效过期，但是有大量的并发打这个key，导致全部打到了数据库，导致数据库挂了，对于这种··热点key，直接设置不过期就行了，然后再更新数据的时候，同时更新缓存即可。而雪崩，只的是多个key同一个时间挂了，也是并发，只不过查的东西不一样罢 了。还是一样，可以设置不过期。或者加一个随机数，保证过期时间有点差距就可以了。
说到这个缓存，其实这个缓存一致性也很重要。不管是先更新缓存，还是先更新数据库，实际上都会有问题。
首先缓存一定是删除，不可能是更新。这里其实是一个懒加载的思想，只有需要的时候，才会加入缓存。例如某个数据进缓存了，1分钟更新了10次，但访问只访问了1次，我没必要去更新10次。只有他需要的时候我才去加载一次缓存。
如果我先删除缓存，再更新数据库的话，我缓存删除完毕了，但是数据库还没更新完成，第二个请求来的时候，发现没有缓存读数据库，然后读到旧数据，并且把旧数据写到了缓存中，导致缓存一直是旧的。解决方案是，延时双删，就是当第一个线程更新完数据库的时候，进行一个sleep，并且再进行删除缓存。sleep，就是线程读数据库加写缓存的时间，估算一下即可。这样的话，再有线程来就又读新的数据库，并且进缓存了。
如果我先更新数据库，再删除缓存的话，如果我更新数据库成功了，但是缓存删除失败了，或者更新失败了，那线程读的就一直都是旧数据了。我们可以利用消息队列的重试机制，让消息队列去进行数据的更新，这中间的耗时是可以接受的。不过引入了一个消息队列，运维成本增高了。
最后对于一致性不高的，能容忍很多的，直接就给缓存设置一个过期过期时间，每次更新数据库的时候，不进行缓存删除。其实我遇到的没有这么高的并发，基本上都是删除缓存就完事了。
上面说到redis的持久化方案，redis有两种aof，和rdb。我就提一下，aof就是记录redis的命令，他是因为只是记录命令的日志，因此redis使用的顺序写，不需要进行寻址，所以效率极高，因此他能够每秒记录一次，也就是说最多丢失一秒的数据。RDB就是快照，每5分钟进行一次快照，相当于备份。RDB恢复的速度很快，AOF慢，实际情况的话，一般都是组合使用，使用RDB先恢复备份，最后再通过AOF进行补全。
redis除了提供了持久化，实际上还有主从备份，哨兵模式，还有集群，哨兵的节点主要就是监控其他redis节点的运行状态，然后当出现损坏的主节点时，重新选择新的主节点。主从备份，和mysql的主从很类似，主只进行写的动作，从节点进行读。他们之间通过psync进行数据同步，当一个节点加入的时候，会发一个psync到主节点，主节点发一个rdb快找给从节点，然后从节点加载到内存中。完成同步rdb，而期间的其他命令，都是通过buffer，也同步到从节点。
最后我再说一下redis为什么这么快吧。
首先redis是基于内存的，这就是他快的最大特点。
第二为什么redis的qps这么高，他明明是单线程的。这里要说一下，redis并不全是单线程的，一个数据分从网络传过来，再存进缓存，是两个动作，redis的单线程是在处理数据数据放进内存的时候，是单线程。为什么不使用多线程在这里呢，我们知道多线程带来的就是锁。并发等问题redis是io密集型的，cpu并不是他的瓶颈，而提高io效率的方法并不是就多线程一种方式。因此在读写缓存的时候使用的单线程。
在提升io利用率这方面，redis使用了多路复用的技术。因此redis使用的单线程去接口并发下的网络套接字，没有使用多线程，减少线程之间切换的开销，以及多线程带来的对象共享问题，因此redis被大家称为是单线程的。">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://sunhao1256.github.io/posts/"},{"@type":"ListItem","position":2,"name":"","item":"https://sunhao1256.github.io/posts/%E8%87%AA%E7%AD%94/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"","name":"","description":"聊聊redis，平时你怎么用的 redis是一个高性能的缓存中间件。是一个kv的缓存数据库，他的数据都是存放在内存中的。当然他也有持久化的方案。这个等会儿说。 redis作为一个缓存数据库有他自己的数据结构，常见的有string，用于保存字符串，有最长的限制，我记得应该是512MB，List，列表数据结构类似于java中的linkedList，使用双链表，因此插入和删除复杂度是O1，查询时ON，可以重复。set类似于java中的hashset，无序，而且是不可以存放相同元素的。hash对应着java中的hashmap，经典的字典结构。zset，具有分数的set，他既是一个set，保证了value的唯一，还提供一个分数。平时可以用作排名的统计，也可以用于限流的方案。\n此外redis还提供了其他的module，例如bloomfilter，布隆过滤器是使用一个位数组，用于存放大量的数据，解决的场景在于判断元素是否在大量数据中，存在误差，因为不隆过滤器就是通过多次的hash得到hash值然后放在位数组上，必然会产生冲突，只要hash次数多，数组够大，也能提高精度。如果不是分布式的项目中，可以使用google提供的gauva工具包。我们的一个常见场景，处理缓存穿透，例如查询用户信息，id根本不存在，除了在逻辑代码上处理，依然会打到数据库中，因此我们在启动项目的时候，可以将用户的id加载到不隆过滤器中，这样可以避免缓存穿透的问题。\nredis除了缓存穿透，还有缓存击穿和雪崩的问题。击穿和雪崩其实两个差不多，击穿指的是某一个热点的key，在一瞬间失效过期，但是有大量的并发打这个key，导致全部打到了数据库，导致数据库挂了，对于这种··热点key，直接设置不过期就行了，然后再更新数据的时候，同时更新缓存即可。而雪崩，只的是多个key同一个时间挂了，也是并发，只不过查的东西不一样罢 了。还是一样，可以设置不过期。或者加一个随机数，保证过期时间有点差距就可以了。\n说到这个缓存，其实这个缓存一致性也很重要。不管是先更新缓存，还是先更新数据库，实际上都会有问题。\n首先缓存一定是删除，不可能是更新。这里其实是一个懒加载的思想，只有需要的时候，才会加入缓存。例如某个数据进缓存了，1分钟更新了10次，但访问只访问了1次，我没必要去更新10次。只有他需要的时候我才去加载一次缓存。\n如果我先删除缓存，再更新数据库的话，我缓存删除完毕了，但是数据库还没更新完成，第二个请求来的时候，发现没有缓存读数据库，然后读到旧数据，并且把旧数据写到了缓存中，导致缓存一直是旧的。解决方案是，延时双删，就是当第一个线程更新完数据库的时候，进行一个sleep，并且再进行删除缓存。sleep，就是线程读数据库加写缓存的时间，估算一下即可。这样的话，再有线程来就又读新的数据库，并且进缓存了。\n如果我先更新数据库，再删除缓存的话，如果我更新数据库成功了，但是缓存删除失败了，或者更新失败了，那线程读的就一直都是旧数据了。我们可以利用消息队列的重试机制，让消息队列去进行数据的更新，这中间的耗时是可以接受的。不过引入了一个消息队列，运维成本增高了。\n最后对于一致性不高的，能容忍很多的，直接就给缓存设置一个过期过期时间，每次更新数据库的时候，不进行缓存删除。其实我遇到的没有这么高的并发，基本上都是删除缓存就完事了。\n上面说到redis的持久化方案，redis有两种aof，和rdb。我就提一下，aof就是记录redis的命令，他是因为只是记录命令的日志，因此redis使用的顺序写，不需要进行寻址，所以效率极高，因此他能够每秒记录一次，也就是说最多丢失一秒的数据。RDB就是快照，每5分钟进行一次快照，相当于备份。RDB恢复的速度很快，AOF慢，实际情况的话，一般都是组合使用，使用RDB先恢复备份，最后再通过AOF进行补全。\nredis除了提供了持久化，实际上还有主从备份，哨兵模式，还有集群，哨兵的节点主要就是监控其他redis节点的运行状态，然后当出现损坏的主节点时，重新选择新的主节点。主从备份，和mysql的主从很类似，主只进行写的动作，从节点进行读。他们之间通过psync进行数据同步，当一个节点加入的时候，会发一个psync到主节点，主节点发一个rdb快找给从节点，然后从节点加载到内存中。完成同步rdb，而期间的其他命令，都是通过buffer，也同步到从节点。\n最后我再说一下redis为什么这么快吧。\n首先redis是基于内存的，这就是他快的最大特点。\n第二为什么redis的qps这么高，他明明是单线程的。这里要说一下，redis并不全是单线程的，一个数据分从网络传过来，再存进缓存，是两个动作，redis的单线程是在处理数据数据放进内存的时候，是单线程。为什么不使用多线程在这里呢，我们知道多线程带来的就是锁。并发等问题redis是io密集型的，cpu并不是他的瓶颈，而提高io效率的方法并不是就多线程一种方式。因此在读写缓存的时候使用的单线程。\n在提升io利用率这方面，redis使用了多路复用的技术。因此redis使用的单线程去接口并发下的网络套接字，没有使用多线程，减少线程之间切换的开销，以及多线程带来的对象共享问题，因此redis被大家称为是单线程的。","keywords":[],"articleBody":"聊聊redis，平时你怎么用的 redis是一个高性能的缓存中间件。是一个kv的缓存数据库，他的数据都是存放在内存中的。当然他也有持久化的方案。这个等会儿说。 redis作为一个缓存数据库有他自己的数据结构，常见的有string，用于保存字符串，有最长的限制，我记得应该是512MB，List，列表数据结构类似于java中的linkedList，使用双链表，因此插入和删除复杂度是O1，查询时ON，可以重复。set类似于java中的hashset，无序，而且是不可以存放相同元素的。hash对应着java中的hashmap，经典的字典结构。zset，具有分数的set，他既是一个set，保证了value的唯一，还提供一个分数。平时可以用作排名的统计，也可以用于限流的方案。\n此外redis还提供了其他的module，例如bloomfilter，布隆过滤器是使用一个位数组，用于存放大量的数据，解决的场景在于判断元素是否在大量数据中，存在误差，因为不隆过滤器就是通过多次的hash得到hash值然后放在位数组上，必然会产生冲突，只要hash次数多，数组够大，也能提高精度。如果不是分布式的项目中，可以使用google提供的gauva工具包。我们的一个常见场景，处理缓存穿透，例如查询用户信息，id根本不存在，除了在逻辑代码上处理，依然会打到数据库中，因此我们在启动项目的时候，可以将用户的id加载到不隆过滤器中，这样可以避免缓存穿透的问题。\nredis除了缓存穿透，还有缓存击穿和雪崩的问题。击穿和雪崩其实两个差不多，击穿指的是某一个热点的key，在一瞬间失效过期，但是有大量的并发打这个key，导致全部打到了数据库，导致数据库挂了，对于这种··热点key，直接设置不过期就行了，然后再更新数据的时候，同时更新缓存即可。而雪崩，只的是多个key同一个时间挂了，也是并发，只不过查的东西不一样罢 了。还是一样，可以设置不过期。或者加一个随机数，保证过期时间有点差距就可以了。\n说到这个缓存，其实这个缓存一致性也很重要。不管是先更新缓存，还是先更新数据库，实际上都会有问题。\n首先缓存一定是删除，不可能是更新。这里其实是一个懒加载的思想，只有需要的时候，才会加入缓存。例如某个数据进缓存了，1分钟更新了10次，但访问只访问了1次，我没必要去更新10次。只有他需要的时候我才去加载一次缓存。\n如果我先删除缓存，再更新数据库的话，我缓存删除完毕了，但是数据库还没更新完成，第二个请求来的时候，发现没有缓存读数据库，然后读到旧数据，并且把旧数据写到了缓存中，导致缓存一直是旧的。解决方案是，延时双删，就是当第一个线程更新完数据库的时候，进行一个sleep，并且再进行删除缓存。sleep，就是线程读数据库加写缓存的时间，估算一下即可。这样的话，再有线程来就又读新的数据库，并且进缓存了。\n如果我先更新数据库，再删除缓存的话，如果我更新数据库成功了，但是缓存删除失败了，或者更新失败了，那线程读的就一直都是旧数据了。我们可以利用消息队列的重试机制，让消息队列去进行数据的更新，这中间的耗时是可以接受的。不过引入了一个消息队列，运维成本增高了。\n最后对于一致性不高的，能容忍很多的，直接就给缓存设置一个过期过期时间，每次更新数据库的时候，不进行缓存删除。其实我遇到的没有这么高的并发，基本上都是删除缓存就完事了。\n上面说到redis的持久化方案，redis有两种aof，和rdb。我就提一下，aof就是记录redis的命令，他是因为只是记录命令的日志，因此redis使用的顺序写，不需要进行寻址，所以效率极高，因此他能够每秒记录一次，也就是说最多丢失一秒的数据。RDB就是快照，每5分钟进行一次快照，相当于备份。RDB恢复的速度很快，AOF慢，实际情况的话，一般都是组合使用，使用RDB先恢复备份，最后再通过AOF进行补全。\nredis除了提供了持久化，实际上还有主从备份，哨兵模式，还有集群，哨兵的节点主要就是监控其他redis节点的运行状态，然后当出现损坏的主节点时，重新选择新的主节点。主从备份，和mysql的主从很类似，主只进行写的动作，从节点进行读。他们之间通过psync进行数据同步，当一个节点加入的时候，会发一个psync到主节点，主节点发一个rdb快找给从节点，然后从节点加载到内存中。完成同步rdb，而期间的其他命令，都是通过buffer，也同步到从节点。\n最后我再说一下redis为什么这么快吧。\n首先redis是基于内存的，这就是他快的最大特点。\n第二为什么redis的qps这么高，他明明是单线程的。这里要说一下，redis并不全是单线程的，一个数据分从网络传过来，再存进缓存，是两个动作，redis的单线程是在处理数据数据放进内存的时候，是单线程。为什么不使用多线程在这里呢，我们知道多线程带来的就是锁。并发等问题redis是io密集型的，cpu并不是他的瓶颈，而提高io效率的方法并不是就多线程一种方式。因此在读写缓存的时候使用的单线程。\n在提升io利用率这方面，redis使用了多路复用的技术。因此redis使用的单线程去接口并发下的网络套接字，没有使用多线程，减少线程之间切换的开销，以及多线程带来的对象共享问题，因此redis被大家称为是单线程的。\n","wordCount":"17","inLanguage":"en","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","author":{"@type":"Person","name":"Hao Sun"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://sunhao1256.github.io/posts/%E8%87%AA%E7%AD%94/"},"publisher":{"@type":"Organization","name":"Hao Sun","logo":{"@type":"ImageObject","url":"https://sunhao1256.github.io/%3Clink%20/%20abs%20url%3E"}}}</script>
</head>
<body id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://sunhao1256.github.io/ accesskey=h title="Hao Sun (Alt + H)">Hao Sun</a>
<span class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</span>
</div>
<ul id=menu>
<li>
<a href=https://sunhao1256.github.io/archives/ title=Archive>
<span>Archive</span>
</a>
</li>
<li>
<a href=https://sunhao1256.github.io/search/ title="Search (Alt + /)" accesskey=/>
<span>Search</span>
</a>
</li>
<li>
<a href=https://sunhao1256.github.io/tags/ title=Tags>
<span>Tags</span>
</a>
</li>
</ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<div class=breadcrumbs><a href=https://sunhao1256.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://sunhao1256.github.io/posts/>Posts</a></div>
<h1 class=post-title>
</h1>
<div class=post-meta>1 min&nbsp;·&nbsp;Hao Sun
</div>
</header> <div class=toc>
<details>
<summary accesskey=c title="(Alt + C)">
<span class=details>Table of Contents</span>
</summary>
<div class=inner><ul>
<li>
<a href=#%e8%81%8a%e8%81%8aredis%e5%b9%b3%e6%97%b6%e4%bd%a0%e6%80%8e%e4%b9%88%e7%94%a8%e7%9a%84 aria-label=聊聊redis，平时你怎么用的>聊聊redis，平时你怎么用的</a>
</li>
</ul>
</div>
</details>
</div>
<div class=post-content><h1 id=聊聊redis平时你怎么用的>聊聊redis，平时你怎么用的<a hidden class=anchor aria-hidden=true href=#聊聊redis平时你怎么用的>#</a></h1>
<p>redis是一个高性能的缓存中间件。是一个kv的缓存数据库，他的数据都是存放在内存中的。当然他也有持久化的方案。这个等会儿说。
redis作为一个缓存数据库有他自己的数据结构，常见的有string，用于保存字符串，有最长的限制，我记得应该是512MB，List，列表数据结构类似于java中的linkedList，使用双链表，因此插入和删除复杂度是O1，查询时ON，可以重复。set类似于java中的hashset，无序，而且是不可以存放相同元素的。hash对应着java中的hashmap，经典的字典结构。zset，具有分数的set，他既是一个set，保证了value的唯一，还提供一个分数。平时可以用作排名的统计，也可以用于限流的方案。</p>
<p>此外redis还提供了其他的module，例如bloomfilter，布隆过滤器是使用一个位数组，用于存放大量的数据，解决的场景在于判断元素是否在大量数据中，存在误差，因为不隆过滤器就是通过多次的hash得到hash值然后放在位数组上，必然会产生冲突，只要hash次数多，数组够大，也能提高精度。如果不是分布式的项目中，可以使用google提供的gauva工具包。我们的一个常见场景，处理缓存穿透，例如查询用户信息，id根本不存在，除了在逻辑代码上处理，依然会打到数据库中，因此我们在启动项目的时候，可以将用户的id加载到不隆过滤器中，这样可以避免缓存穿透的问题。</p>
<p>redis除了缓存穿透，还有缓存击穿和雪崩的问题。击穿和雪崩其实两个差不多，击穿指的是某一个热点的key，在一瞬间失效过期，但是有大量的并发打这个key，导致全部打到了数据库，导致数据库挂了，对于这种··热点key，直接设置不过期就行了，然后再更新数据的时候，同时更新缓存即可。而雪崩，只的是多个key同一个时间挂了，也是并发，只不过查的东西不一样罢 了。还是一样，可以设置不过期。或者加一个随机数，保证过期时间有点差距就可以了。</p>
<p>说到这个缓存，其实这个缓存一致性也很重要。不管是先更新缓存，还是先更新数据库，实际上都会有问题。</p>
<p>首先缓存一定是删除，不可能是更新。这里其实是一个懒加载的思想，只有需要的时候，才会加入缓存。例如某个数据进缓存了，1分钟更新了10次，但访问只访问了1次，我没必要去更新10次。只有他需要的时候我才去加载一次缓存。</p>
<p>如果我先删除缓存，再更新数据库的话，我缓存删除完毕了，但是数据库还没更新完成，第二个请求来的时候，发现没有缓存读数据库，然后读到旧数据，并且把旧数据写到了缓存中，导致缓存一直是旧的。解决方案是，延时双删，就是当第一个线程更新完数据库的时候，进行一个sleep，并且再进行删除缓存。sleep，就是线程读数据库加写缓存的时间，估算一下即可。这样的话，再有线程来就又读新的数据库，并且进缓存了。</p>
<p>如果我先更新数据库，再删除缓存的话，如果我更新数据库成功了，但是缓存删除失败了，或者更新失败了，那线程读的就一直都是旧数据了。我们可以利用消息队列的重试机制，让消息队列去进行数据的更新，这中间的耗时是可以接受的。不过引入了一个消息队列，运维成本增高了。</p>
<p>最后对于一致性不高的，能容忍很多的，直接就给缓存设置一个过期过期时间，每次更新数据库的时候，不进行缓存删除。其实我遇到的没有这么高的并发，基本上都是删除缓存就完事了。</p>
<p>上面说到redis的持久化方案，redis有两种aof，和rdb。我就提一下，aof就是记录redis的命令，他是因为只是记录命令的日志，因此redis使用的顺序写，不需要进行寻址，所以效率极高，因此他能够每秒记录一次，也就是说最多丢失一秒的数据。RDB就是快照，每5分钟进行一次快照，相当于备份。RDB恢复的速度很快，AOF慢，实际情况的话，一般都是组合使用，使用RDB先恢复备份，最后再通过AOF进行补全。</p>
<p>redis除了提供了持久化，实际上还有主从备份，哨兵模式，还有集群，哨兵的节点主要就是监控其他redis节点的运行状态，然后当出现损坏的主节点时，重新选择新的主节点。主从备份，和mysql的主从很类似，主只进行写的动作，从节点进行读。他们之间通过psync进行数据同步，当一个节点加入的时候，会发一个psync到主节点，主节点发一个rdb快找给从节点，然后从节点加载到内存中。完成同步rdb，而期间的其他命令，都是通过buffer，也同步到从节点。</p>
<p>最后我再说一下redis为什么这么快吧。</p>
<p>首先redis是基于内存的，这就是他快的最大特点。</p>
<p>第二为什么redis的qps这么高，他明明是单线程的。这里要说一下，redis并不全是单线程的，一个数据分从网络传过来，再存进缓存，是两个动作，redis的单线程是在处理数据数据放进内存的时候，是单线程。为什么不使用多线程在这里呢，我们知道多线程带来的就是锁。并发等问题redis是io密集型的，cpu并不是他的瓶颈，而提高io效率的方法并不是就多线程一种方式。因此在读写缓存的时候使用的单线程。</p>
<p>在提升io利用率这方面，redis使用了多路复用的技术。因此redis使用的单线程去接口并发下的网络套接字，没有使用多线程，减少线程之间切换的开销，以及多线程带来的对象共享问题，因此redis被大家称为是单线程的。</p>
</div>
<footer class=post-footer>
<nav class=paginav>
<a class=prev href=https://sunhao1256.github.io/posts/%E6%B5%8B%E8%AF%95%E4%B8%80%E5%BC%A0%E5%A3%81%E7%BA%B8/>
<span class=title>« Prev Page</span>
<br>
<span>测试一张壁纸</span>
</a>
</nav>
</footer>
</article>
</main>
<footer class=footer>
<span>&copy; 2022 <a href=https://sunhao1256.github.io/>Hao Sun</a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a>
</span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a>
<script>let menu=document.getElementById('menu');menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
</body>
</html>